<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references for AliceVision Meshroom</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchComment = true;	// search in comment

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, comment, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/comment
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/comment/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchComment && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'comment') {
		rev.className.indexOf('noshow') == -1?rev.className = 'comment noshow':rev.className = 'comment show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/comment/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'comment nextshow': rev.className = 'comment';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchComment=!searchComment;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchComment){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; margin: auto 2em; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { width: 100%; empty-cells: show; border-spacing: 0em 0.2em; margin: 1em 0em; border-style: none; }
th, td { border: 1px gray solid; border-width: 1px 1px; padding: 0.5em; vertical-align: top; text-align: left; }
th { background-color: #efefef; }
td + td, th + th { border-left: none; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.comment td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom: 1px gray solid; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include comment</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<thead><tr><th width="20%">Author</th><th width="30%">Title</th><th width="5%">Year</th><th width="30%">Journal/Proceedings</th><th width="10%">Reftype</th><th width="5%">DOI/URL</th></tr></thead>
<tbody><tr id="" class="entry">
	<td>Balabanian, A.</td>
	<td>Getting started with Photogrammetry — with a Smartphone camera [2019 update] Capturing the world in a Volumetric data format <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2017</td>
	<td>&nbsp;</td>
	<td>techreport</td>
	<td><a href="https://medium.com/realities-io/getting-started-with-photogrammetry-d0a6ee40cb72">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Step by step tutorial</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@techreport{,
  author = {Azad Balabanian},
  title = {Getting started with Photogrammetry — with a Smartphone camera [2019 update] Capturing the world in a Volumetric data format},
  year = {2017},
  url = {https://medium.com/realities-io/getting-started-with-photogrammetry-d0a6ee40cb72}
}
</pre></td>
</tr>
<tr id="Pont2018" class="entry">
	<td>Pont, U., Swoboda, S., Jonas, A., Waldmayer, F., Schober, P., Priebernig, H. and Mahdavi, A.</td>
	<td>Combining scientific approaches in building science and architectural design in academia: A case study <p class="infolinks">[<a href="javascript:toggleInfo('Pont2018','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pont2018','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>International Review of Applied Sciences and Engineering<br/>Vol. 9(2), pp. 129-135&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1556/1848.2018.9.2.8">DOI</a> <a href="https://akjournals.com/view/journals/1848/9/2/article-p129.xml">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pont2018" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A successful coupling of architectural design with multi-aspect building performance assessment is a complex, but necessary requirement for today's building planning- and retrofit-activities. Architects are required to not only possess the vocabulary and basic knowledge in multiple fields, but must also work in collaborative design teams, composed of different domain specialists (e.g., structural engineers and building simulation experts). However, training in collaborative work is rarely provided in academic surroundings. In this contribution, we describe an educational effort toward interdisciplinary work on a specific and clearly defined architectural design task, which strongly necessitates the consideration of performance mandates. The task is the retrofit and redesign of an existing building fa&ccedil;ade from the 1950s. “Rationalist” buildings of this period often display reasonable functional solutions and good daylight availability, but they have performance shortcomings in other areas. These encompass, for instance, poor thermal performance of the envelope, lack of sufficient indoor environmental control, and unsatisfactory overall appearance. In a combined design studio and project course for building performance modelling, students from different disciplinary backgrounds formed interdisciplinary design teams. These teams worked together on fa&ccedil;ade retrofit ideas for the aforementioned building, considering both aesthetic aspects and performance issues from the very first design sketch. This led to the development and performance evaluation of a number of original fa&ccedil;ade retrofit ideas. In addition, the students were asked to devise the building process management. They thus had to consider not only design issues, but practical matters of building construction. The present contribution illustrates the scope, the applied approaches, and the concrete results of this interdisciplinary academic effort.</td>
</tr>
<tr id="bib_Pont2018" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pont2018,
  author = {Pont, U. and Swoboda, S. and Jonas, A. and Waldmayer, F. and Schober, P. and Priebernig, H. and Mahdavi, A.},
  title = {Combining scientific approaches in building science and architectural design in academia: A case study},
  journal = {International Review of Applied Sciences and Engineering},
  year = {2018},
  volume = {9},
  number = {2},
  pages = {129--135},
  url = {https://akjournals.com/view/journals/1848/9/2/article-p129.xml},
  doi = {https://doi.org/10.1556/1848.2018.9.2.8}
}
</pre></td>
</tr>
<tr id="scanbox2018" class="entry">
	<td>scanbox</td>
	<td>AliceVision : New OpenSource Photogrammetry Framework <p class="infolinks">[<a href="javascript:toggleInfo('scanbox2018','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('scanbox2018','comment')">Comment</a>] [<a href="javascript:toggleInfo('scanbox2018','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://scanbox.xyz/blog/alicevision-opensource-photogrammetry/
https://web.archive.org/web/20181010161448/https://scanbox.xyz/blog/alicevision-opensource-photogrammetry/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_scanbox2018" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We wanted to share our first results using AliceVision, a free and open source photogrammetry framework.
<br>
<br>AliceVision is the result of a synergy between multiple Universities &amp; Labs (Czech Technical University,  IMAGINE,  Institut National Polytechnique de Toulouse (INPT), Simula Research Laboratory,  and Quine) and Mikros Image, a French post-production company. The team started a project called OpenMVG a few years ago. They presented the new AliceVision Framework at FMX 2018.</td>
</tr>
<tr id="rev_scanbox2018" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Quick Compare With Commercial Solutions</td>
</tr>
<tr id="bib_scanbox2018" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{scanbox2018,
  author = {scanbox},
  title = {AliceVision : New OpenSource Photogrammetry Framework},
  year = {2018},
  url = {https://scanbox.xyz/blog/alicevision-opensource-photogrammetry/
<br>https://web.archive.org/web/20181010161448/https://scanbox.xyz/blog/alicevision-opensource-photogrammetry/}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Radfelder, P.D.O.</td>
	<td>Digital Humanities im Museum 4.0 - Präsentation <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://informatik.hs-bremerhaven.de/dh2018/pdf/Pr%C3%A4sentation.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Prof. Dr. Oliver Radfelder},
  title = {Digital Humanities im Museum 4.0 - Präsentation},
  year = {2018},
  url = {https://informatik.hs-bremerhaven.de/dh2018/pdf/Pr%C3%A4sentation.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Albers, J., Bock, J., Harms, F., Junge, L., andLeon Leymann, P.K., Lüth, C., Schultz, B., Sehm, F. and Stadtelmeyer, A.</td>
	<td>Digital Humanities im Museum 4.0 Poster <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://informatik.hs-bremerhaven.de/dh2018/pdf/Poster_2_Erstellung.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Julia Albers, Jannick Bock, Felix Harms, Luca Junge, Pepijn Kampschöer,Leon Leymann, Christian Lüth, Björn Schultz, Fabian Sehm, André Stadtelmeyer},
  title = {Digital Humanities im Museum 4.0 Poster},
  year = {2018},
  url = {https://informatik.hs-bremerhaven.de/dh2018/pdf/Poster_2_Erstellung.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td></td>
	<td>D5.4: Deliver 3D reconstruction benchmarks with dataset <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>article</td>
	<td><a href="https://cordis.europa.eu/project/id/731970/results">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Full Pipeline Evaluation including the “Tanks and Temples” evaluation benchmark</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{,,
  title = {D5.4: Deliver 3D reconstruction benchmarks with dataset},
  year = {2018},
  url = {https://cordis.europa.eu/project/id/731970/results}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>AliceVision</td>
	<td>Meshroom: Open Source 3D Reconstruction Software <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=v_O6tYKQEBA">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {AliceVision},
  title = {Meshroom: Open Source 3D Reconstruction Software},
  year = {2018},
  url = {https://www.youtube.com/watch?v=v_O6tYKQEBA}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>by Josef Prusa, P.3D.</td>
	<td>Photogrammetry 2 – 3D scanning with just PHONE/CAMERA simpler, better than ever! <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=1D0EhSi-vvc https://blog.prusaprinters.org/de/photogrammetrie-2-3d-scannen-einfacher-besser-denn-je_29393/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Prusa 3D by Josef Prusa},
  title = {Photogrammetry 2 – 3D scanning with just PHONE/CAMERA simpler, better than ever!},
  year = {2018},
  url = {https://www.youtube.com/watch?v=1D0EhSi-vvc https://blog.prusaprinters.org/de/photogrammetrie-2-3d-scannen-einfacher-besser-denn-je_29393/}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>CG-Geek</td>
	<td>How to 3D Photoscan Easy and Free! <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=k4NTf0hMjtY">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Learn how to do photogrammetry and create some amazing 3D scans with Meshroom and Blender for free in this tutorial!</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {CG-Geek},
  title = {How to 3D Photoscan Easy and Free!},
  year = {2018},
  url = {https://www.youtube.com/watch?v=k4NTf0hMjtY}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td></td>
	<td>Meshroom: Free photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2018</td>
	<td>forum&nbsp;</td>
	<td>misc</td>
	<td><a href="https://blenderartists.org/t/meshroom-free-photogrammetry/1120286/145">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,,
  title = {Meshroom: Free photogrammetry},
  year = {2018},
  url = {https://blenderartists.org/t/meshroom-free-photogrammetry/1120286/145}
}
</pre></td>
</tr>
<tr id="10.2312:gch.20191349" class="entry">
	<td>Medeiros e S&aacute;, A., Iba&ntilde;ez Vila, A.B., Rodriguez Echavarria, K., Marroquim, R. and Luiz Fonseca, V.</td>
	<td>Accessible Digitisation and Visualisation of Open Cultural Heritage Assets <p class="infolinks">[<a href="javascript:toggleInfo('10.2312:gch.20191349','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('10.2312:gch.20191349','comment')">Comment</a>] [<a href="javascript:toggleInfo('10.2312:gch.20191349','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Eurographics Workshop on Graphics and Cultural Heritage&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.2312/gch.20191349">DOI</a> <a href="https://cris.brighton.ac.uk/ws/portalfiles/portal/7238946/Digital_Modernismo.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_10.2312:gch.20191349" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this research, we proposed a methodology for documenting open and medium-large scale cultural heritage assets. By open we mean both in the sense of their location in open spaces and the fact that they are openly accessible to the public. We take advantage of the maturity of 3D digital technologies for enabling communities across the world to support the documentation of Cultural Heritage (CH) assets that are accessible to the public. For the present project, we focus on producing digital replicas of public sculptures from the Modern period situated in public spaces in Rio de Janeiro. We propose the adoption of an open-source pipeline, based on photogrammetry, which is implemented in separate phases: identification, data acquisition, processing, evaluation, and access. These phases present various challenges, in particular given the medium-large scale of such assets and the variety of spaces in which the assets are located including open spaces and other locations in which it is difficult to control the digitisation conditions. The evaluation and access of the resulting documentation is a key component of such projects. We suggest that community-led approaches have the potential to generate digital resources that are relevant both for professionals and the general public. We discuss various options for access, such as web-based solutions, Augmented Reality (AR) applications, as well as 3D printed digital replicas.</td>
</tr>
<tr id="rev_10.2312:gch.20191349" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Reconstruction accuracy comparison between Meshroom and Agisoft Metashape and VSfM/Regard3D</td>
</tr>
<tr id="bib_10.2312:gch.20191349" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{10.2312:gch.20191349,
  author = {Medeiros e S&aacute;, Asla and Iba&ntilde;ez Vila, Adolfo Bartolome and Rodriguez Echavarria, Karina and Marroquim, Ricardo and Luiz Fonseca, Vivian},
  title = {Accessible Digitisation and Visualisation of Open Cultural Heritage Assets},
  booktitle = {Eurographics Workshop on Graphics and Cultural Heritage},
  publisher = {The Eurographics Association},
  year = {2019},
  url = {https://cris.brighton.ac.uk/ws/portalfiles/portal/7238946/Digital_Modernismo.pdf},
  doi = {https://doi.org/10.2312/gch.20191349}
}
</pre></td>
</tr>
<tr id="2019AGUFM.H11H1572G" class="entry">
	<td>Gupta, S., Singh, N., Shukla, D. and Singh, R.</td>
	<td>Morphological Mapping of 13 August 2017 Kotropi Landslide using Images and Videos from Drone and Structure from Motion <p class="infolinks">[<a href="javascript:toggleInfo('2019AGUFM.H11H1572G','comment')">Comment</a>] [<a href="javascript:toggleInfo('2019AGUFM.H11H1572G','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td><br/>Vol. 2019Proceedings of the AGU Fall Meeting Abstracts, pp. H11H-1572&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://agu.confex.com/agu/fm19/meetingapp.cgi/Paper/529652">URL</a>&nbsp;</td>
</tr>
<tr id="rev_2019AGUFM.H11H1572G" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Short mention, usage example</td>
</tr>
<tr id="bib_2019AGUFM.H11H1572G" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{2019AGUFM.H11H1572G,
  author = {Gupta, S.&sim;K. and Singh, N and Shukla, D.&sim;P. and Singh, R.&sim;P.},
  title = {Morphological Mapping of 13 August 2017 Kotropi Landslide using Images and Videos from Drone and Structure from Motion},
  booktitle = {Proceedings of the AGU Fall Meeting Abstracts},
  year = {2019},
  volume = {2019},
  pages = {H11H--1572},
  url = {https://agu.confex.com/agu/fm19/meetingapp.cgi/Paper/529652}
}
</pre></td>
</tr>
<tr id="admin" class="entry">
	<td>v4design.eu</td>
	<td>First 3D reconstructions being generated – V4Design <p class="infolinks">[<a href="javascript:toggleInfo('admin','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://v4design.eu/2019/07/11/first-3d-reconstructions-being-generated/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_admin" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{admin,
  author = {v4design.eu},
  title = {First 3D reconstructions being generated – V4Design},
  year = {2019},
  url = {https://v4design.eu/2019/07/11/first-3d-reconstructions-being-generated/}
}
</pre></td>
</tr>
<tr id="AlKhalil2019" class="entry">
	<td>Al Khalil, O. and Grussenmeyer, P.</td>
	<td>2D And 3D Reconstruction Workflows From Archive Images, Case Study Of Damaged Monuments In Bosra Al Sham City (Syria) <p class="infolinks">[<a href="javascript:toggleInfo('AlKhalil2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('AlKhalil2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('AlKhalil2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLII-2/W15, pp. 55-62&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLII-2-W15-55-2019">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W15/55/2019/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_AlKhalil2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. The paper explores the possibilities of using old images for 2D and 3D documentation of archaeological monuments using open source, free and commercial photogrammetric software. The available images represent the external fa&ccedil;ade of the Western gate and Al Omari Mosque in the city of Bosra al-Sham in Syria, which were severely damaged during the recent war. The images were captured using consumer camera and they were originally used to achieve 2D documentation for each part of the gate separately. 2D control points were used to scale the digital photomosaic and reference distances were applied for the scaling of the 3D models. Archive images were used to produce a 2D digital photomosaic of the monument by image rectification and 3D dense point clouds by applying Structure from Motion (SfM) techniques. The geometric accuracy of the results has been assessed.</td>
</tr>
<tr id="rev_AlKhalil2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Photogrammetry Software comparison and quality evaluation for cultural heritage projects</td>
</tr>
<tr id="bib_AlKhalil2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{AlKhalil2019,
  author = {Al Khalil, O. and Grussenmeyer, P.},
  title = {2D And 3D Reconstruction Workflows From Archive Images, Case Study Of Damaged Monuments In Bosra Al Sham City (Syria)},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2019},
  volume = {XLII-2/W15},
  pages = {55--62},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W15/55/2019/},
  doi = {https://doi.org/10.5194/isprs-archives-XLII-2-W15-55-2019}
}
</pre></td>
</tr>
<tr id="Bernardin2019" class="entry">
	<td>Bernardin, A., Duriez, C. and Marchal, M.</td>
	<td>An Interactive Physically-based Model for Active Suction Phenomenon Simulation <p class="infolinks">[<a href="javascript:toggleInfo('Bernardin2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('Bernardin2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1466-1471&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/IROS40897.2019.8967526">DOI</a> <a href="https://ieeexplore.ieee.org/document/8967526/">URL</a>&nbsp;</td>
</tr>
<tr id="rev_Bernardin2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Robotics/Physics research
<br>
<br>Meshroom used for 3d reconstruction of object used for physical modelling</td>
</tr>
<tr id="bib_Bernardin2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Bernardin2019,
  author = {Bernardin, Antonin and Duriez, Christian and Marchal, Maud},
  title = {An Interactive Physically-based Model for Active Suction Phenomenon Simulation},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  publisher = {IEEE},
  year = {2019},
  pages = {1466--1471},
  url = {https://ieeexplore.ieee.org/document/8967526/},
  doi = {https://doi.org/10.1109/IROS40897.2019.8967526}
}
</pre></td>
</tr>
<tr id="Burk2019" class="entry">
	<td>Burk, Z. and Johnson, C.</td>
	<td>Method For Production of 3D interactive Models Using Photogrammetry For Use in Human Anatomy Education <p class="infolinks">[<a href="javascript:toggleInfo('Burk2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>HAPS Educator<br/>Vol. 23(2), pp. 457-463&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.21692/haps.2019.016">DOI</a> <a href="https://docs.google.com/a/hapsconnect.org/viewer?a=v&pid=sites&srcid=aGFwc2Nvbm5lY3Qub3JnfGhhcHNfZWR1Y2F0b3J8Z3g6NDhkOWNjOTYwYWEzM2E2MQ">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Burk2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Burk2019,
  author = {Burk, Zachary and Johnson, Corey},
  title = {Method For Production of 3D interactive Models Using Photogrammetry For Use in Human Anatomy Education},
  journal = {HAPS Educator},
  year = {2019},
  volume = {23},
  number = {2},
  pages = {457--463},
  url = {https://docs.google.com/a/hapsconnect.org/viewer?a=v&amp;pid=sites&amp;srcid=aGFwc2Nvbm5lY3Qub3JnfGhhcHNfZWR1Y2F0b3J8Z3g6NDhkOWNjOTYwYWEzM2E2MQ},
  doi = {https://doi.org/10.21692/haps.2019.016}
}
</pre></td>
</tr>
<tr id="Covadonga2019" class="entry">
	<td>Covadonga, L., Epifanio, L. and Eduardo, C.</td>
	<td>Using Drones, 3D Modeling And Digital Fabrication Technologies To Promote Architectural Heritage: A Case Study <p class="infolinks">[<a href="javascript:toggleInfo('Covadonga2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 12th annual International Conference of Education, Research and Innovation, pp. 3565-3571&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.21125/iceri.2019.0919">DOI</a> <a href="http://library.iated.org/view/LORENZO2019USI">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Covadonga2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Covadonga2019,
  author = {Covadonga, Lorenzo and Epifanio, Lorenzo and Eduardo, Chamorro},
  title = {Using Drones, 3D Modeling And Digital Fabrication Technologies To Promote Architectural Heritage: A Case Study},
  booktitle = {Proceedings of the 12th annual International Conference of Education, Research and Innovation},
  year = {2019},
  pages = {3565--3571},
  url = {http://library.iated.org/view/LORENZO2019USI},
  doi = {https://doi.org/10.21125/iceri.2019.0919}
}
</pre></td>
</tr>
<tr id="Danieau2019" class="entry">
	<td>Danieau, F., Gubins, I., Olivier, N., Dumas, O., Denis, B., Lopez, T., Mollet, N., Frager, B. and Avril, Q.</td>
	<td>Automatic Generation and Stylization of 3D Facial Rigs <p class="infolinks">[<a href="javascript:toggleInfo('Danieau2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces (VR), pp. 784-792&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/VR.2019.8798208">DOI</a> <a href="https://ieeexplore.ieee.org/document/8798208/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Danieau2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Danieau2019,
  author = {Danieau, Fabien and Gubins, Ilja and Olivier, Nicolas and Dumas, Olivier and Denis, Bernard and Lopez, Thomas and Mollet, Nicolas and Frager, Brian and Avril, Quentin},
  title = {Automatic Generation and Stylization of 3D Facial Rigs},
  booktitle = {Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  publisher = {IEEE},
  year = {2019},
  pages = {784--792},
  url = {https://ieeexplore.ieee.org/document/8798208/},
  doi = {https://doi.org/10.1109/VR.2019.8798208}
}
</pre></td>
</tr>
<tr id="DeBell2019.12.16.878033" class="entry">
	<td>DeBell, L., Duffy, J.P., McKinley, T.J. and Anderson, K.</td>
	<td>Species and habitat mapping in two dimensions and beyond. Structure-from-Motion Multi-View Stereo photogrammetry for the Conservation Community <p class="infolinks">[<a href="javascript:toggleInfo('DeBell2019.12.16.878033','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('DeBell2019.12.16.878033','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>bioRxiv&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1101/2019.12.16.878033">DOI</a> <a href="https://www.biorxiv.org/content/early/2019/12/16/2019.12.16.878033">URL</a>&nbsp;</td>
</tr>
<tr id="abs_DeBell2019.12.16.878033" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Structure-from-Motion Multi View Stereo (SfM-MVS) photogrammetry is a technique by which volumetric data can be derived from overlapping image sets, using changes of an objects position between images to determine its height and spatial structure. Whilst SfM-MVS has fast become a powerful tool for scientific research, its potential lies beyond the scientific setting, since it can aid in delivering information about habitat structure, biomass, landscape topography, spatial distribution of species in both two and three dimensions, and aid in mapping change over time &ndash; both actual and predicted. All of which are of strong relevance for the conservation community, whether from a practical management perspective or understanding and presenting data in new and novel ways from a policy perspective.For practitioners outside of academia wanting to use SfM-MVS there are technical barriers to its application. For example, there are many SfM-MVS software options, but knowing which to choose, or how to get the best results from the software can be difficult for the uninitiated. There are also free and open source software options (FOSS) for processing data through a SfM-MVS pipeline that could benefit those in conservation management and policy, especially in instances where there is limited funding (i.e. commonly within grassroots or community-based projects). This paper signposts the way for the conservation community to understand the choices and options for SfM-MVS implementation, its limitations, current best practice guidelines and introduces applicable FOSS options such as OpenDroneMap, MicMac, CloudCompare, QGIS and speciesgeocodeR. It will also highlight why and where this technology has the potential to become an asset for spatial, temporal and volumetric studies of landscape and conservation ecology.</td>
</tr>
<tr id="bib_DeBell2019.12.16.878033" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{DeBell2019.12.16.878033,
  author = {DeBell, Leon and Duffy, James P and McKinley, Trevelyan J and Anderson, Karen},
  title = {Species and habitat mapping in two dimensions and beyond. Structure-from-Motion Multi-View Stereo photogrammetry for the Conservation Community},
  journal = {bioRxiv},
  publisher = {Cold Spring Harbor Laboratory},
  year = {2019},
  url = {https://www.biorxiv.org/content/early/2019/12/16/2019.12.16.878033},
  doi = {https://doi.org/10.1101/2019.12.16.878033}
}
</pre></td>
</tr>
<tr id="Douglass2019" class="entry">
	<td>Douglass, M.J. and Cara&ccedil;a Santos, A.M.</td>
	<td>Application of optical photogrammetry in radiation oncology: HDR surface mold brachytherapy <p class="infolinks">[<a href="javascript:toggleInfo('Douglass2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Douglass2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Brachytherapy<br/>Vol. 18(5), pp. 689-700&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/J.BRACHY.2019.05.006">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Douglass2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Purpose: We propose a novel method of designing surface mold brachytherapy applicators using optical photogrammetry. The accuracy of this technique for the purpose of 3D-printing surface mold brachytherapy applicators is investigated. Methods and Materials: Photogrammetry was used to generate a 3D model of a patient's right arm. The geometric accuracy of the model was evaluated against CT in terms of volume, surface area, and the Hausdorff distance. A surface mold applicator was then 3D printed using this reconstructed model. The accuracy was evaluated by analyzing the displacement and air-gap volumes between the applicator and plaster cast on a CT image. This technique was subsequently applied to generate a 3D-printed applicator of the author's hand directly, as a proof of principle, using only photographic images. Results: The volume and surface area of the model were within 0.1% and 2.6% of the CT-obtained values, respectively. Using the Hausdorff distance metric, it was determined that 93% of the visible vertices present in the CT-derived model had a matching vertex on the photogrammetry-derived model within 1 mm, indicating a high level of similarity. The maximum displacement between the plaster cast of the patient's arm and the photo-derived 3D-printed applicator was 1.2 mm with a total air-gap volume of approximately 0.05 cm3. Conclusions: Photogrammetry has been applied to the task of generating 3D-printed brachytherapy surface mold applicators. The current work demonstrates the feasibility and accuracy of this technique and how it may be incorporated into a 3D-printing brachytherapy workflow.</td>
</tr>
<tr id="bib_Douglass2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Douglass2019,
  author = {Douglass, Michael J.J. and Cara&ccedil;a Santos, Alexandre M.},
  title = {Application of optical photogrammetry in radiation oncology: HDR surface mold brachytherapy},
  journal = {Brachytherapy},
  publisher = {Elsevier},
  year = {2019},
  volume = {18},
  number = {5},
  pages = {689--700},
  doi = {https://doi.org/10.1016/J.BRACHY.2019.05.006}
}
</pre></td>
</tr>
<tr id="Forgione2019" class="entry">
	<td>Forgione, T.</td>
	<td>Dynamic Adaptive 3D Streaming over HTTP <p class="infolinks">[<a href="javascript:toggleInfo('Forgione2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td><i>School</i>: University of Toulouse&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Forgione2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Forgione2019,
  author = {Forgione, Thomas},
  title = {Dynamic Adaptive 3D Streaming over HTTP},
  school = {University of Toulouse},
  year = {2019}
}
</pre></td>
</tr>
<tr id="Gherardini_2019" class="entry">
	<td>Gherardini, F., Santachiara, M. and Leali, F.</td>
	<td>Enhancing heritage fruition through 3D virtual models and augmented reality: an application to Roman artefacts <p class="infolinks">[<a href="javascript:toggleInfo('Gherardini_2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gherardini_2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Virtual Archaeology Review<br/>Vol. 10(21), pp. 67&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.4995/var.2019.11918">DOI</a> <a href="https://riunet.upv.es/bitstream/handle/10251/124734/11918-48089-5-PB.pdf?sequence=4&isAllowed=y">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Gherardini_2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The spatial characteristics of museum exhibitions may limit visitors’ experience of the artefacts on display. In the case of large artefacts, limited space may affect their whole visualization, or inhibit the visualization of the details farthest from the observer. In other cases, the storage of artefacts in  distant sites (museums or archaeological areas) may influence their knowledge  process  or  the  possibility  for  comparative  analysis.  Moreover,  the  precarious  state  of  preservation  of  some artefacts,  with  damaged  or  missing  parts,  makes  it  difficult  to  perceive  their  original  appearance.  To  overcome  these limitations, we propose an integrated approach based on 3D virtual models and Augmented Reality (AR) to enhance the fruition of artefacts, improving their visualization, analysis and personal/shared knowledge, also by overcoming space and time constraints. The final AR application is an easily accessible tool for most users from a mobile device, used both inside and outside museums, opening new perspectives for fruition. The framework encourages the use of free and open source software and standard devices, to maximize their dissemination and exploit the potential of such technologies, which is far greater than current use in the cultural heritage field. Selected case studies to test and validate the integrated framework are proposed, dealing with some Roman artefacts found in the area of Modena (Italy). The first is a Roman floor mosaic, found in Savignano sul Panaro (near Modena) in 2011, of which less than half of its original 4.5 x 6.9 m surface is preserved. The others are two Roman funerary lion sculptures: the first is one of two lions flanking the main door of Modena Cathedral, and the second, well-preserved but damaged, is housed in the Museo Lapidario Estense of Modena. Finally, the application was tested by museum experts and visitors both inside and outside the museum, and positively assessed.</td>
</tr>
<tr id="bib_Gherardini_2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gherardini_2019,
  author = {Francesco Gherardini and Mattia Santachiara and Francesco Leali},
  title = {Enhancing heritage fruition through 3D virtual models and augmented reality: an application to Roman artefacts},
  journal = {Virtual Archaeology Review},
  publisher = {Universitat Politecnica de Valencia},
  year = {2019},
  volume = {10},
  number = {21},
  pages = {67},
  url = {https://riunet.upv.es/bitstream/handle/10251/124734/11918-48089-5-PB.pdf?sequence=4&amp;isAllowed=y},
  doi = {https://doi.org/10.4995/var.2019.11918}
}
</pre></td>
</tr>
<tr id="Gherardini2019" class="entry">
	<td>Gherardini, F., Santachiara, M. and Leali, F.</td>
	<td>Enhancing heritage fruition through 3D virtual models and augmented reality: an application to Roman artefacts <p class="infolinks">[<a href="javascript:toggleInfo('Gherardini2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gherardini2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('Gherardini2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Virtual Archaeology Review<br/>Vol. 10(21), pp. 67&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.4995/var.2019.11918">DOI</a> <a href="https://polipapers.upv.es/index.php/var/article/view/11918">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Gherardini2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The spatial characteristics of museum exhibitions may limit visitors' experience of the artefacts on display. In the case of large artefacts, limited space may affect their whole visualization, or inhibit the visualization of the details farthest from the observer. In other cases, the storage of artefacts in distant sites (museums or archaeological areas) may influence their knowledge process or the possibility for comparative analysis. Moreover, the precarious state of preservation of some artefacts, with damaged or missing parts, makes it difficult to perceive their original appearance. To overcome these limitations, we propose an integrated approach based on 3D virtual models and Augmented Reality (AR) to enhance the fruition of artefacts, improving their visualization, analysis and personal/shared knowledge, also by overcoming space and time constraints. The final AR application is an easily accessible tool for most users from a mobile device, used both inside and outside museums, opening new perspectives for fruition. The framework encourages the use of free and open source software and standard devices, to maximize their dissemination and exploit the potential of such technologies, which is far greater than current use in the cultural heritage field. Selected case studies to test and validate the integrated framework are proposed, dealing with some Roman artefacts found in the area of Modena (Italy). The first is a Roman floor mosaic, found in Savignano sul Panaro (near Modena) in 2011, of which less than half of its original 4.5 x 6.9 m surface is preserved. The others are two Roman funerary lion sculptures: the first is one of two lions flanking the main door of Modena Cathedral, and the second, well-preserved but damaged, is housed in the Museo Lapidario Estense of Modena. Finally, the application was tested by museum experts and visitors both inside and outside the museum, and positively assessed. Highlights: Digital practice is not understood as a prerogative of a small number of people, but as a tool to guarantee and expand artefact fruition, using standard devices and free and open source software. Experimentation of new settings to re-contextualize artefacts and establish possible links among them, offering engaging and customized experiences to improve their accessibility and enjoyment. Promotion of artefact fruition not only in but also outside museums, such as in a classroom or an open and shared space, opening to new approaches in the fruition of cultural heritage.</td>
</tr>
<tr id="rev_Gherardini2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Cultural heritage project</td>
</tr>
<tr id="bib_Gherardini2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gherardini2019,
  author = {Gherardini, Francesco and Santachiara, Mattia and Leali, Francesco},
  title = {Enhancing heritage fruition through 3D virtual models and augmented reality: an application to Roman artefacts},
  journal = {Virtual Archaeology Review},
  year = {2019},
  volume = {10},
  number = {21},
  pages = {67},
  url = {https://polipapers.upv.es/index.php/var/article/view/11918},
  doi = {https://doi.org/10.4995/var.2019.11918}
}
</pre></td>
</tr>
<tr id="Gu2019" class="entry">
	<td>Gu, L. and Liu, X.</td>
	<td>Online Fashion Design Education Supported by Digital Three Dimensions Technologies <p class="infolinks">[<a href="javascript:toggleInfo('Gu2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 3rd International Seminar on Education Innovation and Economic Management (SEIEM 2018)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.2991/seiem-18.2019.149">DOI</a> <a href="https://www.atlantis-press.com/article/55911571">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Gu2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Gu2019,
  author = {Gu, Liwen and Liu, Xiaogang},
  title = {Online Fashion Design Education Supported by Digital Three Dimensions Technologies},
  booktitle = {Proceedings of the 3rd International Seminar on Education Innovation and Economic Management (SEIEM 2018)},
  publisher = {Atlantis Press},
  year = {2019},
  url = {https://www.atlantis-press.com/article/55911571},
  doi = {https://doi.org/10.2991/seiem-18.2019.149}
}
</pre></td>
</tr>
<tr id="GuldurErkal2019" class="entry">
	<td>Guldur Erkal, B.</td>
	<td>Image-based 3D surface reconstruction of cold-formed steel c-sections <p class="infolinks">[<a href="javascript:toggleInfo('GuldurErkal2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 2019 European Conference on Computing in Construction&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.35490/EC3.2019.181">DOI</a> <a href="ec-3.org/conf2019/contribution_181_final/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_GuldurErkal2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{GuldurErkal2019,
  author = {Guldur Erkal, Burcu},
  title = {Image-based 3D surface reconstruction of cold-formed steel c-sections},
  booktitle = {Proceedings of the 2019 European Conference on Computing in Construction},
  year = {2019},
  url = {ec-3.org/conf2019/contribution_181_final/},
  doi = {https://doi.org/10.35490/EC3.2019.181}
}
</pre></td>
</tr>
<tr id="Hafiz2019" class="entry">
	<td>Hafiz, A. and Setianto, A.</td>
	<td>Application of Structure from Motion Method to Determine Direction of Slope Failure <p class="infolinks">[<a href="javascript:toggleInfo('Hafiz2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 2019 5th International Conference on Science and Technology (ICST)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICST47872.2019.9166399">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Hafiz2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Hafiz2019,
  author = {Hafiz, Abdel and Setianto, Agung},
  title = {Application of Structure from Motion Method to Determine Direction of Slope Failure},
  booktitle = {Proceedings of the 2019 5th International Conference on Science and Technology (ICST)},
  publisher = {IEEE},
  year = {2019},
  doi = {https://doi.org/10.1109/ICST47872.2019.9166399}
}
</pre></td>
</tr>
<tr id="inproceedings" class="entry">
	<td>Weil, L., Kolb, D., Weism&uuml;ller, J., Imm, E. and Kranzlm&uuml;ller, D.</td>
	<td>Raising Awareness for Endangered Species using Augmented Reality <p class="infolinks">[<a href="javascript:toggleInfo('inproceedings','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_inproceedings" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{inproceedings,
  author = {Weil, Lea and Kolb, Daniel and Weism&uuml;ller, Jens and Imm, Eric and Kranzlm&uuml;ller, Dieter},
  title = {Raising Awareness for Endangered Species using Augmented Reality},
  year = {2019}
}
</pre></td>
</tr>
<tr id="Ionita" class="entry">
	<td>Ionita, D.</td>
	<td>Implementing Augmented Reality at the Imperial War Museum <p class="infolinks">[<a href="javascript:toggleInfo('Ionita','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ionita','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://daniel.regentsit.co.uk/novel2.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Ionita" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper describes the process of creating an  Augmented Reality  experience  for  the  visitors  of  the  Imperial  War Museum, London, United Kingdom.</td>
</tr>
<tr id="bib_Ionita" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Ionita,
  author = {Daniel Ionita},
  title = {Implementing Augmented Reality at the Imperial War Museum},
  year = {2019},
  url = {https://daniel.regentsit.co.uk/novel2.pdf}
}
</pre></td>
</tr>
<tr id="IvanReljic2019" class="entry">
	<td>Ivan Relji&cacute;, Ivan Dunđer and Sanja Seljan</td>
	<td>Photogrammetric 3D Scanning of Physical Objects: Tools and Workflow <p class="infolinks">[<a href="javascript:toggleInfo('IvanReljic2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('IvanReljic2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>TEM Journal<br/>Vol. 8(2), pp. 383-388&nbsp;</td>
	<td>article</td>
	<td><a href="http://www.temjournal.com/content/82/TEMJournalMay2019_383_388.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="rev_IvanReljic2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Small comparison, not really thorough regarding Meshroom</td>
</tr>
<tr id="bib_IvanReljic2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{IvanReljic2019,
  author = {Ivan Relji&cacute; and Ivan Dunđer and Sanja Seljan},
  title = {Photogrammetric 3D Scanning of Physical Objects: Tools and Workflow},
  journal = {TEM Journal},
  publisher = {UIKTEN - Association for Information Communication Technology Education and Science},
  year = {2019},
  volume = {8},
  number = {2},
  pages = {383--388},
  url = {http://www.temjournal.com/content/82/TEMJournalMay2019_383_388.pdf}
}
</pre></td>
</tr>
<tr id="Julin2019" class="entry">
	<td>Julin, A., Jaalama, K., Virtanen, J.-P., Maksimainen, M., Kurkela, M., Hyypp&auml;, J. and Hyypp&auml;, H.</td>
	<td>Automated Multi-Sensor 3D Reconstruction for the Web <p class="infolinks">[<a href="javascript:toggleInfo('Julin2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Julin2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>ISPRS International Journal of Geo-Information<br/>Vol. 8(5), pp. 221&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/ijgi8050221">DOI</a> <a href="https://www.mdpi.com/2220-9964/8/5/221">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Julin2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The Internet has become a major dissemination and sharing platform for 3D content. The utilization of 3D measurement methods can drastically increase the production efficiency of 3D content in an increasing number of use cases where 3D documentation of real-life objects or environments is required. We demonstrated a developed, highly automated and integrated content creation process of providing reality-based photorealistic 3D models for the web. Close-range photogrammetry, terrestrial laser scanning (TLS) and their combination are compared using available state-of-the-art tools in a real-life project setting with real-life limitations. Integrating photogrammetry and TLS is a good compromise for both geometric and texture quality. Compared to approaches using only photogrammetry or TLS, it is slower and more resource-heavy but combines complementary advantages of each method, such as direct scale determination from TLS or superior image quality typically used in photogrammetry. The integration is not only beneficial, but clearly productionally possible using available state-of-the-art tools that have become increasingly available also for non-expert users. Despite the high degree of automation, some manual editing steps are still required in practice to achieve satisfactory results in terms of adequate visual quality. This is mainly due to the current limitations of WebGL technology.</td>
</tr>
<tr id="bib_Julin2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Julin2019,
  author = {Julin, Arttu and Jaalama, Kaisa and Virtanen, Juho-Pekka and Maksimainen, Mikko and Kurkela, Matti and Hyypp&auml;, Juha and Hyypp&auml;, Hannu},
  title = {Automated Multi-Sensor 3D Reconstruction for the Web},
  journal = {ISPRS International Journal of Geo-Information},
  year = {2019},
  volume = {8},
  number = {5},
  pages = {221},
  url = {https://www.mdpi.com/2220-9964/8/5/221},
  doi = {https://doi.org/10.3390/ijgi8050221}
}
</pre></td>
</tr>
<tr id="Karmacharya2019" class="entry">
	<td>Karmacharya, S.K., Bishwakarma, M., Shrestha, U. and R&uuml;ther, N.</td>
	<td>Application of ‘Structure from Motion' (SfM) technique in physical hydraulic modelling <p class="infolinks">[<a href="javascript:toggleInfo('Karmacharya2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Karmacharya2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('Karmacharya2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Journal of Physics: Conference Series<br/>Vol. 1266(1), pp. 012008&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1088/1742-6596/1266/1/012008">DOI</a> <a href="https://iopscience.iop.org/article/10.1088/1742-6596/1266/1/012008 https://iopscience.iop.org/article/10.1088/1742-6596/1266/1/012008/meta">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Karmacharya2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: There are many methods available for measurement of bed morphology in physical hydraulic model studies considering mobile bed sediment. Among which, there are sophisticated instrumentations which provide quality results in shorter time but are vastly expensive and requires special training for execution. Whereas the conventional surveying methodology, which is simple and inexpensive, requires plenty of time for the measurement and processing of the data. That is why the recent developments in 'Structure from Motion' (SfM) technique have made it a potential candidate for an inexpensive and efficient tool for measurement of bed morphology in physical hydraulic model studies. SfM method allows to simultaneously determine both the parameters of the camera and the 3D structure of a scene by combining 2D images taken from multiple viewpoints. SfM tools can create a dense point cloud out of a set of partially overlapping photographs taken even by a budget friendly digital camera. The SfM method have already been used as an alternative for topographic surveying to create high-resolution digital elevation models (DEM). Some researchers had also used it for measurement of bed morphology in laboratory experiments. In this study, different freely available SfM tools were used to create a dense point cloud from a set of photographs representing a short reach in a river model in the hydraulic laboratory at Hydro Lab. The selected tools were compared with each other and against a commercial software, based on the methodologies used, processing time and quality of the output. Then the results from SfM method were compared with actual measurements in the physical model done with a conventional surveying technique using a theodolite and a level machine. The results showed that free SfM tools can also produce efficient results compared to commercial tools and SfM method can be used as an inexpensive and efficient alternative for bed morphology measurements in physical hydraulic models.</td>
</tr>
<tr id="rev_Karmacharya2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: with comparison</td>
</tr>
<tr id="bib_Karmacharya2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Karmacharya2019,
  author = {Karmacharya, Sanat Kumar and Bishwakarma, Meg and Shrestha, Ujjwal and R&uuml;ther, Nils},
  title = {Application of ‘Structure from Motion' (SfM) technique in physical hydraulic modelling},
  journal = {Journal of Physics: Conference Series},
  publisher = {IOP Publishing},
  year = {2019},
  volume = {1266},
  number = {1},
  pages = {012008},
  url = {https://iopscience.iop.org/article/10.1088/1742-6596/1266/1/012008 https://iopscience.iop.org/article/10.1088/1742-6596/1266/1/012008/meta},
  doi = {https://doi.org/10.1088/1742-6596/1266/1/012008}
}
</pre></td>
</tr>
<tr id="Li2019" class="entry">
	<td>Li, H. and Nguyen, C.</td>
	<td>Perspective-Consistent Multifocus Multiview 3D Reconstruction of Small Objects <p class="infolinks">[<a href="javascript:toggleInfo('Li2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>2019 Digital Image Computing: Techniques and Applications (DICTA), pp. 1-8&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/DICTA47822.2019.8946006">DOI</a> <a href="https://ieeexplore.ieee.org/document/8946006/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Li2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Li2019,
  author = {Li, Hengjia and Nguyen, Chuong},
  title = {Perspective-Consistent Multifocus Multiview 3D Reconstruction of Small Objects},
  booktitle = {2019 Digital Image Computing: Techniques and Applications (DICTA)},
  publisher = {IEEE},
  year = {2019},
  pages = {1--8},
  url = {https://ieeexplore.ieee.org/document/8946006/},
  doi = {https://doi.org/10.1109/DICTA47822.2019.8946006}
}
</pre></td>
</tr>
<tr id="Lin2019" class="entry">
	<td>Lin, Y.-C., Cheng, Y.-T., Zhou, T., Ravi, R., Hasheminasab, S., Flatt, J., Troy, C. and Habib, A.</td>
	<td>Evaluation of UAV LiDAR for Mapping Coastal Environments <p class="infolinks">[<a href="javascript:toggleInfo('Lin2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lin2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Remote Sensing<br/>Vol. 11(24), pp. 2893&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/rs11242893">DOI</a> <a href="https://www.mdpi.com/2072-4292/11/24/2893">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Lin2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Unmanned Aerial Vehicle (UAV)-based remote sensing techniques have demonstrated great potential for monitoring rapid shoreline changes. With image-based approaches utilizing Structure from Motion (SfM), high-resolution Digital Surface Models (DSM), and orthophotos can be generated efficiently using UAV imagery. However, image-based mapping yields relatively poor results in low textured areas as compared to those from LiDAR. This study demonstrates the applicability of UAV LiDAR for mapping coastal environments. A custom-built UAV-based mobile mapping system is used to simultaneously collect LiDAR and imagery data. The quality of LiDAR, as well as image-based point clouds, are investigated and compared over different geomorphic environments in terms of their point density, relative and absolute accuracy, and area coverage. The results suggest that both UAV LiDAR and image-based techniques provide high-resolution and high-quality topographic data, and the point clouds generated by both techniques are compatible within a 5 to 10 cm range. UAV LiDAR has a clear advantage in terms of large and uniform ground coverage over different geomorphic environments, higher point density, and ability to penetrate through vegetation to capture points below the canopy. Furthermore, UAV LiDAR-based data acquisitions are assessed for their applicability in monitoring shoreline changes over two actively eroding sandy beaches along southern Lake Michigan, Dune Acres, and Beverly Shores, through repeated field surveys. The results indicate a considerable volume loss and ridge point retreat over an extended period of one year (May 2018 to May 2019) as well as a short storm-induced period of one month (November 2018 to December 2018). The foredune ridge recession ranges from 0 m to 9 m. The average volume loss at Dune Acres is 18.2 cubic meters per meter and 12.2 cubic meters per meter within the one-year period and storm-induced period, respectively, highlighting the importance of episodic events in coastline changes. The average volume loss at Beverly Shores is 2.8 cubic meters per meter and 2.6 cubic meters per meter within the survey period and storm-induced period, respectively.</td>
</tr>
<tr id="bib_Lin2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lin2019,
  author = {Lin, Yi-Chun and Cheng, Yi-Ting and Zhou, Tian and Ravi, Radhika and Hasheminasab, Seyyed and Flatt, John and Troy, Cary and Habib, Ayman},
  title = {Evaluation of UAV LiDAR for Mapping Coastal Environments},
  journal = {Remote Sensing},
  year = {2019},
  volume = {11},
  number = {24},
  pages = {2893},
  url = {https://www.mdpi.com/2072-4292/11/24/2893},
  doi = {https://doi.org/10.3390/rs11242893}
}
</pre></td>
</tr>
<tr id="Maiwald2019" class="entry">
	<td>Maiwald, F., Bruschke, J., Lehmann, C. and Niebling, F.</td>
	<td>A 4D information system for the exploration of multitemporal images and maps using photogrammetry, web technologies and VR/AR <p class="infolinks">[<a href="javascript:toggleInfo('Maiwald2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Maiwald2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Virtual Archaeology Review<br/>Vol. 10(21), pp. 1-13&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.4995/VAR.2019.11867">DOI</a> <a href="https://polipapers.upv.es/index.php/var/article/view/11867">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Maiwald2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This contribution shows the comparison, investigation, and implementation of different access strategies on multimodal data. The first part of the research is structured as a theoretical part opposing and explaining the terms of conventional access, virtual archival access, and virtual museums while additionally referencing related work. Especially, issues that still persist in repositories like the ambiguity or missing of metadata is pointed out. The second part explains the practical implementation of a workflow from a large image repository to various four-dimensional applications. Mainly, the filtering of images and in the following, the orientation of images is explained. Selection of the relevant images is partly done manually but also with the use of deep convolutional neural networks for image classification. In the following, photogrammetric methods are used for finding the relative orientation between image pairs in a projective frame. For this purpose, an adapted Structure from Motion (SfM) workflow is presented, in which the step of feature detection and matching is replaced by the Radiant-Invariant Feature Transform (RIFT) and Matching On Demand with View Synthesis (MODS). Both methods have been evaluated on a benchmark dataset and performed superior than other approaches. Subsequently, the oriented images are placed interactively and in the future automatically in a 4D browser application showing images, maps, and building models Further usage scenarios are presented in several Virtual Reality (VR) and Augmented Reality (AR) applications. The new representation of the archival data enables spatial and temporal browsing of repositories allowing the research of innovative perspectives and the uncovering of historical details.  Highlights:   Strategies for a completely automated workflow from image repositories to four-dimensional (4D) access approaches.  The orientation of historical images using adapted and evaluated feature matching methods.  4D access methods for historical images and 3D models using web technologies and Virtual Reality (VR)/Augmented Reality (AR).</td>
</tr>
<tr id="bib_Maiwald2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Maiwald2019,
  author = {Maiwald, Ferdinand and Bruschke, Jonas and Lehmann, Christoph and Niebling, Florian},
  title = {A 4D information system for the exploration of multitemporal images and maps using photogrammetry, web technologies and VR/AR},
  journal = {Virtual Archaeology Review},
  publisher = {Universitat Politecnica de Valencia},
  year = {2019},
  volume = {10},
  number = {21},
  pages = {1--13},
  url = {https://polipapers.upv.es/index.php/var/article/view/11867},
  doi = {https://doi.org/10.4995/VAR.2019.11867}
}
</pre></td>
</tr>
<tr id="NunesMasson2019" class="entry">
	<td>Nunes Masson, J.E. and Petry, M.R.</td>
	<td>Comparison of Algorithms for 3D Reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('NunesMasson2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('NunesMasson2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICARSC.2019.8733610">DOI</a> <a href="https://ieeexplore.ieee.org/document/8733610/">URL</a>&nbsp;</td>
</tr>
<tr id="rev_NunesMasson2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: with comparison</td>
</tr>
<tr id="bib_NunesMasson2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{NunesMasson2019,
  author = {Nunes Masson, Juliano Emir and Petry, Marcelo R.},
  title = {Comparison of Algorithms for 3D Reconstruction},
  booktitle = {Proceedings of the 2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)},
  publisher = {IEEE},
  year = {2019},
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/document/8733610/},
  doi = {https://doi.org/10.1109/ICARSC.2019.8733610}
}
</pre></td>
</tr>
<tr id="Palestini2019" class="entry">
	<td>Palestini, C. and Basso, A.</td>
	<td>Low Cost Technological Implementations Related To Integrated Application Experiments <p class="infolinks">[<a href="javascript:toggleInfo('Palestini2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Palestini2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLII-2/W17&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLII-2-W17-241-2019">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W17/241/2019/isprs-archives-XLII-2-W17-241-2019.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Palestini2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. Thanks to the development of new Cuda technologies applied to graphics cards and to a more accessible and growing use by professionals in various commercial, artistic and research sectors, the latest generation digital instruments have implemented new methods of photogrammetric surveying and remote sensing, progressively reducing the cost of the instruments and that related to the application development of the different SfM algorithms, now widely used also in numerous open source software. The research presented in the article compares two of the most recently used free programs with the most satisfactory results in the field of 3D photogrammetric survey and photomodelling: Meshroom, developed by AliceVision and Regard3D, an open source software, compiled in 2015 by the Swiss IT engineer freelance Roman Hiestand. The test case study will concern the photo-modelling, through the free tools previously discussed, of medium size complex decorative details, one of the monumental gates of the ancient Roman city of Sepino, an archaeological site in Molise (IT) located at the foot of the Matese and extending over the Tammaro valley, so as to be able to fully test the capture characteristics and the trend and structure of the pipeline of the two software examined.</td>
</tr>
<tr id="bib_Palestini2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Palestini2019,
  author = {Palestini, C. and Basso, A.},
  title = {Low Cost Technological Implementations Related To Integrated Application Experiments},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2019},
  volume = {XLII-2/W17},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W17/241/2019/isprs-archives-XLII-2-W17-241-2019.pdf},
  doi = {https://doi.org/10.5194/isprs-archives-XLII-2-W17-241-2019}
}
</pre></td>
</tr>
<tr id="Panagiotis2019" class="entry">
	<td>Panagiotis, P.</td>
	<td>Automated 3D facial landmarks localization for 4D dataset <p class="infolinks">[<a href="javascript:toggleInfo('Panagiotis2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>, pp. 77<i>School</i>: International Hellenic University&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://repository.ihu.edu.gr//xmlui/handle/11544/29528">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Panagiotis2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Panagiotis2019,
  author = {Panagiotis, Papaioannou},
  title = {Automated 3D facial landmarks localization for 4D dataset},
  school = {International Hellenic University},
  year = {2019},
  pages = {77},
  url = {https://repository.ihu.edu.gr//xmlui/handle/11544/29528}
}
</pre></td>
</tr>
<tr id="Pei2019" class="entry">
	<td>Pei, Z., Li, Y., Ma, M., Li, J., Leng, C., Zhang, X. and Zhang, Y.</td>
	<td>Occluded-Object 3D Reconstruction Using Camera Array Synthetic Aperture Imaging <p class="infolinks">[<a href="javascript:toggleInfo('Pei2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pei2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Sensors<br/>Vol. 19(3), pp. 607&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/s19030607">DOI</a> <a href="http://www.mdpi.com/1424-8220/19/3/607">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pei2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: With the three-dimensional (3D) coordinates of objects captured by a sequence of images taken in different views, object reconstruction is a technique which aims to recover the shape and appearance information of objects. Although great progress in object reconstruction has been made over the past few years, object reconstruction in occlusion situations remains a challenging problem. In this paper, we propose a novel method to reconstruct occluded objects based on synthetic aperture imaging. Unlike most existing methods, which either assume that there is no occlusion in the scene or remove the occlusion from the reconstructed result, our method uses the characteristics of synthetic aperture imaging that can effectively reduce the influence of occlusion to reconstruct the scene with occlusion. The proposed method labels occlusion pixels according to variance and reconstructs the 3D point cloud based on synthetic aperture imaging. Accuracies of the point cloud are tested by calculating the spatial difference between occlusion and non-occlusion conditions. The experiment results show that the proposed method can handle the occluded situation well and demonstrates a promising performance.</td>
</tr>
<tr id="bib_Pei2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pei2019,
  author = {Pei, Zhao and Li, Yawen and Ma, Miao and Li, Jun and Leng, Chengcai and Zhang, Xiaoqiang and Zhang, Yanning},
  title = {Occluded-Object 3D Reconstruction Using Camera Array Synthetic Aperture Imaging},
  journal = {Sensors},
  year = {2019},
  volume = {19},
  number = {3},
  pages = {607},
  url = {http://www.mdpi.com/1424-8220/19/3/607},
  doi = {https://doi.org/10.3390/s19030607}
}
</pre></td>
</tr>
<tr id="Perry2019" class="entry">
	<td>Perry, B.J.</td>
	<td>A Streamlined Bridge Inspection Framework Utilizing Unmanned Aerial Vehicles (UAVs) <p class="infolinks">[<a href="javascript:toggleInfo('Perry2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td><i>School</i>: Colorado State University&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://www.proquest.com/openview/942f3e212fc26a9b7cf078ca4deb97f0/1?cbl=18750&diss=y&pq-origsite=gscholar">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Perry2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Perry2019,
  author = {Perry, Brandon J.},
  title = {A Streamlined Bridge Inspection Framework Utilizing Unmanned Aerial Vehicles (UAVs)},
  school = {Colorado State University},
  year = {2019},
  url = {https://www.proquest.com/openview/942f3e212fc26a9b7cf078ca4deb97f0/1?cbl=18750&amp;diss=y&amp;pq-origsite=gscholar}
}
</pre></td>
</tr>
<tr id="Pietroszek2019" class="entry">
	<td>Pietroszek, K. and Moore, C.</td>
	<td>AHMED: Toolset for Ad-Hoc Mixed-reality Exhibition Design <p class="infolinks">[<a href="javascript:toggleInfo('Pietroszek2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology, pp. 1-2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3359996.3364729">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3359996.3364729">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Pietroszek2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pietroszek2019,
  author = {Pietroszek, Krzysztof and Moore, Carl},
  title = {AHMED: Toolset for Ad-Hoc Mixed-reality Exhibition Design},
  booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
  publisher = {ACM},
  year = {2019},
  pages = {1--2},
  url = {https://dl.acm.org/doi/10.1145/3359996.3364729},
  doi = {https://doi.org/10.1145/3359996.3364729}
}
</pre></td>
</tr>
<tr id="Pietroszek2019a" class="entry">
	<td>Pietroszek, K.</td>
	<td>Mixed-Reality Exhibition for Museum of Peace Corps Experiences using AHMED toolset <p class="infolinks">[<a href="javascript:toggleInfo('Pietroszek2019a','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>Proceedings of the Symposium on Spatial User Interaction, pp. 1-2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3357251.3358754">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3357251.3358754">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Pietroszek2019a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pietroszek2019a,
  author = {Pietroszek, Krzysztof},
  title = {Mixed-Reality Exhibition for Museum of Peace Corps Experiences using AHMED toolset},
  booktitle = {Proceedings of the Symposium on Spatial User Interaction},
  publisher = {ACM},
  year = {2019},
  pages = {1--2},
  url = {https://dl.acm.org/doi/10.1145/3357251.3358754},
  doi = {https://doi.org/10.1145/3357251.3358754}
}
</pre></td>
</tr>
<tr id="Potabatti2019" class="entry">
	<td>Potabatti, N.S.</td>
	<td>Photogrammetry for 3D Reconstruction in SOLIDWORKS and its Applications in Industry <p class="infolinks">[<a href="javascript:toggleInfo('Potabatti2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('Potabatti2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>, pp. 134<i>School</i>: Purdue University&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://scholarworks.iupui.edu/handle/1805/19992">URL</a>&nbsp;</td>
</tr>
<tr id="rev_Potabatti2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Includes Alicevision Plugin for Solidworks</td>
</tr>
<tr id="bib_Potabatti2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Potabatti2019,
  author = {Potabatti, Nikhil S.},
  title = {Photogrammetry for 3D Reconstruction in SOLIDWORKS and its Applications in Industry},
  school = {Purdue University},
  year = {2019},
  pages = {134},
  url = {https://scholarworks.iupui.edu/handle/1805/19992}
}
</pre></td>
</tr>
<tr id="Shrestha2019" class="entry">
	<td>Shrestha, U.</td>
	<td>Structure from Motion applied to movable bed scale models <p class="infolinks">[<a href="javascript:toggleInfo('Shrestha2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>, pp. 69<i>School</i>: Norwegian University of Science and Technology&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="file:///home/simone/Downloads/no.ntnu_inspera_43469946_25755829.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Shrestha2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Shrestha2019,
  author = {Shrestha, Ujjwal},
  title = {Structure from Motion applied to movable bed scale models},
  school = {Norwegian University of Science and Technology},
  year = {2019},
  pages = {69},
  url = {file:///home/simone/Downloads/no.ntnu_inspera_43469946_25755829.pdf}
}
</pre></td>
</tr>
<tr id="Stathopoulou2019" class="entry">
	<td>Stathopoulou, E.-K., Welponer, M. and Remondino, F.</td>
	<td>Open-Source Image Based 3 D Reconstruction Pipelines: Review, Comparison And Evaluation <p class="infolinks">[<a href="javascript:toggleInfo('Stathopoulou2019','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Stathopoulou2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLII-2/W17, pp. 331-338&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLII-2-W17-331-2019">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W17/331/2019/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Stathopoulou2019" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. State-of-the-art automated image orientation (Structure from Motion) and dense image matching (Multiple View Stereo) methods commonly used to produce 3D information from 2D images can generate 3D results – such as point cloud or meshes – of varying geometric and visual quality. Pipelines are generally robust and reliable enough, mostly capable to process even large sets of unordered images, yet the final results often lack completeness and accuracy, especially while dealing with real-world cases where objects are typically characterized by complex geometries and textureless surfaces and obstacles or occluded areas may also occur. In this study we investigate three of the available commonly used open-source solutions, namely COLMAP, OpenMVG+OpenMVS and AliceVision, evaluating their results under diverse large scale scenarios. Comparisons and critical evaluation on the image orientation and dense point cloud generation algorithms is performed with respect to the corresponding ground truth data. The presented FBK-3DOM datasets are available for research purposes.</td>
</tr>
<tr id="bib_Stathopoulou2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Stathopoulou2019,
  author = {Stathopoulou, E.-K. and Welponer, M. and Remondino, F.},
  title = {Open-Source Image Based 3 D Reconstruction Pipelines: Review, Comparison And Evaluation},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2019},
  volume = {XLII-2/W17},
  pages = {331--338},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2-W17/331/2019/},
  doi = {https://doi.org/10.5194/isprs-archives-XLII-2-W17-331-2019}
}
</pre></td>
</tr>
<tr id="Weil2019" class="entry">
	<td>Weil, L., Kolb, D., Weismüller, J., Imm, E. and Kranzlmüller, D.</td>
	<td>Raising Awareness for Endangered Species using Augmented Reality <p class="infolinks">[<a href="javascript:toggleInfo('Weil2019','comment')">Comment</a>] [<a href="javascript:toggleInfo('Weil2019','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://www.researchgate.net/profile/Daniel_Kolb4/publication/341151490_Raising_Awareness_for_Endangered_Species_using_Augmented_Reality/links/5eb1331d45851592d6b97e9f/Raising-Awareness-for-Endangered-Species-using-Augmented-Reality.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="rev_Weil2019" class="comment noshow">
	<td colspan="6"><b>Comment</b>: 3D reconstruction of animals, short use case</td>
</tr>
<tr id="bib_Weil2019" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Weil2019,
  author = {Weil, Lea and Kolb, Daniel and Weismüller, Jens and Imm, Eric and Kranzlmüller, Dieter},
  title = {Raising Awareness for Endangered Species using Augmented Reality},
  year = {2019},
  url = {https://www.researchgate.net/profile/Daniel_Kolb4/publication/341151490_Raising_Awareness_for_Endangered_Species_using_Augmented_Reality/links/5eb1331d45851592d6b97e9f/Raising-Awareness-for-Endangered-Species-using-Augmented-Reality.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Hofmann, G.</td>
	<td>Meshroom – Open-Source-Photogrammetrie auf einen Klick <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://download.digitalproduction.com/Kostenlose%20PDFs%202019/DP1806_AliceVision_Meshroom.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: There are now countless solutions for photogrammetry or 3D scanning, i.e. the creation of three-dimensional objects from a series of photos. Some of them are open source and more or less complex to use. With Meshroom, a new player has appeared that shines with simple one-click operation and works under both Windows and Linux. Thanks to caching and a node-based operating concept, however, there are still possibilities to intervene.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Digital Production print publication for digital artists with interview and tutorial</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Gottfried Hofmann},
  title = {Meshroom – Open-Source-Photogrammetrie auf einen Klick},
  year = {2019},
  url = {https://download.digitalproduction.com/Kostenlose%20PDFs%202019/DP1806_AliceVision_Meshroom.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Montes, J.E.C.</td>
	<td>REPRESENTACIÓN AUTOMÁTICA EN 3D DE BAJO COSTE PARA INSPECCIÓN VISUAL DE COMPONENTES AERONÁUTICOS INSTALADOS EN ALA CON ACCESO LIMITADO <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://ciateq.repositorioinstitucional.mx/jspui/bitstream/1020/365/1/CorbalMontesJoseE%20MSIM%202019.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In  the  aeronautical  sector,  different  non-destructive  tests  are  carried  out  to  determine the  health  status  of  aircraft  components.  These  tests  are  performed  to  determine  the number of hours the aircraft can continue flying with that component or if any immediate maintenance is necessary. Due to it is desired to keep the aircraft in operation as many hours as possible, it is wanted to  carry out  the biggest  number of tests without disassembling the engine from the aircraft, as this task is time-consuming. Although the borescope inspection can reach zones with limited access, sometimes components are blocking  some  zones,  making  difficult  the  access  if  all  parts  are  assembled.  This  study consists  of  the  optimization  of  inspection  tests  through  the  capture,  analysis,  and representation  of  a  3D  model  of  the  combustion  chamber  of  an  aircraft.  Two  possible configurations  for  image  acquisition  were  analyzed:  a  single  rotating  camera  with panoramic image capture and four cameras installed at 90° of separation. In the case of the configuration with four cameras, Python scripts were used using image processing libraries  for  the  creation  of  a  panoramic  image  representing  the  system.  The  results obtained  are  quite  similar  to  the  reality  in  both  cases  and  can  be  used  by  a  trained inspector to determine the condition of the component. However, the configuration with different cameras showed a loss of 7% of the pixels compared to the first configuration. It is necessary to properly calibrate the distance to move the inspector robot to obtain the information of the whole scenario.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: PDF Page 41 - Meshroom comparison with other software</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {José Eduardo Corbal Montes},
  title = {REPRESENTACIÓN AUTOMÁTICA EN 3D DE BAJO COSTE PARA INSPECCIÓN VISUAL DE COMPONENTES AERONÁUTICOS INSTALADOS EN ALA CON ACCESO LIMITADO},
  year = {2019},
  url = {https://ciateq.repositorioinstitucional.mx/jspui/bitstream/1020/365/1/CorbalMontesJoseE%20MSIM%202019.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>v4design.eu</td>
	<td>V4Design Visual and textual content re-purposing FOR(4) architecture, Design and virtual reality games <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://v4design.eu/wp-content/uploads/2019/07/D4.3_V4Design_v1.5.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This  deliverable  represents  the  first  iteration  of  3D  reconstruction  and  scientific  report 
<br>describing  and  showing  the  SoA  methods  for  image  sequence  analysis,  and  3D  sparse  and 
<br>dense reconstruction.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: In-depth comparison of software tools and libraries page 42</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {v4design.eu},
  title = {V4Design Visual and textual content re-purposing FOR(4) architecture, Design and virtual reality games},
  year = {2019},
  url = {https://v4design.eu/wp-content/uploads/2019/07/D4.3_V4Design_v1.5.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Granier, X., Chayani, M., Abergel, V., Benistant, P., Bergerot, L., Bohbot, H., Cassen, S., de Luca, L., Dutailly, B., Epaud, F. and et al.</td>
	<td>Les recommandations du Consortium 3D SHS - Les recommandations du consortium 3D SHS <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://hal.archives-ouvertes.fr/hal-01683842/file/Les%20recommandations%20du%20consortium%203D%20SHS.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Software comparison list</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Xavier Granier, Mehdi Chayani, Violette Abergel, Pascal Benistant, Laurent Bergerot, Hervé Bohbot, Serge Cassen, Livio de Luca, Bruno Dutailly, Fréderic Epaud, et al.},
  title = {Les recommandations du Consortium 3D SHS - Les recommandations du consortium 3D SHS},
  year = {2019},
  url = {https://hal.archives-ouvertes.fr/hal-01683842/file/Les%20recommandations%20du%20consortium%203D%20SHS.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Bernardin, A., Duriez, C. and Marchal, M.</td>
	<td>An Interactive Physically-based Model for Active Suction Phenomenon Simulation - SWS19 <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://hal.inria.fr/hal-02419381/document">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Antonin Bernardin, Christian Duriez, Maud Marchal},
  title = {An Interactive Physically-based Model for Active Suction Phenomenon Simulation - SWS19},
  year = {2019},
  url = {https://hal.inria.fr/hal-02419381/document}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Hengjia Li, ChuongNguyen.</td>
	<td>Perspective-consistent multifocus multiview 3D reconstruction of small objects <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://arxiv.org/pdf/1912.03005.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: short mention, usage example</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Hengjia Li, Chuong Nguyen},
  title = {Perspective-consistent multifocus multiview 3D reconstruction of small objects},
  year = {2019},
  url = {https://arxiv.org/pdf/1912.03005.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td></td>
	<td>SIFT in CUDA In the Horizon 2020 projects POPART and LADIO <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.uio.no/studier/emner/matnat/ifi/IN5050/v19/undervisningsmateriale/in5050-popsift.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: popsift presentation</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,,
  title = {SIFT in CUDA In the Horizon 2020 projects POPART and LADIO},
  year = {2019},
  url = {https://www.uio.no/studier/emner/matnat/ifi/IN5050/v19/undervisningsmateriale/in5050-popsift.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Emanuele, P.</td>
	<td>Utilizzo di asset 3D per la produzione videonel campo del cultural heritageDal reperto alla divulgazione scientifica <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://webthesis.biblio.polito.it/13119/1/tesi.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Plicato Emanuele},
  title = {Utilizzo di asset 3D per la produzione videonel campo del cultural heritageDal reperto alla divulgazione scientifica},
  year = {2019},
  url = {https://webthesis.biblio.polito.it/13119/1/tesi.pdf}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>de Dinechin, M.D.</td>
	<td>Lightning Talks Blender Conference <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://youtu.be/o4BTL_tLzcs?t=3895">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: 3D reconstruction in Meshroom to generate real world reference for an art project</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Matthieu Dupont de Dinechin},
  title = {Lightning Talks Blender Conference},
  year = {2019},
  url = {https://youtu.be/o4BTL_tLzcs?t=3895}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Covrett, A.</td>
	<td>NAB Show 2019 | Maxon Cinema 4D <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=0f1LLlpTVj8&t=2365">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Meshroom in C4D pipeline</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Aaron Covrett},
  title = {NAB Show 2019 | Maxon Cinema 4D},
  year = {2019},
  url = {https://www.youtube.com/watch?v=0f1LLlpTVj8&amp;t=2365}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>HIDEKATSU</td>
	<td>[【フォトグラメトリ】3DF ZephrとRealityCapture、MESHROOMを使ってみる] <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=vDjQVBm7HYI">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Interesting reconstruction comparison with difficult car reconstruction (high reflection)</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {HIDEKATSU},
  title = {[【フォトグラメトリ】3DF ZephrとRealityCapture、MESHROOMを使ってみる]},
  year = {2019},
  url = {https://www.youtube.com/watch?v=vDjQVBm7HYI}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Abonnenten, T.N.</td>
	<td>Photogrammetry tests with Meshroom 2019 <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=JHWf1KjI3J0">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Meshroom Showcase</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Todor Nikolov81 Abonnenten},
  title = {Photogrammetry tests with Meshroom 2019},
  year = {2019},
  url = {https://www.youtube.com/watch?v=JHWf1KjI3J0}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Moviola</td>
	<td>Meshroom Tutorial Guide <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=eiEaHLNJJ94">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Meshroom is a powerful open-source tool for creating digital replicas of your film set, complete with tracked camera. Move beyond simple camera tracking with geometry of your entire scene, ready to receive shadows, line up CG objects, add defocus effects, and visualize your entire scene in your favorite 3D environment.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Presentation of the Meshroom software with a focus on using it for Match Moving.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Moviola},
  title = {Meshroom Tutorial Guide},
  year = {2019},
  url = {https://www.youtube.com/watch?v=eiEaHLNJJ94}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>eleccelerator.com</td>
	<td>Outdoor Photogrammetry Adventures <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://eleccelerator.com/outdoor-photogrammetry-adventures/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {eleccelerator.com},
  title = {Outdoor Photogrammetry Adventures},
  year = {2019},
  url = {https://eleccelerator.com/outdoor-photogrammetry-adventures/}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>VFXforFilmmakers.com</td>
	<td>The Pipeline: Episode 2- Location Photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=Ezf1NFVE93Y">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this lesson we build out our photogrammetry with meshroom and maya. Between this lesson and next I will do a build out of the scene. You are welcome to join along in the process by downloading the assets on the vfxforfilmmakers.com website.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {VFXforFilmmakers.com},
  title = {The Pipeline: Episode 2- Location Photogrammetry},
  year = {2019},
  url = {https://www.youtube.com/watch?v=Ezf1NFVE93Y}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Crosslink</td>
	<td>Photogrammetry - Using a turntable for 3D scanning <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=nWh51Ipp5Sc">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this video, I am showing you my experiences with using a turntable for photogrammetry, what worked, what not and what tweaks I had to make to get the perfect result. The software I used for this is Meshroom, which is easy to use and free to download.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Crosslink},
  title = {Photogrammetry - Using a turntable for 3D scanning},
  year = {2019},
  url = {https://www.youtube.com/watch?v=nWh51Ipp5Sc}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Skiba, D.</td>
	<td>Реконструкция 3D-объекта по фото в программе MeshroomО программе <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>blog&nbsp;</td>
	<td>misc</td>
	<td><a href="http://mapper720.ru/tutorials/meshroom.html">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Denis Skiba},
  title = {Реконструкция 3D-объекта по фото в программе MeshroomО программе},
  year = {2019},
  url = {http://mapper720.ru/tutorials/meshroom.html}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Paul, BN</td>
	<td>PHOTOGRAMMÉTRIE AVEC MESHROOM : DEVIENS UN PRO <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=nMUM3NQmFgA">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Paul BN},
  title = {PHOTOGRAMMÉTRIE AVEC MESHROOM : DEVIENS UN PRO},
  year = {2019},
  url = {https://www.youtube.com/watch?v=nMUM3NQmFgA}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Serino, T.</td>
	<td>3D Photo Scanning Tutorial | Blender 2.8 | Meshroom | Instant Meshes <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=kGBhM3-W7ic">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this video, I go step by step through the process I use to create 3D models/assets via photographs. This is known as photo scanning or photogrammetry. In this tutorial, I will go through the entire workflow of scanning an object, retopologizing the object, and baking the high poly detail to the retopologized model. All of this will be done with completely free software such as Meshroom, Instantmeshes and Blender 2.8.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Tyler Serino},
  title = {3D Photo Scanning Tutorial | Blender 2.8 | Meshroom | Instant Meshes},
  year = {2019},
  url = {https://www.youtube.com/watch?v=kGBhM3-W7ic}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Schubert, J.</td>
	<td>Behind the Scenes: 3D Castle Set Extension <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>blog&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.blendernation.com/2019/11/20/behind-the-scenes-3d-castle-set-extension/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Jasper Schubert},
  title = {Behind the Scenes: 3D Castle Set Extension},
  year = {2019},
  url = {https://www.blendernation.com/2019/11/20/behind-the-scenes-3d-castle-set-extension/}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Flynt, J.</td>
	<td>6 Best Photogrammetry Software Programs in 2019 <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>blog&nbsp;</td>
	<td>misc</td>
	<td><a href="https://3dinsider.com/photogrammetry-software/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this article, we take a look at the best paid and free software platforms that you could use to help you get started with drone-based mapping using photogrammetry.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Joseph Flynt},
  title = {6 Best Photogrammetry Software Programs in 2019},
  year = {2019},
  url = {https://3dinsider.com/photogrammetry-software/}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Desbonnet, J.</td>
	<td>Experiments with Meshroom / AliceVision: Galway Cathedral <p class="infolinks">[<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=u6HjcqaBZG8">URL</a>&nbsp;</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Joe Desbonnet},
  title = {Experiments with Meshroom / AliceVision: Galway Cathedral},
  year = {2019},
  url = {https://www.youtube.com/watch?v=u6HjcqaBZG8}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Bot, J.A. and Irschick, D.J.</td>
	<td>Using 3D Photogrammetry to Create Open-Access Models of Live Animals: 2D and 3D Software Solutions <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2019</td>
	<td>3D/VR in the Academic Library:Emerging Practices and Trends&nbsp;</td>
	<td>article</td>
	<td><a href="https://www.clir.org/wp-content/uploads/sites/6/2019/02/Pub-176.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Novel technological solutions emerging over the past five years have 
<br>made it possible to consider previously unheard of re-creations of the world as it exists in its stunning, full-color, 3D topography. The potential value of the rendering of real animals for science, conser-vation, education, and story-telling is substantial. For scientists, 3D models of live animals provide valuable data for testing theories on body shape and movement, and they represent “avatars” of actual specimens for further analysis. For conservationists, the ability to use novel technological solutions such as virtual reality (VR), augmented reality (AR), or gaming applications to present real-life animals opens new doors for reaching the public. For educators, the ability 
<br>to tell stories around a specific animal, instead of a generic animal, is significant. Drawing on our work with the Digital Life Project, we 
<br>describe our process for using open-source software to recreate liv-ing animals in 3D, from photocapture to animation.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{,
  author = {Jeremy A. Bot ; Duncan J. Irschick},
  title = {Using 3D Photogrammetry to Create Open-Access Models of Live Animals: 2D and 3D Software Solutions},
  journal = {3D/VR in the Academic Library:Emerging Practices and Trends},
  year = {2019},
  url = {https://www.clir.org/wp-content/uploads/sites/6/2019/02/Pub-176.pdf}
}
</pre></td>
</tr>
<tr id="2020" class="entry">
	<td></td>
	<td>Mikros, CG Wire et Creative seeds évoquent leur vision de l'open source <p class="infolinks">[<a href="javascript:toggleInfo('2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>3DVF&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.3dvf.com/mikros-cg-wire-et-creative-seeds-evoquent-leur-vision-de-lopen-source/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: En février dernier se tenait Made By Mikros, une journée au cours de laquelle le studio avait organisé, à l’invitation de Rennes Métropole et de l’association Clair-Obscur (dans le cadre du festival de cinéma Travelling) une série de conférences professionnelles dans les locaux de sa maison mère Technicolor. Nous vous...</td>
</tr>
<tr id="rev_2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Short official Meshroom conference presentation video</td>
</tr>
<tr id="bib_2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{2020,,
  title = {Mikros, CG Wire et Creative seeds évoquent leur vision de l'open source},
  journal = {3DVF},
  year = {2020},
  url = {https://www.3dvf.com/mikros-cg-wire-et-creative-seeds-evoquent-leur-vision-de-lopen-source/}
}
</pre></td>
</tr>
<tr id="Aguilera2020" class="entry">
	<td>Aguilera, J.A.F.</td>
	<td>Immersive Experience in Viewing 3D Reconstruction Model in Virtual Reality <p class="infolinks">[<a href="javascript:toggleInfo('Aguilera2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: California State University&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Aguilera2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Aguilera2020,
  author = {Aguilera, Jose Alberto Fonseca},
  title = {Immersive Experience in Viewing 3D Reconstruction Model in Virtual Reality},
  school = {California State University},
  year = {2020}
}
</pre></td>
</tr>
<tr id="article" class="entry">
	<td>Irschick, D., Bot, J., Brooks, A., Bresette, M., Gutierrez, R., Manire, C., Merigo, C., Wyneken, J., Martin, J. and Pereira, M.</td>
	<td>Creating 3D Models of Several Sea Turtle Species as Digital Voucher Specimens <p class="infolinks">[<a href="javascript:toggleInfo('article','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Herpetological Review<br/>Vol. 51, pp. 709-715&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_article" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{article,
  author = {Irschick, Duncan and Bot, Jeremy and Brooks, Annabelle and Bresette, Michael and Gutierrez, Robert and Manire, Charles and Merigo, Connie and Wyneken, Jeanette and Martin, Johnson and Pereira, Michael},
  title = {Creating 3D Models of Several Sea Turtle Species as Digital Voucher Specimens},
  journal = {Herpetological Review},
  year = {2020},
  volume = {51},
  pages = {709--715}
}
</pre></td>
</tr>
<tr id="ArulDoss2020" class="entry">
	<td>Arul Doss, A.C.</td>
	<td>Predicting Desired Temporal Waypoints from Camera and Route Planner Images using End-To-Mid Imitation Learning <p class="infolinks">[<a href="javascript:toggleInfo('ArulDoss2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: Ohio State University&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://etd.ohiolink.edu/apexprod/rws_olink/r/1501/10?clear=10&p10_accession_num=osu1588697131094167">URL</a>&nbsp;</td>
</tr>
<tr id="bib_ArulDoss2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{ArulDoss2020,
  author = {Arul Doss, Aravind Chandradoss},
  title = {Predicting Desired Temporal Waypoints from Camera and Route Planner Images using End-To-Mid Imitation Learning},
  school = {Ohio State University},
  year = {2020},
  url = {https://etd.ohiolink.edu/apexprod/rws_olink/r/1501/10?clear=10&amp;p10_accession_num=osu1588697131094167}
}
</pre></td>
</tr>
<tr id="Balba2020" class="entry">
	<td>Balba, I.</td>
	<td>Passive Tomography: Tools for extracting three-dimensional information from monocular video <p class="infolinks">[<a href="javascript:toggleInfo('Balba2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 108<i>School</i>: Politecnico di Torino&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Balba2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Balba2020,
  author = {Balba, Ilaria},
  title = {Passive Tomography: Tools for extracting three-dimensional information from monocular video},
  school = {Politecnico di Torino},
  year = {2020},
  pages = {108}
}
</pre></td>
</tr>
<tr id="Balcita2020" class="entry">
	<td>Balcita, R.E. and Palaoag, T.D.</td>
	<td>Assisting Students Learning Experiences Using an Augmented Reality Model Framework <p class="infolinks">[<a href="javascript:toggleInfo('Balcita2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Balcita2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>International Journal of Learning and Teaching, pp. 146-151&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.18178/ijlt.6.3.146-151">DOI</a> <a href="http://www.ijlt.org/index.php?m=content&c=index&a=show&catid=148&id=778">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Balcita2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In learning through experience there are so many techniques that can be used in order to learn and master skills. Strategies used for learning may be in the form of presentation, multimedia, simulation or hands-on. Others might prefer combination of strategies both being able to hear and/or see the actual or real object of machines, tools or equipment. There are advanced visual technologies available in the internet to choose from but most are not designed to the learning process in a school. Augmented reality is an emerging advance technology that shows a lot of use and opportunity as a tool for learning and enhancing experience. AR can simulate real objects into models that be used for education. This study aims to experiment on an AR engine created using the AR model framework to enhance the learning experiences of students in the different learning strategies used in this study. The experiment is focused to find the significant differences of not having and having an AR model into the learning/teaching strategy. To analyze the data frequency, statistical mode is used to find the most frequent response to interpret the nominal and ordinal categories of the variables. The results of using the AR model framework significantly improved the learning experiences of the participants.</td>
</tr>
<tr id="bib_Balcita2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Balcita2020,
  author = {Balcita, Rommel E. and Palaoag, Thelma D.},
  title = {Assisting Students Learning Experiences Using an Augmented Reality Model Framework},
  journal = {International Journal of Learning and Teaching},
  year = {2020},
  pages = {146--151},
  url = {http://www.ijlt.org/index.php?m=content&amp;c=index&amp;a=show&amp;catid=148&amp;id=778},
  doi = {https://doi.org/10.18178/ijlt.6.3.146-151}
}
</pre></td>
</tr>
<tr id="Basista2020" class="entry">
	<td>Basista, A. and Karnicki, R.</td>
	<td>Photogrammetric reconstruction software as a cost-efficient support tool in conservation research <p class="infolinks">[<a href="javascript:toggleInfo('Basista2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Basista2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Technical Transactions., pp. 1-13&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.37705/TechTrans/e2020021">DOI</a> <a href="http://orcid.org/0000-0002-0755-4044">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Basista2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A crucial activity in architectural and archaeological conservation research is the process of synthesising information in which the researcher records collected field data in the form of a planar drawing. This labour-intensive stage is significantly improved by automated systems which support the measurement work. Some of these are programs that convert sets of photographs into virtual and spatial models. The author compares the reasonably priced software options, shares the experience which was gathered during their use and presents the results of the research. The paper also presents the economic aspect and practical examples and highlights the development potential of these tools.</td>
</tr>
<tr id="bib_Basista2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Basista2020,
  author = {Basista, Anna and Karnicki, Rafa&lstrok;},
  title = {Photogrammetric reconstruction software as a cost-efficient support tool in conservation research},
  journal = {Technical Transactions.},
  year = {2020},
  pages = {1--13},
  url = {http://orcid.org/0000-0002-0755-4044},
  doi = {https://doi.org/10.37705/TechTrans/e2020021}
}
</pre></td>
</tr>
<tr id="Bassier2020" class="entry">
	<td>Bassier, M., Bonduel, M., Derdaele, J. and Vergauwen, M.</td>
	<td>Processing existing building geometry for reuse as Linked Data <p class="infolinks">[<a href="javascript:toggleInfo('Bassier2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Automation in Construction<br/>Vol. 115, pp. 103180&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.autcon.2020.103180">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0926580519308234">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Bassier2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bassier2020,
  author = {Bassier, Maarten and Bonduel, Mathias and Derdaele, Jens and Vergauwen, Maarten},
  title = {Processing existing building geometry for reuse as Linked Data},
  journal = {Automation in Construction},
  year = {2020},
  volume = {115},
  pages = {103180},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0926580519308234},
  doi = {https://doi.org/10.1016/j.autcon.2020.103180}
}
</pre></td>
</tr>
<tr id="Bici_2020" class="entry">
	<td>Bici, M., Gherardini, F., Campana, F. and Leali, F.</td>
	<td>A preliminary approach on point cloud reconstruction of bronze statues through oriented photogrammetry: the &ldquo;Principe Ellenistico&rdquo; case <p class="infolinks">[<a href="javascript:toggleInfo('Bici_2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bici_2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>IOP Conference Series: Materials Science and Engineering<br/>Vol. 949, pp. 12117&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1088/1757-899x/949/1/012117">DOI</a> <a href="https://doi.org/10.1088/1757-899x/949/1/012117">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bici_2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Close-Range Photogrammetry is a widespread and efficient technique in the 3D acquisition of artefacts, particularly in fields like Cultural Heritage. Despite this wide usage, also due to a convenient quality/cost ratio, it shows some limitations due to light conditions as well as the artefact surface finishing. In this paper, we would like to report the assessment of a photogrammetry approach to 3D capture metal reflective surfaces, such as bronze, which is a widely used material in ancient statues. To this aim, we propose a photogrammetry workflow based on systematic steps capable of overcome some of the main issues of reflective surfaces. To validate this approach, the developed 3D model is compared to a more accurate model of the same artefact, obtained with a 3D scanner. As a case study, we selected the Principe Ellenistico, an ancient bronze statue conserved in the Museo Nazionale Romano (Rome, Italy), of which a photogrammetric model is firstly developed and then compared to the scanned one.</td>
</tr>
<tr id="bib_Bici_2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bici_2020,
  author = {Bici, M and Gherardini, F and Campana, F and Leali, F},
  title = {A preliminary approach on point cloud reconstruction of bronze statues through oriented photogrammetry: the &ldquo;Principe Ellenistico&rdquo; case},
  journal = {IOP Conference Series: Materials Science and Engineering},
  publisher = {IOP Publishing},
  year = {2020},
  volume = {949},
  pages = {12117},
  url = {https://doi.org/10.1088/1757-899x/949/1/012117},
  doi = {https://doi.org/10.1088/1757-899x/949/1/012117}
}
</pre></td>
</tr>
<tr id="Bolsee2020" class="entry">
	<td>Bolsee, Q., Darwish, W., Bonatto, D., Lafruit, G. and Munteanu, A.</td>
	<td>A Device for Capturing Inward-Looking Spherical Light Fields <p class="infolinks">[<a href="javascript:toggleInfo('Bolsee2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the International Conference on 3D Immersion (IC3D), pp. 1-5&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/IC3D51119.2020.9376346">DOI</a> <a href="https://ieeexplore.ieee.org/document/9376346/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Bolsee2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Bolsee2020,
  author = {Bolsee, Quentin and Darwish, Walid and Bonatto, Daniele and Lafruit, Gauthier and Munteanu, Adrian},
  title = {A Device for Capturing Inward-Looking Spherical Light Fields},
  booktitle = {Proceedings of the International Conference on 3D Immersion (IC3D)},
  publisher = {IEEE},
  year = {2020},
  pages = {1--5},
  url = {https://ieeexplore.ieee.org/document/9376346/},
  doi = {https://doi.org/10.1109/IC3D51119.2020.9376346}
}
</pre></td>
</tr>
<tr id="Borrero2020" class="entry">
	<td>Borrero, M. and Stroth, L.R.</td>
	<td>A Proposal for the Standardized Reporting of Error and Paradata Regarding Structure from Motion (SfM) 3D Models Used in Recording and Consolidating Archaeological Architecture <p class="infolinks">[<a href="javascript:toggleInfo('Borrero2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Borrero2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Advances in Archaeological Practice<br/>Vol. 8(4), pp. 376-388&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1017/aap.2020.11">DOI</a> <a href="https://www.cambridge.org/core/product/identifier/S232637682000011X/type/journal_article">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Borrero2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In the past decade, archaeologists have increasingly made use of photogrammetry, the process of creating 3D models from photographs, in a variety of field and lab settings. We argue that we must, as a discipline, develop a consistent methodology to ensure that 3D models are held to a consistent standard, including not only photographic protocol but also the documentation of model accuracy using an agreed-upon measure. To help develop this discussion, we present our system for incorporating photogrammetry into the documentation of architecture. This technique was developed at the site of Nim Li Punit, Belize, in 2018. Excavating architecture involves documenting the pre-excavated building, liberating overburden, documenting all in situ construction (including wall fall, fill stones, and standing architecture), drawing consolidated architecture, and documenting the final state of the post-excavated buildings. The generation of 3D models greatly assisted in all facets of the excavation, documentation, analysis, and consolidation processes. To ensure that our models were accurate, we documented the reprojection error and final model horizontal distortion to assess the quality of the model. We suggest that documenting both forms of error should become standard practice in any discussion of archaeological applications of photogrammetry.</td>
</tr>
<tr id="bib_Borrero2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Borrero2020,
  author = {Borrero, Mario and Stroth, Luke R.},
  title = {A Proposal for the Standardized Reporting of Error and Paradata Regarding Structure from Motion (SfM) 3D Models Used in Recording and Consolidating Archaeological Architecture},
  journal = {Advances in Archaeological Practice},
  year = {2020},
  volume = {8},
  number = {4},
  pages = {376--388},
  url = {https://www.cambridge.org/core/product/identifier/S232637682000011X/type/journal_article},
  doi = {https://doi.org/10.1017/aap.2020.11}
}
</pre></td>
</tr>
<tr id="Campbell2020" class="entry">
	<td>Campbell, O.</td>
	<td>Microstructures and deformation mechanisms from ballistic impacts in stone <p class="infolinks">[<a href="javascript:toggleInfo('Campbell2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Campbell2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('Campbell2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Cardiff University Cardiff School of Earth and Environmental Sciences&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.findaphd.com/phds/project/microstructures-and-deformation-mechanisms-from-ballistic-impacts-in-stone/?p94906">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Campbell2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: An increasingly aggressive approach to heritage as a commodity and a target in conflict has caused growing concern in the international community. In addition to increased incidents of looting, used to raise funds for hostile activities, numerous sites have been deliberately damaged and destroyed. Recent examples of these are the destruction of Palmyra, Mosul and the Great Mosque of al-Nuri. This destruction is not limited to the ongoing conflict in Syria and Iraq; for example widespread damage in Yemen and Mali has been largely unreported, yet is creating untold harm to cultural heritage.
<br>In the light of this targeted destruction it is now more important than ever to conserve, stabilise and restore heritage in these regions as soon as and wherever possible. As part of the preparation for peace efforts, a swift response methodology needs to be established to assess and monitor damaged heritage, optimise the use of resources, and identify those sites that could be salvaged if remediation methods are allocated efficiently and in a timely manner. However, it is not possible to effectively conserve heritage caught in contemporary conflict without a sound understanding of the damage mechanisms, and their long-term consequences for site stability.
<br>Project Aims and Methods
<br>To address this issue, a Leverhulme-funded full studentship is offered at Cardiff University in collaboration with UWE Bristol. The student will use controlled ballistic tests to quantify instantaneous meso- and microscopic damage in stone at the time of impact, as a function of variables including stone type, ballistic calibre, and angle and distance of shot. Samples will be generated by ballistics tests at the Cranfield Ordnance Test &amp; Evaluation Centre (COTEC), in order to quantify meso- and microscopic damage from rifle bullets and determine the parameters controlling the extent of damage and the underlying deformation mechanisms.
<br>Candidate and Eligibility
<br>The ideal candidate for this competitive position will have a sound knowledge of petrology and rock deformation, preferably including microstructures and deformation mechanisms. They will have obtained or be working towards a Master’s degree in a relevant Geological Science at a recognised Higher Education establishment or Research Centre. The studentship will only fully fund applicants who are eligible for Home/EU fees. Applicants who are normally required to cover overseas fees will have to cover the difference between the Home/EU and the overseas tuition fee rates.</td>
</tr>
<tr id="rev_Campbell2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: https://www.heritageinthecrossfire.com/
<br>Not published online.
<br>Cardiff University    Cardiff School of Earth and Environmental Sciences
<br>
<br>Project makes use of Meshroom</td>
</tr>
<tr id="bib_Campbell2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Campbell2020,
  author = {Oliver Campbell},
  title = {Microstructures and deformation mechanisms from ballistic impacts in stone},
  journal = {Cardiff University Cardiff School of Earth and Environmental Sciences},
  year = {2020},
  url = {https://www.findaphd.com/phds/project/microstructures-and-deformation-mechanisms-from-ballistic-impacts-in-stone/?p94906}
}
</pre></td>
</tr>
<tr id="Carlucci2020" class="entry">
	<td>Carlucci, R., Cipriano, G., Santacesaria, F.C., Ricci, P., Maglietta, R., Petrella, A., Mazzariol, S., De Padova, D., Mossa, M., Bellomo, S. and Fanizza, C.</td>
	<td>Exploring data from an individual stranding of a Cuvier's beaked whale in the Gulf of Taranto (Northern Ionian Sea, Central-eastern Mediterranean Sea) <p class="infolinks">[<a href="javascript:toggleInfo('Carlucci2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Experimental Marine Biology and Ecology<br/>Vol. 533, pp. 151473&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.jembe.2020.151473">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0022098120302380">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Carlucci2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Carlucci2020,
  author = {Carlucci, Roberto and Cipriano, Giulia and Santacesaria, Francesca Cornelia and Ricci, Pasquale and Maglietta, Rosalia and Petrella, Antonio and Mazzariol, Sandro and De Padova, Diana and Mossa, Michele and Bellomo, Stefano and Fanizza, Carmelo},
  title = {Exploring data from an individual stranding of a Cuvier's beaked whale in the Gulf of Taranto (Northern Ionian Sea, Central-eastern Mediterranean Sea)},
  journal = {Journal of Experimental Marine Biology and Ecology},
  year = {2020},
  volume = {533},
  pages = {151473},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022098120302380},
  doi = {https://doi.org/10.1016/j.jembe.2020.151473}
}
</pre></td>
</tr>
<tr id="Cassidy2020" class="entry">
	<td>Cassidy, M., Melou, J., Queau, Y., Lauze, F. and Durou, J.-D.</td>
	<td>Refractive Multi-view Stereo <p class="infolinks">[<a href="javascript:toggleInfo('Cassidy2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 2020 International Conference on 3D Vision (3DV), pp. 384-393&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/3DV50981.2020.00048">DOI</a> <a href="https://ieeexplore.ieee.org/document/9320106/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Cassidy2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Cassidy2020,
  author = {Cassidy, Matthew and Melou, Jean and Queau, Yvain and Lauze, Francois and Durou, Jean-Denis},
  title = {Refractive Multi-view Stereo},
  booktitle = {Proceedings of the 2020 International Conference on 3D Vision (3DV)},
  publisher = {IEEE},
  year = {2020},
  pages = {384--393},
  url = {https://ieeexplore.ieee.org/document/9320106/},
  doi = {https://doi.org/10.1109/3DV50981.2020.00048}
}
</pre></td>
</tr>
<tr id="CominoTrinidad2020" class="entry">
	<td>Comino Trinidad, M.</td>
	<td>Algorithms for the reconstruction, analysis, repairing and enhancement of 3D urban models from multiple data sources <p class="infolinks">[<a href="javascript:toggleInfo('CominoTrinidad2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: Universitat Polit&egrave;cnica de Catalunya.&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="http://hdl.handle.net/2117/335427">URL</a>&nbsp;</td>
</tr>
<tr id="bib_CominoTrinidad2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{CominoTrinidad2020,
  author = {Comino Trinidad, Marc},
  title = {Algorithms for the reconstruction, analysis, repairing and enhancement of 3D urban models from multiple data sources},
  school = {Universitat Polit&egrave;cnica de Catalunya.},
  year = {2020},
  url = {http://hdl.handle.net/2117/335427}
}
</pre></td>
</tr>
<tr id="Dawkins2020" class="entry">
	<td>Dawkins, O. and Young, G.W.</td>
	<td>Engaging Place with Mixed Realities: Sharing Multisensory Experiences of Place Through Community-Generated Digital Content and Multimodal Interaction <p class="infolinks">[<a href="javascript:toggleInfo('Dawkins2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Virtual, Augmented and Mixed Reality. Industrial and Everyday Life Applications. HCII 2020. Lecture Notes in Computer Science, pp. 199-218&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-49698-2_14">DOI</a> <a href="http://link.springer.com/10.1007/978-3-030-49698-2_14">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Dawkins2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Dawkins2020,
  author = {Dawkins, Oliver and Young, Gareth W.},
  title = {Engaging Place with Mixed Realities: Sharing Multisensory Experiences of Place Through Community-Generated Digital Content and Multimodal Interaction},
  booktitle = {Virtual, Augmented and Mixed Reality. Industrial and Everyday Life Applications. HCII 2020. Lecture Notes in Computer Science},
  year = {2020},
  pages = {199--218},
  url = {http://link.springer.com/10.1007/978-3-030-49698-2_14},
  doi = {https://doi.org/10.1007/978-3-030-49698-2_14}
}
</pre></td>
</tr>
<tr id="Dawkins2020a" class="entry">
	<td>Dawkins, O. and Young, G.W.</td>
	<td>Workshop—Ground Truthing and Virtual Field Trips <p class="infolinks">[<a href="javascript:toggleInfo('Dawkins2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 6th International Conference of the Immersive Learning Research Network (iLRN), pp. 418-420&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.23919/iLRN47897.2020.9155213">DOI</a> <a href="https://ieeexplore.ieee.org/document/9155213/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Dawkins2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Dawkins2020a,
  author = {Dawkins, Oliver and Young, Gareth W.},
  title = {Workshop—Ground Truthing and Virtual Field Trips},
  booktitle = {Proceedings of the 6th International Conference of the Immersive Learning Research Network (iLRN)},
  publisher = {IEEE},
  year = {2020},
  pages = {418--420},
  url = {https://ieeexplore.ieee.org/document/9155213/},
  doi = {https://doi.org/10.23919/iLRN47897.2020.9155213}
}
</pre></td>
</tr>
<tr id="DeLorenzo2020" class="entry">
	<td>DeLorenzo, L., Vander Linden, A., Bergmann, P.J., Wagner, G.P., Siler, C.D. and Irschick, D.J.</td>
	<td>Using 3D digital photogrammetry to examine scaling of the body axis in burrowing skinks <p class="infolinks">[<a href="javascript:toggleInfo('DeLorenzo2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Morphology<br/>Vol. 281(11), pp. 1382-1390&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1002/jmor.21253">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/jmor.21253">URL</a>&nbsp;</td>
</tr>
<tr id="bib_DeLorenzo2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{DeLorenzo2020,
  author = {DeLorenzo, Leah and Vander Linden, Abby and Bergmann, Philip J. and Wagner, Gunter P. and Siler, Cameron D. and Irschick, Duncan J.},
  title = {Using 3D digital photogrammetry to examine scaling of the body axis in burrowing skinks},
  journal = {Journal of Morphology},
  year = {2020},
  volume = {281},
  number = {11},
  pages = {1382--1390},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/jmor.21253},
  doi = {https://doi.org/10.1002/jmor.21253}
}
</pre></td>
</tr>
<tr id="DePaolis2020" class="entry">
	<td>De Paolis, L.T., De Luca, V., Gatto, C., D'Errico, G. and Paladini, G.I.</td>
	<td>Photogrammetric 3D Reconstruction of Small Objects for a Real-Time Fruition <p class="infolinks">[<a href="javascript:toggleInfo('DePaolis2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Augmented Reality, Virtual Reality, and Computer Graphics. AVR 2020. Lecture Notes in Computer Science, pp. 375-394&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-58465-8_28">DOI</a> <a href="https://link.springer.com/10.1007/978-3-030-58465-8_28">URL</a>&nbsp;</td>
</tr>
<tr id="bib_DePaolis2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{DePaolis2020,
  author = {De Paolis, Lucio Tommaso and De Luca, Valerio and Gatto, Carola and D'Errico, Giovanni and Paladini, Giovanna Ilenia},
  title = {Photogrammetric 3D Reconstruction of Small Objects for a Real-Time Fruition},
  booktitle = {Augmented Reality, Virtual Reality, and Computer Graphics. AVR 2020. Lecture Notes in Computer Science},
  year = {2020},
  pages = {375--394},
  url = {https://link.springer.com/10.1007/978-3-030-58465-8_28},
  doi = {https://doi.org/10.1007/978-3-030-58465-8_28}
}
</pre></td>
</tr>
<tr id="DJALLEL2020" class="entry">
	<td>DJALLEL, M.</td>
	<td>Handling occlusions based on 3D reconstruction in augmented reality <p class="infolinks">[<a href="javascript:toggleInfo('DJALLEL2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 90<i>School</i>: Universit&eacute; Mohamed Khider&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_DJALLEL2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{DJALLEL2020,
  author = {DJALLEL, MESSERHI},
  title = {Handling occlusions based on 3D reconstruction in augmented reality},
  school = {Universit&eacute; Mohamed Khider},
  year = {2020},
  pages = {90}
}
</pre></td>
</tr>
<tr id="Duarte2020" class="entry">
	<td>Duarte, J., Cunha, M. and Carvalho, J.</td>
	<td>Modeling and Comparison of Data Obtained by GPR, for Geological / Structural Analysis of a Carbonated Ornamental Rock Quarry - Blocometry Validation - Case Study in Valinho De F&aacute;tima, Portugal <p class="infolinks">[<a href="javascript:toggleInfo('Duarte2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>IOP Conference Series: Earth and Environmental Science&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Duarte2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Duarte2020,
  author = {Duarte, Jo&atilde;o and Cunha, Marco and Carvalho, Jos&eacute;},
  title = {Modeling and Comparison of Data Obtained by GPR, for Geological / Structural Analysis of a Carbonated Ornamental Rock Quarry - Blocometry Validation - Case Study in Valinho De F&aacute;tima, Portugal},
  booktitle = {IOP Conference Series: Earth and Environmental Science},
  year = {2020}
}
</pre></td>
</tr>
<tr id="Dymkova2020" class="entry">
	<td>Dymkova, S.S. and Dymkov, A.D.</td>
	<td>Synchronizing of moving object with novel 3D maps imaging <p class="infolinks">[<a href="javascript:toggleInfo('Dymkova2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 2020 Systems of Signal Synchronization, Generating and Processing in Telecommunications (SYNCHROINFO), pp. 1-5&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/SYNCHROINFO49631.2020.9166029">DOI</a> <a href="https://ieeexplore.ieee.org/document/9166029/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Dymkova2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Dymkova2020,
  author = {Dymkova, S. S. and Dymkov, A. D.},
  title = {Synchronizing of moving object with novel 3D maps imaging},
  booktitle = {Proceedings of the 2020 Systems of Signal Synchronization, Generating and Processing in Telecommunications (SYNCHROINFO)},
  publisher = {IEEE},
  year = {2020},
  pages = {1--5},
  url = {https://ieeexplore.ieee.org/document/9166029/},
  doi = {https://doi.org/10.1109/SYNCHROINFO49631.2020.9166029}
}
</pre></td>
</tr>
<tr id="Egger2020" class="entry">
	<td>Egger, B., Smith, W.A.P., Tewari, A., Wuhrer, S., Zollhoefer, M., Beeler, T., Bernard, F., Bolkart, T., Kortylewski, A., Romdhani, S., Theobalt, C., Blanz, V. and Vetter, T.</td>
	<td>3D Morphable Face Models—Past, Present, and Future <p class="infolinks">[<a href="javascript:toggleInfo('Egger2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Egger2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>ACM Transactions on Graphics<br/>Vol. 39(5), pp. 1-38&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1145/3395208">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3395208">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Egger2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this article, we provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. The challenges in building and applying these models, namely, capture, modeling, image formation, and image analysis, are still active research topics, and we review the state-of-the-art in each of these areas. We also look ahead, identifying unsolved challenges, proposing directions for future research, and highlighting the broad range of current and future applications.</td>
</tr>
<tr id="bib_Egger2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Egger2020,
  author = {Egger, Bernhard and Smith, William A. P. and Tewari, Ayush and Wuhrer, Stefanie and Zollhoefer, Michael and Beeler, Thabo and Bernard, Florian and Bolkart, Timo and Kortylewski, Adam and Romdhani, Sami and Theobalt, Christian and Blanz, Volker and Vetter, Thomas},
  title = {3D Morphable Face Models—Past, Present, and Future},
  journal = {ACM Transactions on Graphics},
  year = {2020},
  volume = {39},
  number = {5},
  pages = {1--38},
  url = {https://dl.acm.org/doi/10.1145/3395208},
  doi = {https://doi.org/10.1145/3395208}
}
</pre></td>
</tr>
<tr id="Elesawy2020" class="entry">
	<td>Elesawy, A.A., Signer, M., Seshadri, B. and Schlueter, A.</td>
	<td>Aerial Photogrammetry in Remote Locations - A workflow for using 3D point cloud data in building energy modeling <p class="infolinks">[<a href="javascript:toggleInfo('Elesawy2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Anthropologic: Architecture and Fabrication in the cognitive age - Proceedings of the 38th eCAADe Conference&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://papers.cumincad.org/cgi-bin/works/2015 +dave=2:/Show?ecaade2020_290">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Elesawy2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Elesawy2020,
  author = {Elesawy, Amr Alaaeldin and Signer, Mario and Seshadri, Bharath and Schlueter, Arno},
  title = {Aerial Photogrammetry in Remote Locations - A workflow for using 3D point cloud data in building energy modeling},
  booktitle = {Anthropologic: Architecture and Fabrication in the cognitive age - Proceedings of the 38th eCAADe Conference},
  year = {2020},
  url = {http://papers.cumincad.org/cgi-bin/works/2015 +dave=2:/Show?ecaade2020_290}
}
</pre></td>
</tr>
<tr id="ElSaer2020" class="entry">
	<td>El Saer, A., Stentoumis, C., Kalisperakis, I., Grammatikopoulos, L., Nomikou, P. and Vlasopoulos, O.</td>
	<td>3D Reconstruction And Mesh Optimization Of Underwater Spaces For Virtual Reality <p class="infolinks">[<a href="javascript:toggleInfo('ElSaer2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('ElSaer2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLIII-B2-2, pp. 949-956&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLIII-B2-2020-949-2020">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/949/2020/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_ElSaer2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. In this contribution, we propose a versatile image-based methodology for 3D reconstructing underwater scenes of high fidelity and integrating them into a virtual reality environment. Typically, underwater images suffer from colour degradation (blueish images) due to the propagation of light through water, which is a more absorbing medium than air, as well as the scattering of light on suspended particles. Other factors, such as artificial lights, also, diminish the quality of images and, thus, the quality of the image-based 3D reconstruction. Moreover, degraded images have a direct impact on the user perception of the virtual environment, due to geometric and visual degenerations. Here, it is argued that these can be mitigated by image pre-processing algorithms and specialized filters. The impact of different filtering techniques on images is evaluated, in order to eliminate colour degradation and mismatches in the image sequences. The methodology in this work consists of five sequential pre-processes; saturation enhancement, haze reduction, and Rayleigh distribution adaptation, to de-haze the images, global histogram matching to minimize differences among images of the dataset, and image sharpening to strengthen the edges of the scene. The 3D reconstruction of the models is based on open-source structure-from-motion software. The models are optimized for virtual reality through mesh simplification, physically based rendering texture maps baking, and level-of-details. The results of the proposed methodology are qualitatively evaluated on image datasets captured in the seabed of Santorini island in Greece, using a ROV platform.</td>
</tr>
<tr id="bib_ElSaer2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{ElSaer2020,
  author = {El Saer, A. and Stentoumis, C. and Kalisperakis, I. and Grammatikopoulos, L. and Nomikou, P. and Vlasopoulos, O.},
  title = {3D Reconstruction And Mesh Optimization Of Underwater Spaces For Virtual Reality},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2020},
  volume = {XLIII-B2-2},
  pages = {949--956},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/949/2020/},
  doi = {https://doi.org/10.5194/isprs-archives-XLIII-B2-2020-949-2020}
}
</pre></td>
</tr>
<tr id="ElSaer2020a" class="entry">
	<td>El Saer, A., Stentoumis, C., Kalisperakis, I. and Nomikou, P.</td>
	<td>Developing a strategy for precise 3d modelling of large-scale scenes for VR <p class="infolinks">[<a href="javascript:toggleInfo('ElSaer2020a','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('ElSaer2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives<br/>Vol. 43(B4), pp. 567-574&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/ISPRS-ARCHIVES-XLIII-B4-2020-567-2020">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_ElSaer2020a" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this work, we present a methodology for precise 3D modelling and multi-source geospatial data blending for the purposes of Virtual Reality immersive and interactive experiences. We evaluate it on the volcanic island of Santorini due to its formidable geological terrain and the interest it poses for scientific and touristic purposes. The methodology developed here consists of three main steps. Initially, bathymetric and SRTM data are scaled down to match the smallest resolution of our dataset (LIDAR). Afterwards, the resulted elevations are combined based on the slope of the relief, while considering a buffer area to enforce a smoother terrain. As a final step, the orthophotos are combined with the estimated Digital Terrain Model, via applying a nearest neighbour matching schema leading to the final terrain background. In addition to this, both onshore and offshore points-of-interest were modelled via image-based 3D reconstruction and added to the virtual scene. The overall geospatial data that need to be visualized in applications demanding photo-textured hyper-realistic models pose a significant challenge. The 3D models are treated via a mesh optimization workflow, suitable for efficient and fast visualization in virtual reality engines, through mesh simplification, physically based rendering texture maps baking, and level-of-details.</td>
</tr>
<tr id="bib_ElSaer2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{ElSaer2020a,
  author = {El Saer, A. and Stentoumis, C. and Kalisperakis, I. and Nomikou, P.},
  title = {Developing a strategy for precise 3d modelling of large-scale scenes for VR},
  journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
  publisher = {International Society for Photogrammetry and Remote Sensing},
  year = {2020},
  volume = {43},
  number = {B4},
  pages = {567--574},
  doi = {https://doi.org/10.5194/ISPRS-ARCHIVES-XLIII-B4-2020-567-2020}
}
</pre></td>
</tr>
<tr id="Falkingham2020" class="entry">
	<td>Falkingham, P.L., Turner, M.L. and Gatesy, S.M.</td>
	<td>Constructing and testing hypotheses of dinosaur foot motions from fossil tracks using digitization and simulation <p class="infolinks">[<a href="javascript:toggleInfo('Falkingham2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Palaeontology<br/>Vol. 63(6), pp. 865-880&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1111/pala.12502">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1111/pala.12502">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Falkingham2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Falkingham2020,
  author = {Falkingham, Peter L. and Turner, Morgan L. and Gatesy, Stephen M.},
  title = {Constructing and testing hypotheses of dinosaur foot motions from fossil tracks using digitization and simulation},
  journal = {Palaeontology},
  year = {2020},
  volume = {63},
  number = {6},
  pages = {865--880},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/pala.12502},
  doi = {https://doi.org/10.1111/pala.12502}
}
</pre></td>
</tr>
<tr id="Gafton2020" class="entry">
	<td>Gafton, P. and Maraz, E.</td>
	<td>2D Image Relighting with Image-to-Image Translation <p class="infolinks">[<a href="javascript:toggleInfo('Gafton2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gafton2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>&nbsp;</td>
	<td>article</td>
	<td><a href="http://arxiv.org/abs/2006.07816">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Gafton2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: With the advent of Generative Adversarial Networks (GANs), a finer level of control in manipulating various features of an image has become possible. One example of such fine manipulation is changing the position of the light source in a scene. This is fundamentally an ill-posed problem, since it requires understanding the scene geometry to generate proper lighting effects. This problem is not a trivial one and can become even more complicated if we want to change the direction of the light source from any direction to a specific one. Here we provide our attempt to solve this problem using GANs. Specifically, pix2pix [arXiv:1611.07004] trained with the dataset VIDIT [arXiv:2005.05460] which contains images of the same scene with different types of light temperature and 8 different light source positions (N, NE, E, SE, S, SW, W, NW). The results are 8 neural networks trained to be able to change the direction of the light source from any direction to one of the 8 previously mentioned. Additionally, we provide, as a tool, a simple CNN trained to identify the direction of the light source in an image.</td>
</tr>
<tr id="bib_Gafton2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gafton2020,
  author = {Gafton, Paul and Maraz, Erick},
  title = {2D Image Relighting with Image-to-Image Translation},
  year = {2020},
  url = {http://arxiv.org/abs/2006.07816}
}
</pre></td>
</tr>
<tr id="Gajic2020" class="entry">
	<td>Gajic, D., Gojic, G., Dragan, D. and Petrovic, V.</td>
	<td>Comparative evaluation of keypoint detectors for 3d digital avatar reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('Gajic2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Facta universitatis - series: Electronics and Energetics<br/>Vol. 33(3), pp. 379-394&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.2298/FUEE2003379G">DOI</a> <a href="http://www.doiserbia.nb.rs/Article.aspx?ID=0353-36702003379G">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Gajic2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Gajic2020,
  author = {Gajic, Dusan and Gojic, Gorana and Dragan, Dinu and Petrovic, Veljko},
  title = {Comparative evaluation of keypoint detectors for 3d digital avatar reconstruction},
  journal = {Facta universitatis - series: Electronics and Energetics},
  year = {2020},
  volume = {33},
  number = {3},
  pages = {379--394},
  url = {http://www.doiserbia.nb.rs/Article.aspx?ID=0353-36702003379G},
  doi = {https://doi.org/10.2298/FUEE2003379G}
}
</pre></td>
</tr>
<tr id="Gomes2020" class="entry">
	<td>Gomes, G.D., Flynn, R. and Murray, N.</td>
	<td>A QoE Evaluation of an Immersive Virtual Reality Autonomous Driving Experience <p class="infolinks">[<a href="javascript:toggleInfo('Gomes2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gomes2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 12th International Conference on Quality of Multimedia Experience, QoMEX 2020&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/QOMEX48832.2020.9123128">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Gomes2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The driver/passenger role in autonomous driving experiences is an important subject that is concerned with how these systems will interact and communicate with the human stakeholder. Even though self-driving technologies have made rapid progress in recent years, their success will depend on ethics, safe capabilities and user acceptance. The overall satisfaction resulting from the interaction between humans, these technologies and their evaluation in simulators can help industry to improve their design. Such evaluations can be based on user's perceived Quality of Experience (QoE). The impact of the quality features that compound VR environments is an important factor to understand. Sense of depth, texture quality and resolution are some examples that influence the perceived quality of the simulation and immersion levels. This demonstration promotes a VR autonomous driving experience in one street of Athlone, Ireland. The application will be presented in two different formats: photogrammetry, a technique that uses photos to provide realistic 3D content, and secondly non-photorealistic simulated environment. Further investigations will be carried out to understand factors that enable the highest immersive experience in autonomous vehicles considering feedback modalities between the car and its users.</td>
</tr>
<tr id="bib_Gomes2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Gomes2020,
  author = {Gomes, Guilherme Daniel and Flynn, Ronan and Murray, Niall},
  title = {A QoE Evaluation of an Immersive Virtual Reality Autonomous Driving Experience},
  booktitle = {Proceedings of the 12th International Conference on Quality of Multimedia Experience, QoMEX 2020},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  doi = {https://doi.org/10.1109/QOMEX48832.2020.9123128}
}
</pre></td>
</tr>
<tr id="Hansen2020" class="entry">
	<td>Hansen, H.H.</td>
	<td>Indoor 3D reconstruction by Lidar and IMU and point cloud segmentation and compression with machine learning <p class="infolinks">[<a href="javascript:toggleInfo('Hansen2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 107<i>School</i>: University of Oslo&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="file:///home/simone/Downloads/Indoor-3D-reconstruction-by-Lidar-and-IMU-and-point-cloud-segmentation-and-compression-with-machine-learning.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Hansen2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Hansen2020,
  author = {Hansen, Henry Haugsten},
  title = {Indoor 3D reconstruction by Lidar and IMU and point cloud segmentation and compression with machine learning},
  school = {University of Oslo},
  year = {2020},
  pages = {107},
  url = {file:///home/simone/Downloads/Indoor-3D-reconstruction-by-Lidar-and-IMU-and-point-cloud-segmentation-and-compression-with-machine-learning.pdf}
}
</pre></td>
</tr>
<tr id="Hartono_2020" class="entry">
	<td>Hartono, J.R. and Oei, F.J.</td>
	<td>A Proposal of image-based measurement instead of laser-based measurement for indoor application <p class="infolinks">[<a href="javascript:toggleInfo('Hartono_2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hartono_2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>IOP Conference Series: Materials Science and Engineering<br/>Vol. 1007, pp. 12026&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1088/1757-899x/1007/1/012026">DOI</a> <a href="https://doi.org/10.1088/1757-899x/1007/1/012026">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Hartono_2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Measuring dimensions of indoor environment have an important role in construction, whether for calculation of work, or documentation purposes. Humans may introduce errors and make measuring real objects less accurate. Several methods have been developed to reduce this error and one of them is a non-contact measurement that executes according to guideline can minimize this error. Measurement using image-based measurement can reduce human involvement, where Total Station Theodolite (TST) is very dependent on its operator skill and involvement. This study aims to show the differences between image-based and laser-based measurements using TST in measuring the dimension of the indoor environment. Image-based measurement was obtained by taking photos of a few rooms and processed with an open-source software to produce a 3D model. This 3D model then measured to provide measurement for differences comparison. Laser-based measurement was obtained by hiring professional surveyor to measure the rooms with TST. Results from this study can be used as a reference in developing a new method to measure dimension in indoor application. Without hiring professional to measure using photogrammetry in this research, measurement using photogrammetry can get average differences of 0,2593% from measurement using TST.</td>
</tr>
<tr id="bib_Hartono_2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hartono_2020,
  author = {Hartono, J R and Oei, F J},
  title = {A Proposal of image-based measurement instead of laser-based measurement for indoor application},
  journal = {IOP Conference Series: Materials Science and Engineering},
  publisher = {IOP Publishing},
  year = {2020},
  volume = {1007},
  pages = {12026},
  url = {https://doi.org/10.1088/1757-899x/1007/1/012026},
  doi = {https://doi.org/10.1088/1757-899x/1007/1/012026}
}
</pre></td>
</tr>
<tr id="Hasheminasab2020" class="entry">
	<td>Hasheminasab, S.M., Zhou, T. and Habib, A.</td>
	<td>GNSS/INS-Assisted Structure from Motion Strategies for UAV-Based Imagery over Mechanized Agricultural Fields <p class="infolinks">[<a href="javascript:toggleInfo('Hasheminasab2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hasheminasab2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Remote Sensing<br/>Vol. 12(3), pp. 351&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/rs12030351">DOI</a> <a href="https://www.mdpi.com/2072-4292/12/3/351">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Hasheminasab2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Acquired imagery by unmanned aerial vehicles (UAVs) has been widely used for three-dimensional (3D) reconstruction/modeling in various digital agriculture applications, such as phenotyping, crop monitoring, and yield prediction. 3D reconstruction from well-textured UAV-based images has matured and the user community has access to several commercial and opensource tools that provide accurate products at a high level of automation. However, in some applications, such as digital agriculture, due to repetitive image patterns, these approaches are not always able to produce reliable/complete products. The main limitation of these techniques is their inability to establish a sufficient number of correctly matched features among overlapping images, causing incomplete and/or inaccurate 3D reconstruction. This paper provides two structure from motion (SfM) strategies, which use trajectory information provided by an onboard survey-grade global navigation satellite system/inertial navigation system (GNSS/INS) and system calibration parameters. The main difference between the proposed strategies is that the first one—denoted as partially GNSS/INS-assisted SfM—implements the four stages of an automated triangulation procedure, namely, imaging matching, relative orientation parameters (ROPs) estimation, exterior orientation parameters (EOPs) recovery, and bundle adjustment (BA). The second strategy— denoted as fully GNSS/INS-assisted SfM—removes the EOPs estimation step while introducing a random sample consensus (RANSAC)-based strategy for removing matching outliers before the BA stage. Both strategies modify the image matching by restricting the search space for conjugate points. They also implement a linear procedure for ROPs' refinement. Finally, they use the GNSS/INS information in modified collinearity equations for a simpler BA procedure that could be used for refining system calibration parameters. Eight datasets over six agricultural fields are used to evaluate the performance of the developed strategies. In comparison with a traditional SfM framework and Pix4D Mapper Pro, the proposed strategies are able to generate denser and more accurate 3D point clouds as well as orthophotos without any gaps.</td>
</tr>
<tr id="bib_Hasheminasab2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hasheminasab2020,
  author = {Hasheminasab, Seyyed Meghdad and Zhou, Tian and Habib, Ayman},
  title = {GNSS/INS-Assisted Structure from Motion Strategies for UAV-Based Imagery over Mechanized Agricultural Fields},
  journal = {Remote Sensing},
  year = {2020},
  volume = {12},
  number = {3},
  pages = {351},
  url = {https://www.mdpi.com/2072-4292/12/3/351},
  doi = {https://doi.org/10.3390/rs12030351}
}
</pre></td>
</tr>
<tr id="Hellmuth2020" class="entry">
	<td>Hellmuth, R., Wehner, F. and Giannakidis, A.</td>
	<td>Approach for an Update Method for Digital Factory Models <p class="infolinks">[<a href="javascript:toggleInfo('Hellmuth2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Hellmuth2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Procedia CIRP<br/>Vol. 93, pp. 280-285&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/J.PROCIR.2020.03.042">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Hellmuth2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The requirements of factory planning and the building concerned have changed in the last years. Factory planning has the task of designing products, plants, processes and the building of a factory. Although the building has an indirect influence on manufacturing systems, a quick conversion of the building is crucial in the event of changes in production technology. A current digital building model of the factory enables to carry out conversion processes quickly. The approach develops a method to update a digital building model of a factory during operation. Photogrammetry is used to update point clouds and derive BIM models.</td>
</tr>
<tr id="bib_Hellmuth2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hellmuth2020,
  author = {Hellmuth, Ren&eacute; and Wehner, Florian and Giannakidis, Alexandros},
  title = {Approach for an Update Method for Digital Factory Models},
  journal = {Procedia CIRP},
  publisher = {Elsevier},
  year = {2020},
  volume = {93},
  pages = {280--285},
  doi = {https://doi.org/10.1016/J.PROCIR.2020.03.042}
}
</pre></td>
</tr>
<tr id="Hellmuth2020a" class="entry">
	<td>Hellmuth, R., Wehner, F. and Giannakidis, A.</td>
	<td>Datasets of captured images of three different devices for photogrammetry calculation comparison and integration into a laserscan point cloud of a built environment <p class="infolinks">[<a href="javascript:toggleInfo('Hellmuth2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Data in Brief<br/>Vol. 33, pp. 106321&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.dib.2020.106321">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S2352340920312154">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Hellmuth2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hellmuth2020a,
  author = {Hellmuth, Ren&eacute; and Wehner, Florian and Giannakidis, Alexandros},
  title = {Datasets of captured images of three different devices for photogrammetry calculation comparison and integration into a laserscan point cloud of a built environment},
  journal = {Data in Brief},
  year = {2020},
  volume = {33},
  pages = {106321},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352340920312154},
  doi = {https://doi.org/10.1016/j.dib.2020.106321}
}
</pre></td>
</tr>
<tr id="Horvath2020" class="entry">
	<td>Horvath, J. and Cameron, R.</td>
	<td>3D Printer Workflow and Software <p class="infolinks">[<a href="javascript:toggleInfo('Horvath2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Mastering 3D Printing, pp. 51-92&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-1-4842-5842-2_3">DOI</a> <a href="http://link.springer.com/10.1007/978-1-4842-5842-2_3">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Horvath2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Horvath2020,
  author = {Horvath, Joan and Cameron, Rich},
  title = {3D Printer Workflow and Software},
  booktitle = {Mastering 3D Printing},
  publisher = {Apress},
  year = {2020},
  pages = {51--92},
  url = {http://link.springer.com/10.1007/978-1-4842-5842-2_3},
  doi = {https://doi.org/10.1007/978-1-4842-5842-2_3}
}
</pre></td>
</tr>
<tr id="Jarofka2020" class="entry">
	<td>Jarofka, M., Schweig, S., Maas, N., Kracht, F.E. and Schramm, D.</td>
	<td>Application of Photogrammetric Object Reconstruction for Simulation Environments in the Context of Inland Waterways <p class="infolinks">[<a href="javascript:toggleInfo('Jarofka2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Jarofka2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of International Conference on Simulation and Modeling Methodologies, Technologies and Applications, pp. 1-17&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1007/978-3-030-84811-8_1">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-84811-8_1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Jarofka2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: For the automated generation of simulation environments in the context of inland waterways navigation, a toolchain for the reconstruction of roadside buildings is used for the first time in this field. It was first implemented and tested for the reconstruction of roadside buildings. The toolchain uses data of a stereo camera to automatically generate models of the surrounding objects. This contribution describes the major changes that have to be made to adapt the toolchain to the changed environment. An unmanned aerial vehicle (UAV) is used to take images of specific objects. Due to the limited space on this UAV, only the supplied camera is used. Thus, the further steps in the toolchain have to be adapted. For the evaluation of the resulting model quality images of two bridges are considered. The implemented programs Metashape and Meshroom are compared with each other in terms of quality and computational effort. It is shown that the resulting model quality is better by using the program Metashape. Regarding the computational effort, the necessary time as well as the CPU and GPU utilization are reviewed. Although the GPU utilization is similar, Metashape outperforms Meshroom in terms of CPU utilization and total processing time. Furthermore, two different image recording methods are compared. On the one hand, models are reconstructed from only the top view. On the other hand, a tilted viewing angle with images from both sides of the bridges is used.</td>
</tr>
<tr id="bib_Jarofka2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Jarofka2020,
  author = {Jarofka, Maximilian and Schweig, Stephan and Maas, Niko and Kracht, Fr&eacute;d&eacute;ric Etienne and Schramm, Dieter},
  title = {Application of Photogrammetric Object Reconstruction for Simulation Environments in the Context of Inland Waterways},
  booktitle = {Proceedings of International Conference on Simulation and Modeling Methodologies, Technologies and Applications},
  publisher = {Springer, Cham},
  year = {2020},
  pages = {1--17},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-84811-8_1},
  doi = {https://doi.org/10.1007/978-3-030-84811-8_1}
}
</pre></td>
</tr>
<tr id="Jiang2020" class="entry">
	<td>Jiang, S., Jiang, C. and Jiang, W.</td>
	<td>Efficient structure from motion for large-scale UAV images: A review and a comparison of SfM tools <p class="infolinks">[<a href="javascript:toggleInfo('Jiang2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>ISPRS Journal of Photogrammetry and Remote Sensing<br/>Vol. 167, pp. 230-251&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.isprsjprs.2020.04.016">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0924271620301131">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Jiang2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Jiang2020,
  author = {Jiang, San and Jiang, Cheng and Jiang, Wanshou},
  title = {Efficient structure from motion for large-scale UAV images: A review and a comparison of SfM tools},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  year = {2020},
  volume = {167},
  pages = {230--251},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271620301131},
  doi = {https://doi.org/10.1016/j.isprsjprs.2020.04.016}
}
</pre></td>
</tr>
<tr id="Kalisperakis2020" class="entry">
	<td>Kalisperakis, I., Mandilaras, T., El Saer, A., Stamatopoulou, P., Stentoumis, C., Bourou, S. and Grammatikopoulos, L.</td>
	<td>A modular mobile mapping platform for complex indoor and outdoor environments <p class="infolinks">[<a href="javascript:toggleInfo('Kalisperakis2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kalisperakis2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives<br/>Vol. 43(B1), pp. 243-250&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/ISPRS-ARCHIVES-XLIII-B1-2020-243-2020">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Kalisperakis2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this work we present the development of a prototype, mobile mapping platform with modular design and architecture that can be suitably modified to address effectively both outdoors and indoors environments. Our system is built on the Robotics Operation System (ROS) and utilizes multiple sensors to capture images, pointclouds and 3D motion trajectories. These include synchronized cameras with wide angle lenses, a LiDAR sensor, a GPS/IMU unit and a tracking optical sensor. We report on the individual components of the platform, it's architecture, the integration and the calibration of its components, the fusion of all recorded data and provide initial 3D reconstruction results. The processing algorithms are based on existing implementations of SLAM (Simultaneous Localisation and Mapping) methods combined with SfM (Structure-from-Motion) for optimal estimations of orientations and 3D pointclouds. The scope of this work, which is part of an ongoing H2020 program, is to digitize the physical world, collect relevant spatial data and make digital copies available to experts and public for covering a wide range of needs; remote access and viewing, process, design, use in VR etc.</td>
</tr>
<tr id="bib_Kalisperakis2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kalisperakis2020,
  author = {Kalisperakis, I. and Mandilaras, T. and El Saer, A. and Stamatopoulou, P. and Stentoumis, C. and Bourou, S. and Grammatikopoulos, L.},
  title = {A modular mobile mapping platform for complex indoor and outdoor environments},
  journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
  publisher = {International Society for Photogrammetry and Remote Sensing},
  year = {2020},
  volume = {43},
  number = {B1},
  pages = {243--250},
  doi = {https://doi.org/10.5194/ISPRS-ARCHIVES-XLIII-B1-2020-243-2020}
}
</pre></td>
</tr>
<tr id="Kalisperakis2020a" class="entry">
	<td>Kalisperakis, I., Mandilaras, T., El Saer, A., Stamatopoulou, P., Stentoumis, C., Bourou, S. and Grammatikopoulos, L.</td>
	<td>A Modular Mobile Mapping Platform For Complex Indoor And Outdoor Environments <p class="infolinks">[<a href="javascript:toggleInfo('Kalisperakis2020a','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kalisperakis2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLIII-B1-2, pp. 243-250&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLIII-B1-2020-243-2020">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B1-2020/243/2020/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kalisperakis2020a" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. In this work we present the development of a prototype, mobile mapping platform with modular design and architecture that can be suitably modified to address effectively both outdoors and indoors environments. Our system is built on the Robotics Operation System (ROS) and utilizes multiple sensors to capture images, pointclouds and 3D motion trajectories. These include synchronized cameras with wide angle lenses, a lidar sensor, a GPS/IMU unit and a tracking optical sensor. We report on the individual components of the platform, it's architecture, the integration and the calibration of its components, the fusion of all recorded data and provide initial 3D reconstruction results. The processing algorithms are based on existing implementations of SLAM (Simultaneous Localisation and Mapping) methods combined with SfM (Structure-from-Motion) for optimal estimations of orientations and 3D pointclouds. The scope of this work, which is part of an ongoing H2020 program, is to digitize the physical world, collect relevant spatial data and make digital copies available to experts and public for covering a wide range of needs; remote access and viewing, process, design, use in VR etc.</td>
</tr>
<tr id="bib_Kalisperakis2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kalisperakis2020a,
  author = {Kalisperakis, I. and Mandilaras, T. and El Saer, A. and Stamatopoulou, P. and Stentoumis, C. and Bourou, S. and Grammatikopoulos, L.},
  title = {A Modular Mobile Mapping Platform For Complex Indoor And Outdoor Environments},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2020},
  volume = {XLIII-B1-2},
  pages = {243--250},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B1-2020/243/2020/},
  doi = {https://doi.org/10.5194/isprs-archives-XLIII-B1-2020-243-2020}
}
</pre></td>
</tr>
<tr id="Kim2020" class="entry">
	<td>Kim, T.H. and Lee, Y.C.</td>
	<td>Comparison of Open Source based Algorithms and Filtering Methods for UAS Image Processing <p class="infolinks">[<a href="javascript:toggleInfo('Kim2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kim2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Cadastre &amp; Land InformatiX<br/>Vol. 50(2), pp. 155-168&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.22640/LXSIRI.2020.50.2.155">DOI</a> <a href="https://doi.org/10.22640/lxsiri.2020.50.2.155">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kim2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Open source is a key growth engine of the 4th industrial revolution, and the continuous development and use of various algorithms for image processing is expected. The purpose of this study is to examine the effectiveness of the UAS image processing open source based algorithm by comparing and analyzing the water reproduction and moving object filtering function and the time required for data processing in 3D reproduction. Five matching algorithms were compared based on recall and processing speed through the 'ANN-Benchmarks' program, and HNSW (Hierarchical Navigable Small World) matching algorithm was judged to be the best. Based on this, 108 algorithms for image processing were constructed by combining each methods of triangulation, point cloud data densification, and surface generation. In addition, the 3D reproduction and data processing time of 108 algorithms for image processing were studied for UAS (Unmanned Aerial System) images of a park adjacent to the sea, and compared and analyzed with the commercial image processing software 'Pix4D Mapper'. As a result of the study, the algorithms that are good in terms of reproducing water and filtering functions of moving objects during 3D reproduction were specified, respectively, and the algorithm with the lowest required time was selected, and the effectiveness of the algorithm was verified by comparing it with the result of 'Pix4D Mapper'. 1. 서 론 오픈소스 소프트웨어(이하 '오픈소스')는 여러 소속 및 개인의 자발적인 참여로 개발되고 있다. 특히, 누구 나 무료 제작textperiodcentered배포가 가능하고 내부 코드가 공개되어 있어 소프트웨어 자체 개발 비용절감과 기간 단축이 라는 매우 중요한 장점을 갖고 있다. 또한, 상업용 소 프트웨어 대비 접근성과 유연성이 우수하며 글로벌</td>
</tr>
<tr id="bib_Kim2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kim2020,
  author = {Kim, Tae Hee;Lee, Yong Chang;},
  title = {Comparison of Open Source based Algorithms and Filtering Methods for UAS Image Processing},
  journal = {Journal of Cadastre &amp; Land InformatiX},
  publisher = {LX Spatial Information Research Institute},
  year = {2020},
  volume = {50},
  number = {2},
  pages = {155--168},
  url = {https://doi.org/10.22640/lxsiri.2020.50.2.155},
  doi = {https://doi.org/10.22640/LXSIRI.2020.50.2.155}
}
</pre></td>
</tr>
<tr id="Kurkela2020" class="entry">
	<td>Kurkela, M., Maksimainen, M., Julin, A., Virtanen, J.-P., M&auml;nnist&ouml;, I., Vaaja, M.T. and Hyypp&auml;, H.</td>
	<td>Applying photogrammetry to reconstruct 3D luminance point clouds of indoor environments <p class="infolinks">[<a href="javascript:toggleInfo('Kurkela2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Architectural Engineering and Design Management, pp. 1-17&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1080/17452007.2020.1862041">DOI</a> <a href="https://www.tandfonline.com/doi/full/10.1080/17452007.2020.1862041">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Kurkela2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Kurkela2020,
  author = {Kurkela, Matti and Maksimainen, Mikko and Julin, Arttu and Virtanen, Juho-Pekka and M&auml;nnist&ouml;, Ilari and Vaaja, Matti T. and Hyypp&auml;, Hannu},
  title = {Applying photogrammetry to reconstruct 3D luminance point clouds of indoor environments},
  journal = {Architectural Engineering and Design Management},
  year = {2020},
  pages = {1--17},
  url = {https://www.tandfonline.com/doi/full/10.1080/17452007.2020.1862041},
  doi = {https://doi.org/10.1080/17452007.2020.1862041}
}
</pre></td>
</tr>
<tr id="Lallensack2020" class="entry">
	<td>Lallensack, J.N., Buchwitz, M. and Romilio, A.</td>
	<td>Photogrammetry in ichnology: 3D model generation, visualisation, and data extraction <p class="infolinks">[<a href="javascript:toggleInfo('Lallensack2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Paleontological Techniques&nbsp;</td>
	<td>article</td>
	<td><a href="https://eartharxiv.org/repository/view/1833/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Lallensack2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lallensack2020,
  author = {Lallensack, Jens N. and Buchwitz, Michael and Romilio, Anthony},
  title = {Photogrammetry in ichnology: 3D model generation, visualisation, and data extraction},
  journal = {Journal of Paleontological Techniques},
  year = {2020},
  url = {https://eartharxiv.org/repository/view/1833/}
}
</pre></td>
</tr>
<tr id="Larkin2020" class="entry">
	<td>Larkin, N.R., Duffin, C.J., Dey, S., Stukins, S. and Falkingham, P.</td>
	<td>The first tetrapod track recorded from the Rhaetian in the British Isles <p class="infolinks">[<a href="javascript:toggleInfo('Larkin2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the Geologists' Association<br/>Vol. 131(6), pp. 722-729&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.pgeola.2020.07.012">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0016787820300754">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Larkin2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Larkin2020,
  author = {Larkin, Nigel R. and Duffin, Christopher J. and Dey, Steven and Stukins, Stephen and Falkingham, Peter},
  title = {The first tetrapod track recorded from the Rhaetian in the British Isles},
  journal = {Proceedings of the Geologists' Association},
  year = {2020},
  volume = {131},
  number = {6},
  pages = {722--729},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0016787820300754},
  doi = {https://doi.org/10.1016/j.pgeola.2020.07.012}
}
</pre></td>
</tr>
<tr id="Lee2020" class="entry">
	<td>Lee, N., Lee, K., Park, Y., Seo, S. and Lee, T.</td>
	<td>Development of 3D Reconstruction and Object Recognition Model using Video <p class="infolinks">[<a href="javascript:toggleInfo('Lee2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Digital Contents Society<br/>Vol. 21(11), pp. 2011-2019&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.9728/dcs.2020.21.11.2011">DOI</a> <a href="http://www.dbpia.co.kr/Journal/ArticleDetail/NODE10494650">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Lee2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Lee2020,
  author = {Lee, Nahyuk and Lee, Kyungtaek and Park, Youngsup and Seo, Sanghyun and Lee, Taemin},
  title = {Development of 3D Reconstruction and Object Recognition Model using Video},
  journal = {Journal of Digital Contents Society},
  year = {2020},
  volume = {21},
  number = {11},
  pages = {2011--2019},
  url = {http://www.dbpia.co.kr/Journal/ArticleDetail/NODE10494650},
  doi = {https://doi.org/10.9728/dcs.2020.21.11.2011}
}
</pre></td>
</tr>
<tr id="Li2020" class="entry">
	<td>Li, X., Ping, K., Gu, X. and He, M.</td>
	<td>3D Shape Reconstruction of Furniture Object from a Single Real Indoor Image <p class="infolinks">[<a href="javascript:toggleInfo('Li2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP), pp. 101-104&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICCWAMTIP51612.2020.9317479">DOI</a> <a href="https://ieeexplore.ieee.org/document/9317479/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Li2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Li2020,
  author = {Li, Xi and Ping, Kuang and Gu, Xiaofeng and He, Mingyun},
  title = {3D Shape Reconstruction of Furniture Object from a Single Real Indoor Image},
  booktitle = {Proceedings of the 2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)},
  publisher = {IEEE},
  year = {2020},
  pages = {101--104},
  url = {https://ieeexplore.ieee.org/document/9317479/},
  doi = {https://doi.org/10.1109/ICCWAMTIP51612.2020.9317479}
}
</pre></td>
</tr>
<tr id="Li2020a" class="entry">
	<td>Li, X., Arul Doss, A.C., Aksun Guvenc, B. and Guvenc, L.</td>
	<td>Pre-Deployment Testing of Low Speed, Urban Road Autonomous Driving in a Simulated Environment <p class="infolinks">[<a href="javascript:toggleInfo('Li2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>SAE Int. J. Adv. &amp; Curr. Prac. in Mobility<br/>Vol. 2(6), pp. 3301-3311&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.4271/2020-01-0706">DOI</a> <a href="https://www.sae.org/content/2020-01-0706/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Li2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Li2020a,
  author = {Li, Xinchen and Arul Doss, Aravind Chandradoss and Aksun Guvenc, Bilin and Guvenc, Levent},
  title = {Pre-Deployment Testing of Low Speed, Urban Road Autonomous Driving in a Simulated Environment},
  journal = {SAE Int. J. Adv. &amp; Curr. Prac. in Mobility},
  year = {2020},
  volume = {2},
  number = {6},
  pages = {3301--3311},
  url = {https://www.sae.org/content/2020-01-0706/},
  doi = {https://doi.org/10.4271/2020-01-0706}
}
</pre></td>
</tr>
<tr id="Luigini2020" class="entry">
	<td>Luigini, A., Parricchi, M.A., Basso, A. and Basso, D.</td>
	<td>Immersive and participatory serious games for heritage education, applied to the cultural heritage of South Tyrol <p class="infolinks">[<a href="javascript:toggleInfo('Luigini2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Luigini2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Interaction Design and Architecture(s)(43), pp. 42-67&nbsp;</td>
	<td>article</td>
	<td><a href="https://bia.unibz.it/esploro/outputs/journalArticle/Immersive-and-participatory-serious-games-for/991005772911101241">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Luigini2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Heritage education is an activity that is increasingly present in the educational curricula of schools and museums. Cognitive mechanisms and Representation devices must be thoroughly analysed and designed in order to promote the creation of didactic paths to foster effective learning experiences. Immersive visualization technologies are well suited for gamification applications and the technological and economic accessibility of VR HMD (head-mounted display) viewers makes these technologies particularly attractive for the development of potentially more widespread methodologies. This article will describe an educational path, and the relative experimentation, on the cultural heritage focused on the production of the typical bread of the Val Pusteria area-and the rural life around it. The project was aimed at primary school children and was based on a serious game in Virtual Immersive Reality.</td>
</tr>
<tr id="bib_Luigini2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Luigini2020,
  author = {Luigini, Alessandro and Parricchi, Monica Adriana and Basso, Alessandro and Basso, Demis},
  title = {Immersive and participatory serious games for heritage education, applied to the cultural heritage of South Tyrol},
  journal = {Interaction Design and Architecture(s)},
  publisher = {Scuola IaD},
  year = {2020},
  number = {43},
  pages = {42--67},
  url = {https://bia.unibz.it/esploro/outputs/journalArticle/Immersive-and-participatory-serious-games-for/991005772911101241}
}
</pre></td>
</tr>
<tr id="Madeira2020" class="entry">
	<td>Madeira, T., Oliveira, M. and Dias, P.</td>
	<td>Enhancement of RGB-D Image Alignment Using Fiducial Markers <p class="infolinks">[<a href="javascript:toggleInfo('Madeira2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Madeira2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Sensors<br/>Vol. 20(5), pp. 1497&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/s20051497">DOI</a> <a href="https://www.mdpi.com/1424-8220/20/5/1497">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Madeira2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Three-dimensional (3D) reconstruction methods generate a 3D textured model from the combination of data from several captures. As such, the geometrical transformations between these captures are required. The process of computing or refining these transformations is referred to as alignment. It is often a difficult problem to handle, in particular due to a lack of accuracy in the matching of features. We propose an optimization framework that takes advantage of fiducial markers placed in the scene. Since these markers are robustly detected, the problem of incorrect matching of features is overcome. The proposed procedure is capable of enhancing the 3D models created using consumer level RGB-D hand-held cameras, reducing visual artefacts caused by misalignments. One problem inherent to this solution is that the scene is polluted by the markers. Therefore, a tool was developed to allow their removal from the texture of the scene. Results show that our optimization framework is able to significantly reduce alignment errors between captures, which results in visually appealing reconstructions. Furthermore, the markers used to enhance the alignment are seamlessly removed from the final model texture.</td>
</tr>
<tr id="bib_Madeira2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Madeira2020,
  author = {Madeira, Tiago and Oliveira, Miguel and Dias, Paulo},
  title = {Enhancement of RGB-D Image Alignment Using Fiducial Markers},
  journal = {Sensors},
  year = {2020},
  volume = {20},
  number = {5},
  pages = {1497},
  url = {https://www.mdpi.com/1424-8220/20/5/1497},
  doi = {https://doi.org/10.3390/s20051497}
}
</pre></td>
</tr>
<tr id="Maghool2020" class="entry">
	<td>Maghool, S.A.H., Schnabel, M.A. and Moleta, T.</td>
	<td>A framework for quantifying the temporal visual experience of architecture a case study of the Sheikh Lotfollah Mosque <p class="infolinks">[<a href="javascript:toggleInfo('Maghool2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the International Conference of Architectural Science Association&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Maghool2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Maghool2020,
  author = {Maghool, Sayyed Amir Hossain and Schnabel, Marc Aurel and Moleta, Tane},
  title = {A framework for quantifying the temporal visual experience of architecture a case study of the Sheikh Lotfollah Mosque},
  booktitle = {Proceedings of the International Conference of Architectural Science Association},
  year = {2020}
}
</pre></td>
</tr>
<tr id="Martinez2020" class="entry">
	<td>Mart&iacute;nez, A.L. and Arvidsson, N.</td>
	<td>Balance Between Performance and Visual Quality in 3D Game Assets : Appropriateness of Assets for Games and Real-Time Rendering <p class="infolinks">[<a href="javascript:toggleInfo('Martinez2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Martinez2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: Uppsala University&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="http://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-413871">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Martinez2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This thesis explores the balance between visual quality and the performance of a 3D object for computer games. Additionally, it aims to help new 3D artists to create assets that are both visually a ...</td>
</tr>
<tr id="bib_Martinez2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Martinez2020,
  author = {Mart&iacute;nez, Ana Laura and Arvidsson, Natali},
  title = {Balance Between Performance and Visual Quality in 3D Game Assets : Appropriateness of Assets for Games and Real-Time Rendering},
  school = {Uppsala University},
  year = {2020},
  url = {http://urn.kb.se/resolve?urn=urn:nbn:se:uu:diva-413871}
}
</pre></td>
</tr>
<tr id="Medina2020" class="entry">
	<td>Medina, J.J., Maley, J.M., Sannapareddy, S., Medina, N.N., Gilman, C.M. and McCormack, J.E.</td>
	<td>A rapid and cost-effective pipeline for digitization of museum specimens with 3D photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('Medina2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>PLOS ONE<br/>Vol. 15(8)&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1371/journal.pone.0236417">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Medina2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Medina2020,
  author = {Medina, Joshua J. and Maley, James M. and Sannapareddy, Siddharth and Medina, Noah N. and Gilman, Cyril M. and McCormack, John E.},
  title = {A rapid and cost-effective pipeline for digitization of museum specimens with 3D photogrammetry},
  journal = {PLOS ONE},
  year = {2020},
  volume = {15},
  number = {8},
  doi = {https://doi.org/10.1371/journal.pone.0236417}
}
</pre></td>
</tr>
<tr id="Melou2020" class="entry">
	<td>M&eacute;lou, J.</td>
	<td>Fusion d'approches photom&eacute;triques et g&eacute;om&eacute;triques pour la cr&eacute;ation de mod&egrave;les 3D <p class="infolinks">[<a href="javascript:toggleInfo('Melou2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: University of Toulouse&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://oatao.univ-toulouse.fr/27373/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Melou2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Melou2020,
  author = {M&eacute;lou, Jean},
  title = {Fusion d'approches photom&eacute;triques et g&eacute;om&eacute;triques pour la cr&eacute;ation de mod&egrave;les 3D},
  school = {University of Toulouse},
  year = {2020},
  url = {https://oatao.univ-toulouse.fr/27373/}
}
</pre></td>
</tr>
<tr id="Merkle2020" class="entry">
	<td>Merkle, D., Schmitt, A. and Reiterer, A.</td>
	<td>Concept of an autonomous mobile robotic system for bridge inspection <p class="infolinks">[<a href="javascript:toggleInfo('Merkle2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the Remote Sensing Technologies and Applications in Urban Environments V, pp. 8&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1117/12.2570633">DOI</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11535/2570633/Concept-of-an-autonomous-mobile-robotic-system-for-bridge-inspection/10.1117/12.2570633.full">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Merkle2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Merkle2020,
  author = {Merkle, Dominik and Schmitt, Annette and Reiterer, Alexander},
  title = {Concept of an autonomous mobile robotic system for bridge inspection},
  booktitle = {Proceedings of the Remote Sensing Technologies and Applications in Urban Environments V},
  publisher = {SPIE},
  year = {2020},
  pages = {8},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11535/2570633/Concept-of-an-autonomous-mobile-robotic-system-for-bridge-inspection/10.1117/12.2570633.full},
  doi = {https://doi.org/10.1117/12.2570633}
}
</pre></td>
</tr>
<tr id="Merkle2020a" class="entry">
	<td>Merkle, D., Schmitt, A. and Reiterer, A.</td>
	<td>Sensor Evaluation For Crack Detection In Concrete Bridges <p class="infolinks">[<a href="javascript:toggleInfo('Merkle2020a','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Merkle2020a','comment')">Comment</a>] [<a href="javascript:toggleInfo('Merkle2020a','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLIII-B2-2, pp. 1107-1114&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLIII-B2-2020-1107-2020">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/1107/2020/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Merkle2020a" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. Bridges are one of the most critical traffic infrastructure objects, therefore it is necessary to monitor them at regular intervals. Nowadays, this monitoring is made manually by visual inspection. In recent projects, the authors are developing automated crack detection systems to support the inspector. In this pre-study, different sensors, like different camera systems for photogrammetry, a laser scanner, and a laser triangulation system are evaluated for crack detection based on a defined required minimum crack width of 0.2 mm. The used test object is a blasted concrete plate, sized 70 cm × 70 cm × 5 cm and placed in an outdoor environment. The results of the data acquisition with the different sensors are point clouds, which make the results comparable. The point cloud from the chosen laser scanner is not sufficient for the required crack width even at a low speed of 1 m/s. The RGB or intensity information of the photogrammetric point clouds, even based on a low-cost smartphone camera, contain the targeted cracks. The authors advise against using only the 3D information of the photogrammetric point clouds for crack detection due to noise. The laser triangulation system delivers the best results in both intensity and 3D information. The low weight of camera systems makes photogrammetry to the preferred method for an unmanned aerial vehicle (UAV). In the future, the authors aim for crack detection based on the 2D images, automated by using machine learning, and crack localisation by using structure from motion (SfM) or a positioning system.</td>
</tr>
<tr id="rev_Merkle2020a" class="comment noshow">
	<td colspan="6"><b>Comment</b>: To determine and output the camera poses as illustrated (...), the authors used the freeware Meshroom</td>
</tr>
<tr id="bib_Merkle2020a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Merkle2020a,
  author = {Merkle, D. and Schmitt, A. and Reiterer, A.},
  title = {Sensor Evaluation For Crack Detection In Concrete Bridges},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2020},
  volume = {XLIII-B2-2},
  pages = {1107--1114},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2020/1107/2020/},
  doi = {https://doi.org/10.5194/isprs-archives-XLIII-B2-2020-1107-2020}
}
</pre></td>
</tr>
<tr id="Mian2020" class="entry">
	<td>Mian, S., Garrett, T., Glandon, A., Manderino, C., Balachandran, S., Munoz, C.A. and Dolph, C.V.</td>
	<td>Autonomous Spacecraft Inspection with Free-Flying Drones <p class="infolinks">[<a href="javascript:toggleInfo('Mian2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the AIAA/IEEE 39th Digital Avionics Systems Conference (DASC), pp. 1-9&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/DASC50938.2020.9256569">DOI</a> <a href="https://ieeexplore.ieee.org/document/9256569/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Mian2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Mian2020,
  author = {Mian, Sami and Garrett, Tyler and Glandon, Alexander and Manderino, Christopher and Balachandran, Swee and Munoz, Cesar A. and Dolph, Chester V.},
  title = {Autonomous Spacecraft Inspection with Free-Flying Drones},
  booktitle = {Proceedings of the AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)},
  publisher = {IEEE},
  year = {2020},
  pages = {1--9},
  url = {https://ieeexplore.ieee.org/document/9256569/},
  doi = {https://doi.org/10.1109/DASC50938.2020.9256569}
}
</pre></td>
</tr>
<tr id="Milan2020" class="entry">
	<td>Mil&agrave;n, J., Falkingham, P.L. and Mueller-T&ouml;we, I.J.</td>
	<td>Small ornithopod dinosaur tracks and crocodilian remains from the Middle Jurassic Bag&aring; Formation, Bornholm, Denmark: Important additions to the rare Middle Jurassic vertebrate faunas of Northern Europe <p class="infolinks">[<a href="javascript:toggleInfo('Milan2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Milan2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('Milan2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Bulletin of the Geological Society of Denmark<br/>Vol. 68, pp. 245-253&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.37570/bgsd-2020-68-11">DOI</a> <a href="https://doi.org/10.37570/bgsd-2020-68-11 https://2dgf.dk/publikationer/bulletin/bulletin-volume-68-2020/#11">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Milan2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Two new small tridactyl dinosaur tracks are found in the Middle Jurassic Bag&aring; Formation of Bornholm and are interpreted as ornithopodian in origin. A skeletal fragment is identified as a crocodilian skull fragment. Previous finds of dinosaur tracks from the locality consist of two sizes of sauropods, a medium sized theropod and thyreophorans. The addition of tracks from ornithopod dinosaurs and skeletal evidence of crocodilians now give a broader picture of a diverse Middle Jurassic vertebrate fauna. This is an important addition to the understanding of the terres-trial Mesozoic ecosystem of Denmark, and a valuable addition to the scarce Middle Jurassic vertebrate record of Europe.</td>
</tr>
<tr id="rev_Milan2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Small ornithopod dinosaur tracks and crocodilian remains from the Middle Jurassic Bagå Formation, Born-holm, Denmark. (...) tracks were digitized via photogrammetry, using photos taken with a 16mp FujiFilm FinePix XP80, and processed using AliceVision Meshroom</td>
</tr>
<tr id="bib_Milan2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Milan2020,
  author = {Mil&agrave;n, Jesper and Falkingham, Peter L. and Mueller-T&ouml;we, Inken Juliane},
  title = {Small ornithopod dinosaur tracks and crocodilian remains from the Middle Jurassic Bag&aring; Formation, Bornholm, Denmark: Important additions to the rare Middle Jurassic vertebrate faunas of Northern Europe},
  journal = {Bulletin of the Geological Society of Denmark},
  year = {2020},
  volume = {68},
  pages = {245--253},
  url = {https://doi.org/10.37570/bgsd-2020-68-11 https://2dgf.dk/publikationer/bulletin/bulletin-volume-68-2020/#11},
  doi = {https://doi.org/10.37570/bgsd-2020-68-11}
}
</pre></td>
</tr>
<tr id="Monaenkova2020" class="entry">
	<td>Monaenkova, D., Deese, D., Schuette, C. and Thorseth, M.</td>
	<td>Laboratory Scale Photogrammetry: Micro- and Macroscopic 3D Surface Imaging <p class="infolinks">[<a href="javascript:toggleInfo('Monaenkova2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Microscopy and Microanalysis<br/>Vol. 26(S2), pp. 1170-1171&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1017/S1431927620017201">DOI</a> <a href="https://www.cambridge.org/core/product/identifier/S1431927620017201/type/journal_article">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Monaenkova2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Monaenkova2020,
  author = {Monaenkova, Daria and Deese, Diana and Schuette, Chad and Thorseth, Matthew},
  title = {Laboratory Scale Photogrammetry: Micro- and Macroscopic 3D Surface Imaging},
  journal = {Microscopy and Microanalysis},
  year = {2020},
  volume = {26},
  number = {S2},
  pages = {1170--1171},
  url = {https://www.cambridge.org/core/product/identifier/S1431927620017201/type/journal_article},
  doi = {https://doi.org/10.1017/S1431927620017201}
}
</pre></td>
</tr>
<tr id="Moreno2020" class="entry">
	<td>Moreno, C.R.</td>
	<td>Playfood AR <p class="infolinks">[<a href="javascript:toggleInfo('Moreno2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 58<i>School</i>: Universitat Jaume I&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Moreno2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Moreno2020,
  author = {Moreno, Carlos Requena},
  title = {Playfood AR},
  school = {Universitat Jaume I},
  year = {2020},
  pages = {58}
}
</pre></td>
</tr>
<tr id="Munster2020" class="entry">
	<td>M&uuml;nster, S., Maiwald, F., Lehmann, C., Lazariv, T., Hofmann, M. and Niebling, F.</td>
	<td>An Automated Pipeline for a Browser-based, City-scale Mobile 4D VR Application based on Historical Images <p class="infolinks">[<a href="javascript:toggleInfo('Munster2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 2nd Workshop on Structuring and Understanding of Multimedia heritAge Contents, pp. 33-40&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3423323.3425748">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3423323.3425748">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Munster2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Munster2020,
  author = {M&uuml;nster, Sander and Maiwald, Ferdinand and Lehmann, Christoph and Lazariv, Taras and Hofmann, Mathias and Niebling, Florian},
  title = {An Automated Pipeline for a Browser-based, City-scale Mobile 4D VR Application based on Historical Images},
  booktitle = {Proceedings of the 2nd Workshop on Structuring and Understanding of Multimedia heritAge Contents},
  publisher = {ACM},
  year = {2020},
  pages = {33--40},
  url = {https://dl.acm.org/doi/10.1145/3423323.3425748},
  doi = {https://doi.org/10.1145/3423323.3425748}
}
</pre></td>
</tr>
<tr id="Nallapu2020" class="entry">
	<td>teja Nallapu, R.</td>
	<td>Automated Swarm Design Architectures for Reconnaissance of Small Bodies <p class="infolinks">[<a href="javascript:toggleInfo('Nallapu2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: University of Arizona&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://repository.arizona.edu/handle/10150/656752">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Nallapu2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Nallapu2020,
  author = {teja Nallapu, Ravi},
  title = {Automated Swarm Design Architectures for Reconnaissance of Small Bodies},
  school = {University of Arizona},
  year = {2020},
  url = {https://repository.arizona.edu/handle/10150/656752}
}
</pre></td>
</tr>
<tr id="Ndiege2020" class="entry">
	<td>Ndiege, H.S.</td>
	<td>Billboard Measurements using Oblique UAV Images for Improved Revenue Collection <p class="infolinks">[<a href="javascript:toggleInfo('Ndiege2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 63<i>School</i>: University of Nairobi&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="http://erepository.uonbi.ac.ke/handle/11295/153093">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Ndiege2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Ndiege2020,
  author = {Ndiege, Hezron S},
  title = {Billboard Measurements using Oblique UAV Images for Improved Revenue Collection},
  school = {University of Nairobi},
  year = {2020},
  pages = {63},
  doi = {http://erepository.uonbi.ac.ke/handle/11295/153093}
}
</pre></td>
</tr>
<tr id="Neto2020" class="entry">
	<td>Neto, O.A. and Marianne Costa</td>
	<td>Capturing The Environment: using photogrammetry to register the built environment for simulation <p class="infolinks">[<a href="javascript:toggleInfo('Neto2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 24th Conference of the Iberoamerican Society of Digital Graphics&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://papers.cumincad.org/cgi-bin/works/paper/sigradi2020_418">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Neto2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Neto2020,
  author = {Neto, Olavo Avalone and Marianne Costa},
  title = {Capturing The Environment: using photogrammetry to register the built environment for simulation},
  booktitle = {Proceedings of the 24th Conference of the Iberoamerican Society of Digital Graphics},
  year = {2020},
  url = {http://papers.cumincad.org/cgi-bin/works/paper/sigradi2020_418}
}
</pre></td>
</tr>
<tr id="Nightingale2020" class="entry">
	<td>Nightingale, R.C., Ross, M.T., Allenby, M.C., Woodruff, M.A. and Powell, S.K.</td>
	<td>A Method for Economical Smartphone‐Based Clinical 3D Facial Scanning <p class="infolinks">[<a href="javascript:toggleInfo('Nightingale2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Journal of Prosthodontics<br/>Vol. 29(9), pp. 818-825&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1111/jopr.13274">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1111/jopr.13274">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Nightingale2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Nightingale2020,
  author = {Nightingale, Renee Christine and Ross, Maureen Therese and Allenby, Mark Colin and Woodruff, Maria Ann and Powell, Sean Keiran},
  title = {A Method for Economical Smartphone‐Based Clinical 3D Facial Scanning},
  journal = {Journal of Prosthodontics},
  year = {2020},
  volume = {29},
  number = {9},
  pages = {818--825},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/jopr.13274},
  doi = {https://doi.org/10.1111/jopr.13274}
}
</pre></td>
</tr>
<tr id="Nihal2020" class="entry">
	<td>Nihal, A.S.</td>
	<td>Improvement of Photogrammetry by Hyperspectral Imaging <p class="infolinks">[<a href="javascript:toggleInfo('Nihal2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: UNIVERSITY OF EASTERN FINLAND&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://erepo.uef.fi/bitstream/handle/123456789/23624/urn_nbn_fi_uef-20201434.pdf?sequence=-1">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Nihal2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Nihal2020,
  author = {Nihal, Arman Salik},
  title = {Improvement of Photogrammetry by Hyperspectral Imaging},
  school = {UNIVERSITY OF EASTERN FINLAND},
  year = {2020},
  url = {https://erepo.uef.fi/bitstream/handle/123456789/23624/urn_nbn_fi_uef-20201434.pdf?sequence=-1}
}
</pre></td>
</tr>
<tr id="Nomikou2020" class="entry">
	<td>Nomikou, P., Pehlivanides, G., El Saer, A., Karantzalos, K., Stentoumis, C., Bejelou, K., Antoniou, V., Douza, M., Vlasopoulos, O., Monastiridis, K. and Dura, A.</td>
	<td>Novel Virtual Reality Solutions for Captivating Virtual Underwater Tours Targeting the Cultural and Tourism Industries <p class="infolinks">[<a href="javascript:toggleInfo('Nomikou2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the 6th International Conference on Geographical Information Systems Theory, Applications and Management, pp. 7-13&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.5220/0009819700070013">DOI</a> <a href="http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0009819700070013">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Nomikou2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Nomikou2020,
  author = {Nomikou, Paraskevi and Pehlivanides, George and El Saer, A. and Karantzalos, Konstantinos and Stentoumis, Christos and Bejelou, Konstantina and Antoniou, Varvara and Douza, Maria and Vlasopoulos, Othonas and Monastiridis, Konstantinos and Dura, Anna},
  title = {Novel Virtual Reality Solutions for Captivating Virtual Underwater Tours Targeting the Cultural and Tourism Industries},
  booktitle = {Proceedings of the 6th International Conference on Geographical Information Systems Theory, Applications and Management},
  publisher = {SCITEPRESS - Science and Technology Publications},
  year = {2020},
  pages = {7--13},
  url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0009819700070013},
  doi = {https://doi.org/10.5220/0009819700070013}
}
</pre></td>
</tr>
<tr id="Oersen2020" class="entry">
	<td>Oersen, C., Wyngaard, R. and Nkabinde, L.</td>
	<td>An Immersive Mobile Application for Improved Learning and Virtual Tour Experience: A Nature Reserve Perspective <p class="infolinks">[<a href="javascript:toggleInfo('Oersen2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Oersen2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the ITU Kaleidoscope: Industry-Driven Digital Transformation, ITU K 2020&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.23919/ITUK50268.2020.9303226">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Oersen2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The purpose of this study was to develop an immersive virtual reality application for the University of Western Cape's nature reserve in South Africa. For this focus on a nature reserve project, the project team was requested to build a self-guided tour capable of achieving knowledge transfer, and which has aesthetic pleasure. The study was informed by the peculiar challenge of the nature reserve and existing literature to identify gaps that may occur in the body of knowledge. The scrum project methodology was used to manage the life cycle of the project. The application was successfully built within the given time frame and the client's feedback was overwhelmingly positive.</td>
</tr>
<tr id="bib_Oersen2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Oersen2020,
  author = {Oersen, Carmenita and Wyngaard, Ruchen and Nkabinde, Lebogang},
  title = {An Immersive Mobile Application for Improved Learning and Virtual Tour Experience: A Nature Reserve Perspective},
  booktitle = {Proceedings of the ITU Kaleidoscope: Industry-Driven Digital Transformation, ITU K 2020},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  doi = {https://doi.org/10.23919/ITUK50268.2020.9303226}
}
</pre></td>
</tr>
<tr id="Pamart2020" class="entry">
	<td>Pamart, A., Morlet, F., De Luca, L. and Veron, P.</td>
	<td>A Robust and Versatile Pipeline for Automatic Photogrammetric-Based Registration of Multimodal Cultural Heritage Documentation <p class="infolinks">[<a href="javascript:toggleInfo('Pamart2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pamart2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('Pamart2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Remote Sensing<br/>Vol. 12(12), pp. 2051&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/rs12122051">DOI</a> <a href="https://www.mdpi.com/2072-4292/12/12/2051">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pamart2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Imaging techniques and Image Based-Modeling (IBM) practices in the field of Cultural Heritage (CH) studies are nowadays no longer used as one-shot applications but as various and complex scenarios involving multiple modalities; sensors, scales, spectral bands and temporalities utilized by various experts. Current use of Structure from Motion and photogrammetric methods necessitates some improvements in iterative registration to ease the growing complexity in the management of the scientific imaging applied on heritage assets. In this context, the co-registration of photo-documentation among other imaging resources is a key step in order to move towards data fusion and collaborative semantic enrichment scenarios. This paper presents the recent development of a Totally Automated Co-registration and Orientation library (TACO) based on the interoperability of open-source solutions to conduct photogrammetric-based registration. The proposed methodology addresses and solves some gaps in term of robustness and versatility in the field of incremental and global orientation of image-sets dedicated to CH practices.</td>
</tr>
<tr id="rev_Pamart2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Short mentioning of CCTAG and AliceVision</td>
</tr>
<tr id="bib_Pamart2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pamart2020,
  author = {Pamart, Anthony and Morlet, François and De Luca, Livio and Veron, Philippe},
  title = {A Robust and Versatile Pipeline for Automatic Photogrammetric-Based Registration of Multimodal Cultural Heritage Documentation},
  journal = {Remote Sensing},
  publisher = {Multidisciplinary Digital Publishing Institute},
  year = {2020},
  volume = {12},
  number = {12},
  pages = {2051},
  url = {https://www.mdpi.com/2072-4292/12/12/2051},
  doi = {https://doi.org/10.3390/rs12122051}
}
</pre></td>
</tr>
<tr id="Perry2020" class="entry">
	<td>Perry, B.J., Guo, Y., Atadero, R. and van de Lindt, J.W.</td>
	<td>Streamlined bridge inspection system utilizing unmanned aerial vehicles (UAVs) and machine learning <p class="infolinks">[<a href="javascript:toggleInfo('Perry2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Measurement<br/>Vol. 164, pp. 108048&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.measurement.2020.108048">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0263224120305868">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Perry2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Perry2020,
  author = {Perry, Brandon J. and Guo, Yanlin and Atadero, Rebecca and van de Lindt, John W.},
  title = {Streamlined bridge inspection system utilizing unmanned aerial vehicles (UAVs) and machine learning},
  journal = {Measurement},
  year = {2020},
  volume = {164},
  pages = {108048},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224120305868},
  doi = {https://doi.org/10.1016/j.measurement.2020.108048}
}
</pre></td>
</tr>
<tr id="Pietroszek2020" class="entry">
	<td>Pietroszek, K.</td>
	<td>"Vera" - Crossing the Fourth Wall <p class="infolinks">[<a href="javascript:toggleInfo('Pietroszek2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-4&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3334480.3383178">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3334480.3383178">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Pietroszek2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pietroszek2020,
  author = {Pietroszek, Krzysztof},
  title = {"Vera" - Crossing the Fourth Wall},
  booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  publisher = {ACM},
  year = {2020},
  pages = {1--4},
  url = {https://dl.acm.org/doi/10.1145/3334480.3383178},
  doi = {https://doi.org/10.1145/3334480.3383178}
}
</pre></td>
</tr>
<tr id="Polic2020" class="entry">
	<td>Polic, M., Steidl, S., Albl, C., Kukelova, Z. and Pajdla, T.</td>
	<td>Uncertainty Based Camera Model Selection <p class="infolinks">[<a href="javascript:toggleInfo('Polic2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5990-5999&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/CVPR42600.2020.00603">DOI</a> <a href="https://ieeexplore.ieee.org/document/9156313/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Polic2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Polic2020,
  author = {Polic, Michal and Steidl, Stanislav and Albl, Cenek and Kukelova, Zuzana and Pajdla, Tomas},
  title = {Uncertainty Based Camera Model Selection},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher = {IEEE},
  year = {2020},
  pages = {5990--5999},
  url = {https://ieeexplore.ieee.org/document/9156313/},
  doi = {https://doi.org/10.1109/CVPR42600.2020.00603}
}
</pre></td>
</tr>
<tr id="Poux2020" class="entry">
	<td>Poux, F., Valembois, Q., Mattes, C., Kobbelt, L. and Billen, R.</td>
	<td>Initial User-Centered Design of a Virtual Reality Heritage System: Applications for Digital Tourism <p class="infolinks">[<a href="javascript:toggleInfo('Poux2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Poux2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Remote Sensing<br/>Vol. 12(16), pp. 2583&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/rs12162583">DOI</a> <a href="https://www.mdpi.com/2072-4292/12/16/2583">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Poux2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Reality capture allows for the reconstruction, with a high accuracy, of the physical reality of cultural heritage sites. Obtained 3D models are often used for various applications such as promotional content creation, virtual tours, and immersive experiences. In this paper, we study new ways to interact with these high-quality 3D reconstructions in a real-world scenario. We propose a user-centric product design to create a virtual reality (VR) application specifically intended for multi-modal purposes. It is applied to the castle of Jehay (Belgium), which is under renovation, to permit multi-user digital immersive experiences. The article proposes a high-level view of multi-disciplinary processes, from a needs analysis to the 3D reality capture workflow and the creation of a VR environment incorporated into an immersive application. We provide several relevant VR parameters for the scene optimization, the locomotion system, and the multi-user environment definition that were tested in a heritage tourism context.</td>
</tr>
<tr id="bib_Poux2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Poux2020,
  author = {Poux, Florent and Valembois, Quentin and Mattes, Christian and Kobbelt, Leif and Billen, Roland},
  title = {Initial User-Centered Design of a Virtual Reality Heritage System: Applications for Digital Tourism},
  journal = {Remote Sensing},
  year = {2020},
  volume = {12},
  number = {16},
  pages = {2583},
  url = {https://www.mdpi.com/2072-4292/12/16/2583},
  doi = {https://doi.org/10.3390/rs12162583}
}
</pre></td>
</tr>
<tr id="Rasmuson2020" class="entry">
	<td>Rasmuson, S., Sintorn, E. and Assarsson, U.</td>
	<td>User-guided 3D reconstruction using multi-view stereo <p class="infolinks">[<a href="javascript:toggleInfo('Rasmuson2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('Rasmuson2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Symposium on Interactive 3D Graphics and Games, pp. 1-9&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3384382.3384530">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3384382.3384530">URL</a>&nbsp;</td>
</tr>
<tr id="rev_Rasmuson2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: The results from the reconstructions will primarily be compared to the output of the automatic reconstruction software Meshroom</td>
</tr>
<tr id="bib_Rasmuson2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Rasmuson2020,
  author = {Rasmuson, Sverker and Sintorn, Erik and Assarsson, Ulf},
  title = {User-guided 3D reconstruction using multi-view stereo},
  booktitle = {Symposium on Interactive 3D Graphics and Games},
  publisher = {ACM},
  year = {2020},
  pages = {1--9},
  url = {https://dl.acm.org/doi/10.1145/3384382.3384530},
  doi = {https://doi.org/10.1145/3384382.3384530}
}
</pre></td>
</tr>
<tr id="RosellTarrago2020" class="entry">
	<td>Rosell Tarrag&oacute;, M.</td>
	<td>Design of a 3D photogrammetry acquisition system and data processing workflow automation <p class="infolinks">[<a href="javascript:toggleInfo('RosellTarrago2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: Universitat de Lleida&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="http://hdl.handle.net/10459.1/70339.">URL</a>&nbsp;</td>
</tr>
<tr id="bib_RosellTarrago2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{RosellTarrago2020,
  author = {Rosell Tarrag&oacute;, Miquel},
  title = {Design of a 3D photogrammetry acquisition system and data processing workflow automation},
  school = {Universitat de Lleida},
  year = {2020},
  url = {http://hdl.handle.net/10459.1/70339.}
}
</pre></td>
</tr>
<tr id="Rossman2020" class="entry">
	<td>Rossman, M.</td>
	<td>Simulating a Mixed Reality Memory Palace <p class="infolinks">[<a href="javascript:toggleInfo('Rossman2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>, pp. 24<i>School</i>: College of Information and Computer Sciences&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://old.mattrossman.com/file/honors-thesis.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Rossman2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Rossman2020,
  author = {Rossman, Matthew},
  title = {Simulating a Mixed Reality Memory Palace},
  school = {College of Information and Computer Sciences},
  year = {2020},
  pages = {24},
  url = {https://old.mattrossman.com/file/honors-thesis.pdf}
}
</pre></td>
</tr>
<tr id="Sengupta2020" class="entry">
	<td>Sengupta, A., Lagneau, R., Krupa, A., Marchand, E. and Marchal, M.</td>
	<td>Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects <p class="infolinks">[<a href="javascript:toggleInfo('Sengupta2020','comment')">Comment</a>] [<a href="javascript:toggleInfo('Sengupta2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 10038-10044&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICRA40945.2020.9196770">DOI</a> <a href="https://ieeexplore.ieee.org/document/9196770/, https://hal.inria.fr/hal-02495831/document">URL</a>&nbsp;</td>
</tr>
<tr id="rev_Sengupta2020" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Meshroom was used to generate a 3d mesh used for other studies (short mention)</td>
</tr>
<tr id="bib_Sengupta2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Sengupta2020,
  author = {Sengupta, Agniva and Lagneau, Romain and Krupa, Alexandre and Marchand, Eric and Marchal, Maud},
  title = {Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  publisher = {IEEE},
  year = {2020},
  pages = {10038--10044},
  url = {https://ieeexplore.ieee.org/document/9196770/, https://hal.inria.fr/hal-02495831/document},
  doi = {https://doi.org/10.1109/ICRA40945.2020.9196770}
}
</pre></td>
</tr>
<tr id="Shariq2020" class="entry">
	<td>Shariq, M.H. and Hughes, B.R.</td>
	<td>Revolutionising building inspection techniques to meet large-scale energy demands: A review of the state-of-the-art <p class="infolinks">[<a href="javascript:toggleInfo('Shariq2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Renewable and Sustainable Energy Reviews<br/>Vol. 130, pp. 109979&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.rser.2020.109979">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S1364032120302707">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Shariq2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Shariq2020,
  author = {Shariq, M. Hasan and Hughes, Ben Richard},
  title = {Revolutionising building inspection techniques to meet large-scale energy demands: A review of the state-of-the-art},
  journal = {Renewable and Sustainable Energy Reviews},
  year = {2020},
  volume = {130},
  pages = {109979},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364032120302707},
  doi = {https://doi.org/10.1016/j.rser.2020.109979}
}
</pre></td>
</tr>
<tr id="Valero2020" class="entry">
	<td>Valero, E., Mohanty, D.D. and Bosch&eacute;, F.</td>
	<td>Development of an Open-source Scan+BIM Platform <p class="infolinks">[<a href="javascript:toggleInfo('Valero2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Valero2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><br/>Vol. 2020Proceedings of the International Symposium on Automation and Robotics in Construction, pp. 223-232&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Valero2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In the last decade, a significant amount of research and development has been conducted at the intersection of Building Information Modelling (BIM) and reality capture data processing, mainly in the two areas often referred to as 'Scan-to-BIM' and 'Scan-vs-BIM'. Interestingly, it appears that all these advances have been made without the availability of any libre, cost-free and ideally open-source software platform that can handle both reality capture data (typically 3D point clouds and images) and Building Information Models. This paper investigates user demands and possible alternative options to develop such a Scan+BIM platform to further stimulate research in the field. A set of requirements for such a platform are first identified by means of a questionnaire sent to researchers and industry practitioners. Different software applications, identified from the literature and online, are then assessed against those requirements. A final ranking of these applications is conducted and one suitable solution is identified and suggested for development. The proposed solution combines the OpenInfra Platform, as a BIM and point cloud engine and viewer, and the xBIM Toolkit to provide complementary tools for the BIM engine. This new piece of software is currently under development and the authors intend to make it available to the Construction Informatics community soon.</td>
</tr>
<tr id="bib_Valero2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Valero2020,
  author = {Valero, Enrique and Mohanty, Dibya D and Bosch&eacute;, Fr&eacute;d&eacute;ric},
  title = {Development of an Open-source Scan+BIM Platform},
  booktitle = {Proceedings of the International Symposium on Automation and Robotics in Construction},
  publisher = {IAARC Publications},
  year = {2020},
  volume = {2020},
  pages = {223--232}
}
</pre></td>
</tr>
<tr id="VellaBamber2020" class="entry">
	<td>Vella Bamber, T.</td>
	<td>Enhancing 3D printing for repair: Designing a system that enhances the collaboration between repairers and makers <p class="infolinks">[<a href="javascript:toggleInfo('VellaBamber2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td><i>School</i>: Delft University of Technology&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_VellaBamber2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{VellaBamber2020,
  author = {Vella Bamber, Tomas},
  title = {Enhancing 3D printing for repair: Designing a system that enhances the collaboration between repairers and makers},
  school = {Delft University of Technology},
  year = {2020}
}
</pre></td>
</tr>
<tr id="Verykokou2020" class="entry">
	<td>Verykokou, S., Soile, S., Bourexis, F., Tokmakidis, P., Tokmakidis, K. and Ioannidis, C.</td>
	<td>A Comparative Analysis of Different Software Packages for 3D Modelling of Complex Geometries <p class="infolinks">[<a href="javascript:toggleInfo('Verykokou2020','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Verykokou2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)<br/>Vol. 12642 LNCS, pp. 228-240&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1007/978-3-030-73043-7_19">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-3-030-73043-7_19">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Verykokou2020" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The purpose of this paper is the investigation of the performance of four well-established commercial and open-source software packages for automated image-based 3D reconstruction of complex cultural and natural heritage sites, i.e., Agisoft Metashape, RealityCapture, MicMac and Meshroom. The case study is part of the inaccessible giant rock of St. Modestos, in the archaeological site of Meteora. In terms of computational time, the commercial software packages were the most time-efficient solutions, with Metashape being the fastest one. They also have a friendlier user interface, which makes them adoptable even by non-photogrammetrists. Αll four solutions yielded approximately comparable results in terms of accuracy and may be used for generation of 3D dense point clouds of complex sites. With the exception of Meshroom, they may produce georeferenced results. Also, with the exception of MicMac, which did not yield satisfactory results in terms of textured mesh, they may be used for generating photorealistic 3D models. The comparative analysis of the results achieved by the tested software will serve as the basis for establishing photogrammetric pipelines that may be generally used for 3D reconstruction of complex geometries.</td>
</tr>
<tr id="bib_Verykokou2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Verykokou2020,
  author = {Verykokou, Styliani and Soile, Sofia and Bourexis, Fotis and Tokmakidis, Panagiotis and Tokmakidis, Konstantinos and Ioannidis, Charalabos},
  title = {A Comparative Analysis of Different Software Packages for 3D Modelling of Complex Geometries},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher = {Springer, Cham},
  year = {2020},
  volume = {12642 LNCS},
  pages = {228--240},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-73043-7_19},
  doi = {https://doi.org/10.1007/978-3-030-73043-7_19}
}
</pre></td>
</tr>
<tr id="Wang2020" class="entry">
	<td>Wang, C.Y., Bai, S. and Won, A.S.</td>
	<td>ReliveReality: Enabling Socially Reliving Experiences in Virtual Reality via a Single RGB camera <p class="infolinks">[<a href="javascript:toggleInfo('Wang2020','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), pp. 710-711&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/VRW50115.2020.00206">DOI</a> <a href="https://ieeexplore.ieee.org/document/9090534/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Wang2020" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Wang2020,
  author = {Wang, Cheng Yao and Bai, Shengguang and Won, Andrea Stevenson},
  title = {ReliveReality: Enabling Socially Reliving Experiences in Virtual Reality via a Single RGB camera},
  booktitle = {Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
  publisher = {IEEE},
  year = {2020},
  pages = {710--711},
  url = {https://ieeexplore.ieee.org/document/9090534/},
  doi = {https://doi.org/10.1109/VRW50115.2020.00206}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Fleischer DirkKostkanová, V.U.T.</td>
	<td>Digitale Chancen in der Messtechnik: LowCost-Ansätze für komplexe Messaufgaben am Beispiel des Modelldeichs der TU Dresden <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>Conference Paper&nbsp;</td>
	<td>misc</td>
	<td><a href="https://henry.baw.de/bitstream/20.500.11970/107067/1/27_Fleischer.pdf, https://hdl.handle.net/20.500.11970/107067">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Innovationen in der Photogrammetrie ermöglichen die kosten- und anwen-
<br>derfreundliche  Erstellung  von  3D-Oberflächenmodellen  zur  Visualisierung 
<br>der  freigelegten  Injektionskörper.  Dies  in  Korrelation  mit  geotechnischen, 
<br>geoelektrischen und geohydraulischen Untersuchungen erschließt neue 
<br>Wege zur Analyse volumenverändernder Prozesse in der Bautechnik.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Meshroom used for 3D reconstruction (short mentioning)</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Fleischer, DirkKostkanová, VladislavaHelbig, UlfTintelnotGötzHohlfeld, Thomas},
  title = {Digitale Chancen in der Messtechnik: LowCost-Ansätze für komplexe Messaufgaben am Beispiel des Modelldeichs der TU Dresden},
  year = {2020},
  note = {Dresdner Wasserbauliche Mitteilungen 63},
  url = {https://henry.baw.de/bitstream/20.500.11970/107067/1/27_Fleischer.pdf, https://hdl.handle.net/20.500.11970/107067}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Wang, T.</td>
	<td>基于sfm算法的三维重建软件集成 <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>&nbsp;</td>
	<td>book</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: 3D reconstruction is an application of the photogrammetry, photos are projection 
<br>of 3D objects, the photogrammetry exploits information contained in non-ordered 
<br>photos to reverse the process. Objects generated by 3D reconstruction program are 
<br>likely to used in fields like VR. The main algorithm used by 3D reconstruction is the 
<br>structure-from-motion algorithm, implemented by some open source computer vision 
<br>frameworks. And Applications  based  on  those  frameworks  work  just  fine,  their 
<br>disadvantages are: having holes in the generated objects, extra software is needed to 
<br>fill them, bjects generated by the software have too many polygons, extra software is 
<br>needed to retopology those objects and the generating process is too much more time 
<br>consuming.  The  project  mentioned  in  this  article  aims  to  deal  with  the 
<br>importing/exporting  process  when  filling  the  holes  and  running  retopology  and 
<br>incompatibility  brought  by  the  process  by  integrating  extra  software  into  the 
<br>meshroom reconstruction pipline.</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: InstantMeshes and DracoEncoder/Decoder plugins for Meshroom, available on Github by @TigerVsT.
<br>Thesis is not published online.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@book{,
  author = {Tao Wang},
  title = {基于sfm算法的三维重建软件集成},
  year = {2020}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>AliceVision</td>
	<td>Tutorial: Meshroom for Beginners <p class="infolinks">[<a href="javascript:toggleInfo('','comment')">Comment</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://sketchfab.com/blogs/community/tutorial-meshroom-for-beginners">URL</a>&nbsp;</td>
</tr>
<tr id="rev_" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Detailed tutorial with a focus on the features of the 2019.1 release.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {AliceVision},
  title = {Tutorial: Meshroom for Beginners},
  year = {2020},
  url = {https://sketchfab.com/blogs/community/tutorial-meshroom-for-beginners}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>FXhome</td>
	<td>Creating a 3D digital double in Blender &amp; Meshroom | Blender Part 1 <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>video&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=bX_1q0N-EHE">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In Rise of the Dark Side, you will have seen an awesome ragdoll simulation showing one of our rebels getting thrown against a tree! In this tutorial, we're taking a look at how Meshroom and Blender were used to create a convincing 3D digital double of Oli along with info on rigging the model and creating the final simulation.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {FXhome},
  title = {Creating a 3D digital double in Blender &amp; Meshroom | Blender Part 1},
  year = {2020},
  url = {https://www.youtube.com/watch?v=bX_1q0N-EHE}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>TylerGibbonsArt</td>
	<td>3D Photoscanning - Optimizing Meshroom Photoscans <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.youtube.com/watch?v=J3esNV0wXAo">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In this video we walk through some easy ways to simplify and improve our photoscans from Meshroom.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {TylerGibbonsArt},
  title = {3D Photoscanning - Optimizing Meshroom Photoscans},
  year = {2020},
  url = {https://www.youtube.com/watch?v=J3esNV0wXAo}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Horan, G.</td>
	<td>Photogrammetry with your phone <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2020</td>
	<td>blog&nbsp;</td>
	<td>misc</td>
	<td><a href="https://hackspace.raspberrypi.org/articles/photogrammetry-with-your-phone">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We’re going to run you through the entire workflow from photos to 3D print using a statue as an example. We’ll be using Meshroom, which is fully open-source, and is set up out of the box for use by beginners to photogrammetry.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Glenn Horan},
  title = {Photogrammetry with your phone},
  year = {2020},
  url = {https://hackspace.raspberrypi.org/articles/photogrammetry-with-your-phone}
}
</pre></td>
</tr>
<tr id="10.1007/978-3-030-70740-8_13" class="entry">
	<td>Pivo, T. and P\v{c}il, L.</td>
	<td>Stereo Camera Simulation in Blender <p class="infolinks">[<a href="javascript:toggleInfo('10.1007/978-3-030-70740-8_13','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('10.1007/978-3-030-70740-8_13','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Modelling and Simulation for Autonomous Systems, pp. 206-216&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_10.1007/978-3-030-70740-8_13" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The development and implementation of computer vision methods require an appropriate data-set of images for testing. Capturing real images is time-consuming, and it can be difficult in some applications. Furthermore, a precise measurement of distances and geometric transformations between camera positions for particular images is not always possible. In these cases, synthetic data can be beneficially used. Besides, they allow precisely setting camera positions and simulating various types of camera movements. The method for generation of stereo camera data-set is presented in this paper. It is built on the 3D creation suite Blender. The method is designed for visual odometry and 3D reconstruction testing, and it simulates a stereo camera movement over the captured 3D model. The images are directly inputted to the tested system. Together with the known ground truth of camera positions, they allow testing particular steps of the system. The proposed method was used for testing 3D reconstruction of a camera-based car undercarriages scanner.</td>
</tr>
<tr id="bib_10.1007/978-3-030-70740-8_13" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{10.1007/978-3-030-70740-8_13,
  author = {Pivo, Tom&aacute;&scaron; and P\v{c}il, Libor},
  title = {Stereo Camera Simulation in Blender},
  booktitle = {Modelling and Simulation for Autonomous Systems},
  publisher = {Springer International Publishing},
  year = {2021},
  pages = {206--216}
}
</pre></td>
</tr>
<tr id="10.1007/978-3-030-86362-3_31" class="entry">
	<td>Gao, Y., Tebbe, J. and Zell, A.</td>
	<td>Robust Stroke Recognition via Vision and IMU in Robotic Table Tennis <p class="infolinks">[<a href="javascript:toggleInfo('10.1007/978-3-030-86362-3_31','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('10.1007/978-3-030-86362-3_31','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Artificial Neural Networks and Machine Learning -- ICANN 2021, pp. 379-390&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_10.1007/978-3-030-86362-3_31" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Stroke recognition in table tennis is a challenging task, due to the variety of the movements. Many different sensors have been adopted in robotic table tennis, with the goal of detecting the players' movements. In this paper, we propose a two-stage approach to directly recognize the table tennis racket's movement. A bounding box around the racket can be extracted from an RGB image in the first stage. An efficient and lightweight CNN architecture is then developed to regress the racket 3D position by fusion of the cropped image and the 3D rotation data from an IMU in the second stage. Together with the rotation data, a robust 6D racket pose is available at a frame rate 100 Hz. In the experiments, two datasets are collected from our KUKA table tennis robot for evaluation and comparisons, which show a position error of 4.7 cm at a range of 6 m. One behavior cloning experiment is performed in order to reveal the potential of this work.</td>
</tr>
<tr id="bib_10.1007/978-3-030-86362-3_31" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{10.1007/978-3-030-86362-3_31,
  author = {Gao, Yapeng and Tebbe, Jonas and Zell, Andreas},
  title = {Robust Stroke Recognition via Vision and IMU in Robotic Table Tennis},
  booktitle = {Artificial Neural Networks and Machine Learning -- ICANN 2021},
  publisher = {Springer International Publishing},
  year = {2021},
  pages = {379--390}
}
</pre></td>
</tr>
<tr id="10.2312:egt.20211035" class="entry">
	<td>Zell, E., Castan, F., Gasparini, S., Hilsmann, A., Kazhdan, M., Tagliasacchi, A., Zarpalas, D. and Zioulis, N.</td>
	<td>Volumetric Video - Acquisition, Compression, Interaction and Perception <p class="infolinks">[<a href="javascript:toggleInfo('10.2312:egt.20211035','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Eurographics 2021 - Tutorials&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.2312/egt.20211035">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_10.2312:egt.20211035" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{10.2312:egt.20211035,
  author = {Zell, Eduard and Castan, Fabien and Gasparini, Simone and Hilsmann, Anna and Kazhdan, Misha and Tagliasacchi, Andrea and Zarpalas, Dimitris and Zioulis, Nick},
  title = {Volumetric Video - Acquisition, Compression, Interaction and Perception},
  booktitle = {Eurographics 2021 - Tutorials},
  publisher = {The Eurographics Association},
  year = {2021},
  doi = {https://doi.org/10.2312/egt.20211035}
}
</pre></td>
</tr>
<tr id="Aldao2021" class="entry">
	<td>Aldao, E., Gonz&aacute;lez-Jorge, H. and P&eacute;rez, J.A.</td>
	<td>Metrological comparison of LiDAR and photogrammetric systems for deformation monitoring of aerospace parts <p class="infolinks">[<a href="javascript:toggleInfo('Aldao2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Aldao2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Measurement<br/>Vol. 174, pp. 109037&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/J.MEASUREMENT.2021.109037">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Aldao2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The inspection of airframes and aerodynamic surfaces is a very important task in aeronautical maintenance. Traditionally, this labor has always been carried out by maintenance personnel, who manually checked all the parts of the fuselage, which is a great cost for the airlines. This article evaluates the feasibility of implementing low cost portable 3D scanning systems to perform these inspection tasks easily and accurately. A metrological comparison among a LIDAR Kinect One sensor, a single digital camera Sony Alpha 6000 using photogrammetry software and a stereoscopic ZED camera was performed. Their behavior is characterized as well as their main sources of error to determine which technology is the most suitable for inspecting aeronautical surfaces. Kinect LIDAR sensor shows the most promising results and opens the possibility to apply this technology to aircraft maintenance tasks in future.</td>
</tr>
<tr id="bib_Aldao2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Aldao2021,
  author = {Aldao, E. and Gonz&aacute;lez-Jorge, H. and P&eacute;rez, J. A.},
  title = {Metrological comparison of LiDAR and photogrammetric systems for deformation monitoring of aerospace parts},
  journal = {Measurement},
  publisher = {Elsevier},
  year = {2021},
  volume = {174},
  pages = {109037},
  doi = {https://doi.org/10.1016/J.MEASUREMENT.2021.109037}
}
</pre></td>
</tr>
<tr id="Antoniou_2021" class="entry">
	<td>Antoniou, V., Nomikou, P., Papaspyropoulos, K., Karatzaferis, O., Vlasopoulos, O., Stentoumis, C. and Kalisperakis, I.</td>
	<td>A Journey to Salamis Island (Greece) using a GIS Tailored Interactive Story Map Application <p class="infolinks">[<a href="javascript:toggleInfo('Antoniou_2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Antoniou_2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 7th International Conference on Geographical Information Systems Theory, Applications and Management&nbsp;</td>
	<td>misc</td>
	<td><a href="https://doi.org/10.5220/0010440701870194">DOI</a> <a href="https://www.scitepress.org/Papers/2021/104407/104407.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Antoniou_2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Web GIS applications have been used to communicate and showcase spatial information to the general public. 
<br>In the demonstrated Web GIS application, the aim was to highlight the importance of a historic area, Salamis 
<br>island (Greece), through its natural and anthropogenic environment using narrative text, multimedia, and web 
<br>content  as  well  as  geospatial  data  and  3D  visualization.  Using  StoryMaps,  a  widespread  geographical 
<br>visualization  approach,  used  for  science  and  spatial  data  communication,  information,  education,  and 
<br>dissemination, new functions combining many scientific fields were integrated, producing an interactive 
<br>responsive web app in such a way that scientific knowledge can be received and comprehended by a broader 
<br>audience.</td>
</tr>
<tr id="bib_Antoniou_2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{Antoniou_2021,
  author = {Varvara Antoniou and Paraskevi Nomikou and Konstantinos Papaspyropoulos and Odysseas Karatzaferis and Othonas Vlasopoulos and Christos Stentoumis and Ilias Kalisperakis},
  title = {A Journey to Salamis Island (Greece) using a GIS Tailored Interactive Story Map Application},
  booktitle = {Proceedings of the 7th International Conference on Geographical Information Systems Theory, Applications and Management},
  publisher = {SCITEPRESS - Science and Technology Publications},
  year = {2021},
  url = {https://www.scitepress.org/Papers/2021/104407/104407.pdf},
  doi = {https://doi.org/10.5220/0010440701870194}
}
</pre></td>
</tr>
<tr id="Antoniou2021" class="entry">
	<td>Antoniou, V., Nomikou, P., Papaspyropoulos, K., Karatzaferis, O., Vlasopoulos, O., Stentoumis, C. and Kalisperakis, I.</td>
	<td>A Journey to Salamis Island (Greece) using a GIS Tailored Interactive Story Map Application <p class="infolinks">[<a href="javascript:toggleInfo('Antoniou2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 7th International Conference on Geographical Information Systems Theory, Applications and Management, pp. 187-194&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.5220/0010440701870194">DOI</a> <a href="https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010440701870194">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Antoniou2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Antoniou2021,
  author = {Antoniou, Varvara and Nomikou, Paraskevi and Papaspyropoulos, Konstantinos and Karatzaferis, Odysseas and Vlasopoulos, Othonas and Stentoumis, Christos and Kalisperakis, Ilias},
  title = {A Journey to Salamis Island (Greece) using a GIS Tailored Interactive Story Map Application},
  booktitle = {Proceedings of the 7th International Conference on Geographical Information Systems Theory, Applications and Management},
  publisher = {SCITEPRESS - Science and Technology Publications},
  year = {2021},
  pages = {187--194},
  url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010440701870194},
  doi = {https://doi.org/10.5220/0010440701870194}
}
</pre></td>
</tr>
<tr id="Ashokkumar2021" class="entry">
	<td>Ashokkumar, A.</td>
	<td>Creation of 3D models of objects using alternative applications Master Thesis <p class="infolinks">[<a href="javascript:toggleInfo('Ashokkumar2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td><i>School</i>: Technical University of Liberec&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://doi.org/10.1016/j.cad.2010.11.005">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Ashokkumar2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Ashokkumar2021,
  author = {Ashokkumar, Akhilesh},
  title = {Creation of 3D models of objects using alternative applications Master Thesis},
  school = {Technical University of Liberec},
  year = {2021},
  doi = {https://doi.org/10.1016/j.cad.2010.11.005}
}
</pre></td>
</tr>
<tr id="Azevedo2021" class="entry">
	<td>Azevedo, J., Faria, P. and Romero, L.</td>
	<td>Framework for Creating Outdoors Augmented and Virtual Reality <p class="infolinks">[<a href="javascript:toggleInfo('Azevedo2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 16th Iberian Conference on Information Systems and Technologies (CISTI), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.23919/CISTI52073.2021.9476541">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Azevedo2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Azevedo2021,
  author = {Azevedo, Joao and Faria, Pedro and Romero, Luis},
  title = {Framework for Creating Outdoors Augmented and Virtual Reality},
  booktitle = {Proceedings of the 16th Iberian Conference on Information Systems and Technologies (CISTI)},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2021},
  pages = {1--6},
  doi = {https://doi.org/10.23919/CISTI52073.2021.9476541}
}
</pre></td>
</tr>
<tr id="Azpurua2021" class="entry">
	<td>Azp&uacute;rua, H., Rezende, A., Potje, G., J&uacute;nior, G.P.d.C., Fernandes, R., Miranda, V., Filho, L.W.d.R., Domingues, J., Rocha, F., de Sousa, F.L.M., de Barros, L.G.D., Nascimento, E.R., Macharet, D.G., Pessin, G. and Freitas, G.M.</td>
	<td>Towards Semi-autonomous Robotic Inspection and Mapping in Confined Spaces with the EspeleoRob&ocirc; <p class="infolinks">[<a href="javascript:toggleInfo('Azpurua2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Azpurua2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Intelligent &amp; Robotic Systems 2021 101:4<br/>Vol. 101(4), pp. 1-27&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1007/S10846-021-01321-5">DOI</a> <a href="https://link.springer.com/article/10.1007/s10846-021-01321-5">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Azpurua2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Autonomous mobile devices operating in confined environments, such as pipes, underground tunnel systems, and cave networks, face multiple open challenges from the robotics perspective. Those challenges, such as mobility, localization, and mapping in GPS denied scenarios, are receiving particular attention from the academy and industry. One example is the Brazilian mining company Vale S.A., which is employing a robot – EspeleoRob&ocirc; (SpeleoRobot) – to access restricted and dangerous areas for human workers. The EspeleoRob&ocirc; is a robot initially designed for natural cave inspection during teleoperated missions. It is now being used to monitor other types of confined environments, such as dam galleries and other restrained or dangerous areas. This paper describes the platform in its current version and the pipeline used for semi-autonomous inspection in confined environments. The pipeline includes photorealistic mapping techniques, Simultaneous Localization and Mapping (SLAM) with LiDAR, path planning based on mobility optimization, and navigation control using vector fields to reduce operator dependency of the robot operation. The proposed concept was validated in simulations with a realistic underground tunnel system and in representative real-world scenarios. The results endorse the viability of using the proposed concept for real deployments.</td>
</tr>
<tr id="bib_Azpurua2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Azpurua2021,
  author = {Azp&uacute;rua, H&eacute;ctor and Rezende, Adriano and Potje, Guilherme and J&uacute;nior, Gilmar Pereira da Cruz and Fernandes, Rafael and Miranda, Victor and Filho, Levi Welington de Resende and Domingues, Jac&oacute; and Rocha, Filipe and de Sousa, Frederico Luiz Martins and de Barros, Luiz Guilherme Dias and Nascimento, Erickson R. and Macharet, Douglas G. and Pessin, Gustavo and Freitas, Gustavo M.},
  title = {Towards Semi-autonomous Robotic Inspection and Mapping in Confined Spaces with the EspeleoRob&ocirc;},
  journal = {Journal of Intelligent &amp; Robotic Systems 2021 101:4},
  publisher = {Springer},
  year = {2021},
  volume = {101},
  number = {4},
  pages = {1--27},
  url = {https://link.springer.com/article/10.1007/s10846-021-01321-5},
  doi = {https://doi.org/10.1007/S10846-021-01321-5}
}
</pre></td>
</tr>
<tr id="Barszcz2021" class="entry">
	<td>Barszcz, M., Montusiewicz, J., Pa&#347;nikowska-&Lstrok;ukaszuk, M. and Sa&lstrok;amacha, A.</td>
	<td>Comparative Analysis of Digital Models of Objects of Cultural Heritage Obtained by the “3D SLS” and “SfM” Methods <p class="infolinks">[<a href="javascript:toggleInfo('Barszcz2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Barszcz2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Applied Sciences<br/>Vol. 11(12), pp. 5321&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/app11125321">DOI</a> <a href="https://www.mdpi.com/2076-3417/11/12/5321">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Barszcz2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: In the era of the global pandemic caused by the COVID-19 virus, 3D digitisation of selected museum artefacts is becoming more and more frequent practice, but the vast majority is performed by specialised teams. The paper presents the results of comparative studies of 3D digital models of the same museum artefacts from the Silk Road area generated by two completely different technologies: Structure from Motion (SfM)—a method belonging to the so-called low-cost technologies—and by Structured-light 3D Scanning (3D SLS). Moreover, procedural differences in data acquisition and their processing to generate three-dimensional models are presented. Models built using a point cloud were created from data collected in the Afrasiyab museum in Samarkand (Uzbekistan) during “The 1st Scientific Expedition of the Lublin University of Technology to Central Asia” in 2017. Photos for creating 3D models in SfM technology were taken during a virtual expedition carried out under the “3D Digital Silk Road” program in 2021. The obtained results show that the quality of the 3D models generated with SfM differs from the models from the technology (3D SLS), but they may be placed in the galleries of the vitrual museum. The obtained models from SfM do not have information about their size, which means that they are not fully suitable for archiving purposes of cultural heritage, unlike the models from SLS.</td>
</tr>
<tr id="bib_Barszcz2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Barszcz2021,
  author = {Barszcz, Marcin and Montusiewicz, Jerzy and Pa&#347;nikowska-&Lstrok;ukaszuk, Magdalena and Sa&lstrok;amacha, Anna},
  title = {Comparative Analysis of Digital Models of Objects of Cultural Heritage Obtained by the “3D SLS” and “SfM” Methods},
  journal = {Applied Sciences},
  year = {2021},
  volume = {11},
  number = {12},
  pages = {5321},
  url = {https://www.mdpi.com/2076-3417/11/12/5321},
  doi = {https://doi.org/10.3390/app11125321}
}
</pre></td>
</tr>
<tr id="Battulwar2021" class="entry">
	<td>Battulwar, R., Zare-Naghadehi, M., Emami, E. and Sattarvand, J.</td>
	<td>A state-of-the-art review of automated extraction of rock mass discontinuity characteristics using three-dimensional surface models <p class="infolinks">[<a href="javascript:toggleInfo('Battulwar2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Rock Mechanics and Geotechnical Engineering<br/>Vol. 13(4), pp. 920-936&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.jrmge.2021.01.008">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S1674775521000287">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Battulwar2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Battulwar2021,
  author = {Battulwar, Rushikesh and Zare-Naghadehi, Masoud and Emami, Ebrahim and Sattarvand, Javad},
  title = {A state-of-the-art review of automated extraction of rock mass discontinuity characteristics using three-dimensional surface models},
  journal = {Journal of Rock Mechanics and Geotechnical Engineering},
  year = {2021},
  volume = {13},
  number = {4},
  pages = {920--936},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1674775521000287},
  doi = {https://doi.org/10.1016/j.jrmge.2021.01.008}
}
</pre></td>
</tr>
<tr id="Battulwar2021a" class="entry">
	<td>Battulwar, R., Zare-Naghadehi, M., Emami, E. and Sattarvand, J.</td>
	<td>A state-of-the-art review of automated extraction of rock mass discontinuity characteristics using three-dimensional surface models <p class="infolinks">[<a href="javascript:toggleInfo('Battulwar2021a','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Rock Mechanics and Geotechnical Engineering<br/>Vol. 13(4), pp. 920-936&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.jrmge.2021.01.008">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S1674775521000287">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Battulwar2021a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Battulwar2021a,
  author = {Battulwar, Rushikesh and Zare-Naghadehi, Masoud and Emami, Ebrahim and Sattarvand, Javad},
  title = {A state-of-the-art review of automated extraction of rock mass discontinuity characteristics using three-dimensional surface models},
  journal = {Journal of Rock Mechanics and Geotechnical Engineering},
  year = {2021},
  volume = {13},
  number = {4},
  pages = {920--936},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1674775521000287},
  doi = {https://doi.org/10.1016/j.jrmge.2021.01.008}
}
</pre></td>
</tr>
<tr id="Bellis2021" class="entry">
	<td>Bellis, R., Rembielak, A., A. Barnes, E., Paudel, M. and Ravi, A.</td>
	<td>Additive manufacturing (3D printing) in superficial brachytherapy <p class="infolinks">[<a href="javascript:toggleInfo('Bellis2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Contemporary Brachytherapy<br/>Vol. 13(4), pp. 468-482&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5114/jcb.2021.108602">DOI</a> <a href="https://www.termedia.pl/doi/10.5114/jcb.2021.108602">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Bellis2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bellis2021,
  author = {Bellis, Robert and Rembielak, Agata and A. Barnes, Elizabeth and Paudel, Moti and Ravi, Ananth},
  title = {Additive manufacturing (3D printing) in superficial brachytherapy},
  journal = {Journal of Contemporary Brachytherapy},
  year = {2021},
  volume = {13},
  number = {4},
  pages = {468--482},
  url = {https://www.termedia.pl/doi/10.5114/jcb.2021.108602},
  doi = {https://doi.org/10.5114/jcb.2021.108602}
}
</pre></td>
</tr>
<tr id="Bullinger2021" class="entry">
	<td>Bullinger, S., Bodensteiner, C. and Arens, M.</td>
	<td>3D Surface Reconstruction From Multi Date Satellite Images <p class="infolinks">[<a href="javascript:toggleInfo('Bullinger2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Bullinger2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences<br/>Vol. XLIII-B2-2, pp. 313-320&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.5194/isprs-archives-XLIII-B2-2021-313-2021">DOI</a> <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2021/313/2021/">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Bullinger2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Abstract. The reconstruction of accurate three-dimensional environment models is one of the most fundamental goals in the field of photogrammetry. Since satellite images provide suitable properties for obtaining large-scale environment reconstructions, there exist a variety of Stereo Matching based methods to reconstruct point clouds for satellite image pairs. Recently, a Structure from Motion (SfM) based approach has been proposed, which allows to reconstruct point clouds from multiple satellite images. In this work, we propose an extension of this SfM based pipeline that allows us to reconstruct not only point clouds but watertight meshes including texture information. We provide a detailed description of several steps that are mandatory to exploit state-of-the-art mesh reconstruction algorithms in the context of satellite imagery. This includes a decomposition of finite projective camera calibration matrices, a skew correction of corresponding depth maps and input images as well as the recovery of real-world depth maps from reparameterized depth values. The paper presents an extensive quantitative evaluation on multi-date satellite images demonstrating that the proposed pipeline combined with current meshing algorithms outperforms state-of-the-art point cloud reconstruction algorithms in terms of completeness and median error. We make the source code of our pipeline publicly available.</td>
</tr>
<tr id="bib_Bullinger2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Bullinger2021,
  author = {Bullinger, S. and Bodensteiner, C. and Arens, M.},
  title = {3D Surface Reconstruction From Multi Date Satellite Images},
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  year = {2021},
  volume = {XLIII-B2-2},
  pages = {313--320},
  url = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B2-2021/313/2021/},
  doi = {https://doi.org/10.5194/isprs-archives-XLIII-B2-2021-313-2021}
}
</pre></td>
</tr>
<tr id="Bullinger2021a" class="entry">
	<td>Bullinger, S., Bodensteiner, C. and Arens, M.</td>
	<td>A Photogrammetry-based Framework to Facilitate Image-based Modeling and Automatic Camera Tracking <p class="infolinks">[<a href="javascript:toggleInfo('Bullinger2021a','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.5220/0010319801060112">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Bullinger2021a" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Bullinger2021a,
  author = {Bullinger, Sebastian and Bodensteiner, Christoph and Arens, Michael},
  title = {A Photogrammetry-based Framework to Facilitate Image-based Modeling and Automatic Camera Tracking},
  booktitle = {Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  publisher = {SCITEPRESS - Science and Technology Publications},
  year = {2021},
  doi = {https://doi.org/10.5220/0010319801060112}
}
</pre></td>
</tr>
<tr id="Campbell2021" class="entry">
	<td>Campbell, O., Blenkinsop, T., Gilbert, O. and Mol, L.</td>
	<td>Surface and Subsurface Damage Caused by Bullet Impacts into Sandstone <p class="infolinks">[<a href="javascript:toggleInfo('Campbell2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Campbell2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Geosciences<br/>Vol. 11(9), pp. 395&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/geosciences11090395">DOI</a> <a href="https://www.mdpi.com/2076-3263/11/9/395">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Campbell2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The shift of armed conflicts to more urbanised environments has increased the risk to cultural heritage sites. Small arms impacts are ubiquitous in these circumstances, yet the effects and mechanisms of damage caused are not well known. A sandstone target was shot under controlled conditions to investigate surface and subsurface damage. A 3D model of the damaged block, created by structure from motion photogrammetry, shows that internal fracturing was at least as extensive as the visible surface fractures. Backscatter electron imaging of the damaged surface shows a shift from intragranular fracturing and grain size reduction at < 5 mm from the impact point to primarily circumgranular fracturing and grain ‘plucking' at 20 mm from the impact point. Internal fracture intensity decreased with distance from the centre of the crater. Volumes around the impact point are therefore at greater risk of subsequent weathering deterioration, but significant damage extends to the periphery of the target, rendering whole blocks vulnerable. The surface crater, despite being one of the most conspicuous aspects of conflict damage, has many times less area than internal and surface fractures.</td>
</tr>
<tr id="bib_Campbell2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Campbell2021,
  author = {Campbell, Oliver and Blenkinsop, Tom and Gilbert, Oscar and Mol, Lisa},
  title = {Surface and Subsurface Damage Caused by Bullet Impacts into Sandstone},
  journal = {Geosciences},
  year = {2021},
  volume = {11},
  number = {9},
  pages = {395},
  url = {https://www.mdpi.com/2076-3263/11/9/395},
  doi = {https://doi.org/10.3390/geosciences11090395}
}
</pre></td>
</tr>
<tr id="Chai2021" class="entry">
	<td>Chai, B., Chen, Y., Zhou, J., Huang, Q., Pan, C. and Zhan, S.</td>
	<td>Application of Human-Machine Collaboration Algorithm for Mine Pile Weight Estimation Based on Beidou High-Precision Location Service <p class="infolinks">[<a href="javascript:toggleInfo('Chai2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Chai2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td><br/>Vol. 772 LNEEhina Satellite Navigation Conference (CSNC 2021) Proceedings. Lecture Notes in Electrical Engineering, pp. 3-11&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-981-16-3138-2_1">DOI</a> <a href="https://link.springer.com/chapter/10.1007/978-981-16-3138-2_1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Chai2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The terminal yard is a site used to stack bulk mineral materials. When users need, they need to estimate the weight of the mineral material pile before loading. If there is too much or insufficient mineral material, short barge trucks need to be used for stacking, allocating, and clearing to increase the field capacity and transfer efficiency of the yard. Accurate pile quality estimation can effectively reduce the use times of short-distance trucks and reduce yard operating costs. Unlike traditional yard weight estimation, which requires accurate measurement of the volume of the pile, we use comprehensive processing technology based on Beidou high-precision positioning and UAV (Unmanned Aerial Vehicle) shooting high-precision image, combined with open source software (OpenDroneMap) to quickly obtain the rough volume. Then a SVM (Support Vector Machine) high-precision quality estimation model with 8 variables including volume will be established by manually inputting 7 variable factors of pile proportion, moisture content, ore pile height, iron ore form, month, and stacking time. Through actual data verification and analysis, the estimation error is less than 4.5%. Compared with the 20% error of manual experience, it greatly reduces the labor burden and the management cost caused by the inaccurate estimation. Besides, it also improves the management level of the material yard estimation.</td>
</tr>
<tr id="bib_Chai2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Chai2021,
  author = {Chai, Bin and Chen, Yaozhong and Zhou, Junming and Huang, Qiang and Pan, Changchun and Zhan, Shanshan},
  title = {Application of Human-Machine Collaboration Algorithm for Mine Pile Weight Estimation Based on Beidou High-Precision Location Service},
  booktitle = {hina Satellite Navigation Conference (CSNC 2021) Proceedings. Lecture Notes in Electrical Engineering},
  publisher = {Springer, Singapore},
  year = {2021},
  volume = {772 LNEE},
  pages = {3--11},
  url = {https://link.springer.com/chapter/10.1007/978-981-16-3138-2_1},
  doi = {https://doi.org/10.1007/978-981-16-3138-2_1}
}
</pre></td>
</tr>
<tr id="Chen2021" class="entry">
	<td>Chen, K. and Rakha, T.</td>
	<td>CV-based Registration of UAV-captured Fa&ccedil;ade Inspection Images to 3D Building Point Cloud Models Learning from LEED View project Urban Building Energy Modeling View project CV-based Registration of UAV-captured Fa&ccedil;ade Inspection Images to 3D Building Poin <p class="infolinks">[<a href="javascript:toggleInfo('Chen2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Chen2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the Symposium on Simulation for Architecture and Urban Design (SimAUD 21)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://www.researchgate.net/publication/354473795">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Chen2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: There has been a growing trend recently for using camera-equipped drones for closeup visual inspection of building facades. With the rapid development of photogrammetry techniques for image-based 3D model reconstruction, a 3D building point cloud model can be generated from large-scale sequential building images captured by a drone. Meanwhile, a drone system can collect large amounts of high-resolution close-range fa&ccedil;ade images, which automates the detection of visual anomalies with the application of advanced image processing techniques. The localization and mapping of such fa&ccedil;ade anomalies within close-range inspection images to the reconstructed 3D building model becomes significant for the assessment of anomalies and evaluation of fa&ccedil;ade conditions. This study puts forward a Computer Vision (CV)-based algorithm to automatically register 2D images and 2D anomalies into a 3D building point cloud model. A case study is presented to demonstrate the processing of drone-captured image data with the outcomes' visualization. As a result of this study, the proposed algorithm can register 2D images and 2D anomalies to a 3D building model, which paves the way towards computational assessment and documentation of fa&ccedil;ade anomalies to support the decision-making of appropriate maintenance work.</td>
</tr>
<tr id="bib_Chen2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Chen2021,
  author = {Chen, Kaiwen and Rakha, Tarek},
  title = {CV-based Registration of UAV-captured Fa&ccedil;ade Inspection Images to 3D Building Point Cloud Models Learning from LEED View project Urban Building Energy Modeling View project CV-based Registration of UAV-captured Fa&ccedil;ade Inspection Images to 3D Building Poin},
  booktitle = {Proceedings of the Symposium on Simulation for Architecture and Urban Design (SimAUD 21)},
  publisher = {Society for Modeling &amp; Simulation International (SCS)},
  year = {2021},
  url = {https://www.researchgate.net/publication/354473795}
}
</pre></td>
</tr>
<tr id="Chowdhury2021" class="entry">
	<td>Chowdhury, S.A.H., Nguyen, C., Li, H. and Hartley, R.</td>
	<td>Fixed-Lens camera setup and calibrated image registration for multifocus multiview 3D reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('Chowdhury2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Neural Computing and Applications<br/>Vol. 33(13), pp. 7421-7440&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1007/s00521-021-05926-7">DOI</a> <a href="https://link.springer.com/10.1007/s00521-021-05926-7">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Chowdhury2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Chowdhury2021,
  author = {Chowdhury, Shah Ariful Hoque and Nguyen, Chuong and Li, Hengjia and Hartley, Richard},
  title = {Fixed-Lens camera setup and calibrated image registration for multifocus multiview 3D reconstruction},
  journal = {Neural Computing and Applications},
  year = {2021},
  volume = {33},
  number = {13},
  pages = {7421--7440},
  url = {https://link.springer.com/10.1007/s00521-021-05926-7},
  doi = {https://doi.org/10.1007/s00521-021-05926-7}
}
</pre></td>
</tr>
<tr id="Debski2021" class="entry">
	<td>Debski, M., Bajor, G., Lepich, T., Aniszewski, &Lstrok;. and Jedrusik, P.</td>
	<td>Process of photogrammetry with use of custom made workstation as a method of digital recording of anatomical specimens for scientific and research purposes <p class="infolinks">[<a href="javascript:toggleInfo('Debski2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Debski2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Translational Research in Anatomy<br/>Vol. 24, pp. 100128&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/J.TRIA.2021.100128">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Debski2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This work aims to use photogrammetry to prepare the base of anatomical specimens for teaching and research purposes. Photogrammetry consists in preparing a 3D model of an object with the use of a specially designed program, e.g. Meshroom, based on the photos of an object taken from various angles. To enhance the process of taking photos for 3D models, a workstation has been designed and developed. It consists of the frame with a slowly rotating specimen (360° per minute) attached. The object is photographed from each side and at various angles. In the next stage of processing the model, the photos are sent to a graphic designer who creates the first model and then the final one. The prepared 3D models are intended to be used for academic teaching and specialist training. They can also be used for further research, measurements or to plan surgical procedures. At the moment, the base prepared with this method contains the entire human skeleton, several joints, and parenchymal organs. It has been systematically expanded as the goal is to include all human organs grouped into systems. This article does not aim to describe the photogrammetry method itself as it has been already presented in details in other publications[1]. This research focuses on presenting one of the several available methods of obtaining images of objects prone to change their shapes and thus difficult to be captured in the photo taken from several angles. The method presented in this article uses a custom made workstation to ensure a stable environment and conditions for taking photos of rotating objects, which are described later in this article.</td>
</tr>
<tr id="bib_Debski2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Debski2021,
  author = {Debski, Marcin and Bajor, Grzegorz and Lepich, Tomasz and Aniszewski, &Lstrok;ukasz and Jedrusik, Przemys&lstrok;aw},
  title = {Process of photogrammetry with use of custom made workstation as a method of digital recording of anatomical specimens for scientific and research purposes},
  journal = {Translational Research in Anatomy},
  publisher = {Elsevier},
  year = {2021},
  volume = {24},
  pages = {100128},
  doi = {https://doi.org/10.1016/J.TRIA.2021.100128}
}
</pre></td>
</tr>
<tr id="Ðuric2021" class="entry">
	<td>Ðuric Isidora, Vasiljevic Ivana, Obradovic Milo&scaron;, Stojakovic Vesna, Kicanovic, J. and Obradovic, R.</td>
	<td>Comparative Analysis of Open-Source and Commercial Photogrammetry Software for Cultural Heritage <p class="infolinks">[<a href="javascript:toggleInfo('Ðuric2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ðuric2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Stojakovic, V and Tepavcevic, B (eds.), Towards a new, configurable architecture - Proceedings of the 39th eCAADe Conference - Volume 2, University of Novi Sad, Novi Sad, Serbia, 8-10 September 2021, pp. 243-252&nbsp;</td>
	<td>article</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Ðuric2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Recently, photogrammetry has become a relatively easy and low-cost method for cultural heritage 3D reconstruction. Plenty of free and open-source photogrammetry programs have been developed, but not all of them provide an adequate solution for the 3D reconstruction of cultural heritage. In this research, an overview of the state-of-the-art open-source photogrammetry programs was done. In order to investigate whether among the open-source software packages there is an adequate alternative to the commercial software for the purpose of cultural heritage 3D reconstruction, the open-source software - AliceVision Meshroom was compared to the most commonly used commercial software Agisoft Metashape. The programs were compared on the examples of cultural heritage objects and according to the predefined criteria that are important for achieving detailed and accurate 3D reconstruction. The results of testing and comparing the 3D reconstructions obtained using Meshroom and Metashape were illustrated and explained through two case studies of antic objects of cultural heritage, characterized by similar materialization, but different geometric shapes.</td>
</tr>
<tr id="bib_Ðuric2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Ðuric2021,
  author = {Ðuric, Isidora, and Vasiljevic, Ivana, and Obradovic, Milo&scaron;, and Stojakovic, Vesna, and Kicanovic, Jelena and Obradovic, Ratko},
  title = {Comparative Analysis of Open-Source and Commercial Photogrammetry Software for Cultural Heritage},
  journal = {Stojakovic, V and Tepavcevic, B (eds.), Towards a new, configurable architecture - Proceedings of the 39th eCAADe Conference - Volume 2, University of Novi Sad, Novi Sad, Serbia, 8-10 September 2021, pp. 243-252},
  year = {2021}
}
</pre></td>
</tr>
<tr id="Farook2021" class="entry">
	<td>Farook, T.H., Jamayet, N.B., Asif, J.A., Din, A.S., Mahyuddin, M.N. and Alam, M.K.</td>
	<td>Development and virtual validation of a novel digital workflow to rehabilitate palatal defects by using smartphone-integrated stereophotogrammetry (SPINS) <p class="infolinks">[<a href="javascript:toggleInfo('Farook2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Farook2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Scientific Reports<br/>Vol. 11(1), pp. 8469&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1038/s41598-021-87240-9">DOI</a> <a href="http://www.nature.com/articles/s41598-021-87240-9">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Farook2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Palatal defects are rehabilitated by fabricating maxillofacial prostheses called obturators. The treatment incorporates taking deviously unpredictable impressions to facsimile the palatal defects into plaster casts for obturator fabrication in the dental laboratory. The casts are then digitally stored using expensive hardware to prevent physical damage or data loss and, when required, future obturators are digitally designed, and 3D printed. Our objective was to construct and validate an economic in-house smartphone-integrated stereophotogrammetry (SPINS) 3D scanner and to evaluate its accuracy in designing prosthetics using open source/free (OS/F) digital pipeline. Palatal defect models were scanned using SPINS and its accuracy was compared against the standard laser scanner for virtual area and volumetric parameters. SPINS derived 3D models were then used to design obturators by using (OS/F) software. The resultant obturators were virtually compared against standard medical software designs. There were no significant differences in any of the virtual parameters when evaluating the accuracy of both SPINS, as well as OS/F derived obturators. However, limitations in the design process resulted in minimal dissimilarities. With further improvements, SPINS based prosthetic rehabilitation could create a viable, low cost method for rural and developing health services to embrace maxillofacial record keeping and digitised prosthetic rehabilitation.</td>
</tr>
<tr id="bib_Farook2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Farook2021,
  author = {Farook, Taseef Hasan and Jamayet, Nafij Bin and Asif, Jawaad Ahmed and Din, Abdul Sattar and Mahyuddin, Muhammad Nasiruddin and Alam, Mohammad Khursheed},
  title = {Development and virtual validation of a novel digital workflow to rehabilitate palatal defects by using smartphone-integrated stereophotogrammetry (SPINS)},
  journal = {Scientific Reports},
  year = {2021},
  volume = {11},
  number = {1},
  pages = {8469},
  url = {http://www.nature.com/articles/s41598-021-87240-9},
  doi = {https://doi.org/10.1038/s41598-021-87240-9}
}
</pre></td>
</tr>
<tr id="Fernandez2021" class="entry">
	<td>Fernandez, A.A., Mora, S.R. and Damerell, R.A.</td>
	<td>Work-in-Progress–—Photogrammetry within Virtual Reality <p class="infolinks">[<a href="javascript:toggleInfo('Fernandez2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 2021 7th International Conference of the Immersive Learning Research Network (iLRN), pp. 1-2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.23919/iLRN52045.2021.9459384">DOI</a> <a href="https://ieeexplore.ieee.org/document/9459384/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Fernandez2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Fernandez2021,
  author = {Fernandez, Abel A. and Mora, Sabrina Rodriguez and Damerell, Ryan A.},
  title = {Work-in-Progress–—Photogrammetry within Virtual Reality},
  booktitle = {Proceedings of the 2021 7th International Conference of the Immersive Learning Research Network (iLRN)},
  publisher = {IEEE},
  year = {2021},
  pages = {1--2},
  url = {https://ieeexplore.ieee.org/document/9459384/},
  doi = {https://doi.org/10.23919/iLRN52045.2021.9459384}
}
</pre></td>
</tr>
<tr id="Flannery-Sutherland2021" class="entry">
	<td>Flannery-Sutherland, J.T.</td>
	<td>Putative arthropod trace fossils from the Orcadian Basin at Achanarras Quarry (Middle Devonian of Scotland) <p class="infolinks">[<a href="javascript:toggleInfo('Flannery-Sutherland2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Flannery-Sutherland2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of the Geological Society<br/>Vol. 178(4), pp. jgs2020-233&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1144/jgs2020-233">DOI</a> <a href="http://jgs.lyellcollection.org/lookup/doi/10.1144/jgs2020-233">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Flannery-Sutherland2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Achanarras Quarry, Caithness, Scotland displays a diverse fossil fish fauna that is presumed to have inhabited shallow-lacustrine environments present in the Orcadian Basin during the Early to Middle Devonian. Although Achanarras Quarry itself exposes deep-lacustrine facies, the ecology of their depositional environment remains unknown, in stark contrast to the detailed environmental reconstructions available for the lake margin. I report putative arthropod trace fossils from Achanarras Quarry that are tentatively interpreted as having been formed in a deep-lake environment. Transport of doomed pioneers from the thriving shallow-water ecosystems by turbidite flows is discussed as a possible scenario for their formation. The infrequent and ephemeral intrusions of animals into the deep waters of Lake Orcadie fit the broader narrative of the colonization of deep-lake ecosystems after the Devonian. These interpretations of deep-lacustrine trace fossils from Achanarras, along with their place within the narrative of lake ecosystem evolution, are made cautiously, however, given the paucity of the specimens and the uncertainty surrounding their sedimentary setting.</td>
</tr>
<tr id="bib_Flannery-Sutherland2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Flannery-Sutherland2021,
  author = {Flannery-Sutherland, Joseph T.},
  title = {Putative arthropod trace fossils from the Orcadian Basin at Achanarras Quarry (Middle Devonian of Scotland)},
  journal = {Journal of the Geological Society},
  year = {2021},
  volume = {178},
  number = {4},
  pages = {jgs2020--233},
  url = {http://jgs.lyellcollection.org/lookup/doi/10.1144/jgs2020-233},
  doi = {https://doi.org/10.1144/jgs2020-233}
}
</pre></td>
</tr>
<tr id="Francois2021" class="entry">
	<td>Fran&ccedil;ois, T., Calvet, L., S&egrave;ve-d'Erceville, C., Bourdel, N. and Bartoli, A.</td>
	<td>Image-based Incision Detection for Topological Intraoperative 3D Model Update in Augmented Reality Assisted Laparoscopic Surgery <p class="infolinks">[<a href="javascript:toggleInfo('Francois2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Francois2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Francois2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Augmented Reality (AR) is a promising way to precisely locate the internal structures of an organ in laparoscopy. Several methods have been proposed to register a preoperative 3D model reconstructed from MRI or CT to the intraoperative laparoscopy 2D images. These methods assume a fixed topology of the 3D model. They thus quickly fail once the organ is cut to remove pathological internal structures. We propose to add image-based incision detection in the registration pipeline, in order to update the topology of the organ model. Whenever an incision is detected, it is transferred to the 3D model, whose topology is then updated accordingly, and registration started. We trained a UNet as incision detector from 181 labelled incision images, collected from 10 myomectomy procedures. It obtains a mean precision, recall and f1 score of 0.05, 0.36, and 0.08 from 10-fold cross-validation. Overall, topology updating improves 3D registration accuracy by 5% on average.</td>
</tr>
<tr id="bib_Francois2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Francois2021,
  author = {Fran&ccedil;ois, Tom and Calvet, Lilian and S&egrave;ve-d'Erceville, Callyane and Bourdel, Nicolas and Bartoli, Adrien},
  title = {Image-based Incision Detection for Topological Intraoperative 3D Model Update in Augmented Reality Assisted Laparoscopic Surgery},
  booktitle = {Proceedings of the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)},
  year = {2021}
}
</pre></td>
</tr>
<tr id="GabarronCortes2021" class="entry">
	<td>Gabarr&oacute;n Cort&eacute;s, M.A.</td>
	<td>Design of a Photogrammetry Pipeline: Generating 3D Models for Real-time Engines <p class="infolinks">[<a href="javascript:toggleInfo('GabarronCortes2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 80<i>School</i>: Tampere University of Applied Sciences&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_GabarronCortes2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{GabarronCortes2021,
  author = {Gabarr&oacute;n Cort&eacute;s, Manuel Andres},
  title = {Design of a Photogrammetry Pipeline: Generating 3D Models for Real-time Engines},
  school = {Tampere University of Applied Sciences},
  year = {2021},
  pages = {80}
}
</pre></td>
</tr>
<tr id="Galanakis2021" class="entry">
	<td>Galanakis, G., Zabulis, X., Evdaimon, T., Fikenscher, S.-E., Allertseder, S., Tsikrika, T. and Vrochidis, S.</td>
	<td>A Study of 3D Digitisation Modalities for Crime Scene Investigation <p class="infolinks">[<a href="javascript:toggleInfo('Galanakis2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Galanakis2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Forensic Sciences<br/>Vol. 1(2), pp. 56-85&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/forensicsci1020008">DOI</a> <a href="https://www.mdpi.com/2673-6756/1/2/8">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Galanakis2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: A valuable aspect during crime scene investigation is the digital documentation of the scene. Traditional means of documentation include photography and in situ measurements from experts for further analysis. Although 3D reconstruction of pertinent scenes has already been explored as a complementary tool in investigation pipelines, such technology is considered unfamiliar and not yet widely adopted. This is explained by the expensive and specialised digitisation equipment that is available so far. However, the emergence of high-precision but low-cost devices capable of scanning scenes or objects in 3D has been proven as a reliable alternative to their counterparts. This paper summarises and analyses the state-of-the-art technologies in scene documentation using 3D digitisation and assesses the usefulness in typical police-related situations and the forensics domain in general. We present the methodology for acquiring data for 3D reconstruction of various types of scenes. Emphasis is placed on the applicability of each technique in a wide range of situations, ranging in type and size. The application of each reconstruction method is considered in this context and compared with respect to additional constraints, such as time availability and simplicity of operation of the corresponding scanning modality. To further support our findings, we release a multi-modal dataset obtained from a hypothetical indoor crime scene to the public.</td>
</tr>
<tr id="bib_Galanakis2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Galanakis2021,
  author = {Galanakis, George and Zabulis, Xenophon and Evdaimon, Theodore and Fikenscher, Sven-Eric and Allertseder, Sebastian and Tsikrika, Theodora and Vrochidis, Stefanos},
  title = {A Study of 3D Digitisation Modalities for Crime Scene Investigation},
  journal = {Forensic Sciences},
  year = {2021},
  volume = {1},
  number = {2},
  pages = {56--85},
  url = {https://www.mdpi.com/2673-6756/1/2/8},
  doi = {https://doi.org/10.3390/forensicsci1020008}
}
</pre></td>
</tr>
<tr id="Gallo2021" class="entry">
	<td>Gallo, G., Buscemi, F., Ferro, M., Figuera, M. and Marco Riela, P.</td>
	<td>Abstracting Stone Walls for Visualization and Analysis <p class="infolinks">[<a href="javascript:toggleInfo('Gallo2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021. Lecture Notes in Computer Science, pp. 215-222&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-68787-8_15">DOI</a> <a href="http://link.springer.com/10.1007/978-3-030-68787-8_15">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Gallo2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Gallo2021,
  author = {Gallo, Giovanni and Buscemi, Francesca and Ferro, Michele and Figuera, Marianna and Marco Riela, Paolo},
  title = {Abstracting Stone Walls for Visualization and Analysis},
  booktitle = {Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021. Lecture Notes in Computer Science},
  year = {2021},
  pages = {215--222},
  url = {http://link.springer.com/10.1007/978-3-030-68787-8_15},
  doi = {https://doi.org/10.1007/978-3-030-68787-8_15}
}
</pre></td>
</tr>
<tr id="Gutierrez2021" class="entry">
	<td>Gutierrez, E., Casta&ntilde;eda, B., Treuillet, S. and Lucas, Y.</td>
	<td>Combined thermal and color 3D model for wound evaluation from handheld devices <p class="infolinks">[<a href="javascript:toggleInfo('Gutierrez2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Medical Imaging 2021: Imaging Informatics for Healthcare, Research, and Applications, pp. 7&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1117/12.2580669">DOI</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11601/2580669/Combined-thermal-and-color-3D-model-for-wound-evaluation-from/10.1117/12.2580669.full">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Gutierrez2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Gutierrez2021,
  author = {Gutierrez, Evelyn and Casta&ntilde;eda, Benjamin and Treuillet, Sylvie and Lucas, Yves},
  title = {Combined thermal and color 3D model for wound evaluation from handheld devices},
  booktitle = {Medical Imaging 2021: Imaging Informatics for Healthcare, Research, and Applications},
  publisher = {SPIE},
  year = {2021},
  pages = {7},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11601/2580669/Combined-thermal-and-color-3D-model-for-wound-evaluation-from/10.1117/12.2580669.full},
  doi = {https://doi.org/10.1117/12.2580669}
}
</pre></td>
</tr>
<tr id="Hartogsveld2021" class="entry">
	<td>Hartogsveld, L.</td>
	<td>Designing a leaf holder for real-time microscopy <p class="infolinks">[<a href="javascript:toggleInfo('Hartogsveld2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 51<i>School</i>: University of Twente&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="http://essay.utwente.nl/87734/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Hartogsveld2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Hartogsveld2021,
  author = {Hartogsveld, Lars},
  title = {Designing a leaf holder for real-time microscopy},
  school = {University of Twente},
  year = {2021},
  pages = {51},
  url = {http://essay.utwente.nl/87734/}
}
</pre></td>
</tr>
<tr id="Hasan2021" class="entry">
	<td>Hasan, M.K., Calvet, L., Rabbani, N. and Bartoli, A.</td>
	<td>Detection, segmentation, and 3D pose estimation of surgical tools using convolutional neural networks and algebraic geometry <p class="infolinks">[<a href="javascript:toggleInfo('Hasan2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Medical Image Analysis<br/>Vol. 70, pp. 101994&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.media.2021.101994">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S1361841521000402">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Hasan2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Hasan2021,
  author = {Hasan, Md. Kamrul and Calvet, Lilian and Rabbani, Navid and Bartoli, Adrien},
  title = {Detection, segmentation, and 3D pose estimation of surgical tools using convolutional neural networks and algebraic geometry},
  journal = {Medical Image Analysis},
  year = {2021},
  volume = {70},
  pages = {101994},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1361841521000402},
  doi = {https://doi.org/10.1016/j.media.2021.101994}
}
</pre></td>
</tr>
<tr id="Hobloss2021" class="entry">
	<td>Hobloss, N., Zhang, L. and Cagnazzo, M.</td>
	<td>A Multi-View Stereoscopic Video Database With Green Screen (MTF) For Video Transition Quality-of-Experience Assessment <p class="infolinks">[<a href="javascript:toggleInfo('Hobloss2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 13th International Conference on Quality of Multimedia Experience (QoMEX), pp. 201-206&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/QoMEX51781.2021.9465458">DOI</a> <a href="https://ieeexplore.ieee.org/document/9465458/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Hobloss2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Hobloss2021,
  author = {Hobloss, Nour and Zhang, Lu and Cagnazzo, Marco},
  title = {A Multi-View Stereoscopic Video Database With Green Screen (MTF) For Video Transition Quality-of-Experience Assessment},
  booktitle = {Proceedings of the 13th International Conference on Quality of Multimedia Experience (QoMEX)},
  publisher = {IEEE},
  year = {2021},
  pages = {201--206},
  url = {https://ieeexplore.ieee.org/document/9465458/},
  doi = {https://doi.org/10.1109/QoMEX51781.2021.9465458}
}
</pre></td>
</tr>
<tr id="Huurdeman2021" class="entry">
	<td>Huurdeman, H. and Piccoli, C.</td>
	<td>3D Reconstructions as Research Hubs: Geospatial Interfaces for Real-Time Data Exploration of Seventeenth-Century Amsterdam Domestic Interiors <p class="infolinks">[<a href="javascript:toggleInfo('Huurdeman2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Huurdeman2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Open Archaeology<br/>Vol. 7(1), pp. 314-336&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1515/opar-2020-0142">DOI</a> <a href="https://www.degruyter.com/document/doi/10.1515/opar-2020-0142/html">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Huurdeman2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper presents our ongoing work in the Virtual Interiors project, which aims to develop 3D reconstructions as geospatial interfaces to structure and explore historical data of seventeenth-century Amsterdam. We take the reconstruction of the entrance hall of the house of the patrician Pieter de Graeff (1638–1707) as our case study and use it to illustrate the iterative process of knowledge creation, sharing, and discovery that unfolds while creating, exploring and experiencing the 3D models in a prototype research environment. During this work, an interdisciplinary dataset was collected, various metadata and paradata were created to document both the sources and the reasoning process, and rich contextual links were added. These data were used as the basis for creating a user interface for an online research environment, taking design principles and previous user studies into account. Knowledge is shared by visualizing the 3D reconstructions along with the related complexities and uncertainties, while the integration of various underlying data and Linked Data makes it possible to discover contextual knowledge by exploring associated resources. Moreover, we outline how users of the research environment can add annotations and rearrange objects in the scene, facilitating further knowledge discovery and creation.</td>
</tr>
<tr id="bib_Huurdeman2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Huurdeman2021,
  author = {Huurdeman, Hugo and Piccoli, Chiara},
  title = {3D Reconstructions as Research Hubs: Geospatial Interfaces for Real-Time Data Exploration of Seventeenth-Century Amsterdam Domestic Interiors},
  journal = {Open Archaeology},
  year = {2021},
  volume = {7},
  number = {1},
  pages = {314--336},
  url = {https://www.degruyter.com/document/doi/10.1515/opar-2020-0142/html},
  doi = {https://doi.org/10.1515/opar-2020-0142}
}
</pre></td>
</tr>
<tr id="Ilies2021" class="entry">
	<td>Ilies, D.C., Caciora, T., Herman, G.V., Ilies, A., Ropa, M. and Baias, S.</td>
	<td>Geohazards Affecting Cultural Heritage Monuments. A Complex Case Study From Romania <p class="infolinks">[<a href="javascript:toggleInfo('Ilies2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ilies2021','comment')">Comment</a>] [<a href="javascript:toggleInfo('Ilies2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>&nbsp;</td>
	<td>techreport</td>
	<td><a href="https://doi.org/10.21203/rs.3.rs-31190/v1">DOI</a> <a href="https://www.researchsquare.com/article/rs-31190/v1">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Ilies2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The impact that geohazards have on cultural heritage requires continuous research in order to assess risks, prevention and conservation. This study has as the main research object, a uniquen&amp;amp;nbsp;monument in terms of its connection with the risk phenomena. It is about a wooden church historical monument from the village of Corbe?ti, Romania, which was destroyed at the beginning of the tenth decade of the last century by a meteorological hazard, later reconstructed on a new site (in Oradea Municipality), and currently there is a risk of being affected by a geological hazard. The study focused on three main directions of research, namely: reconstructing the film of events, analyzing current risks and finding viable methods for future conservation and promotion. The methodology is based on extensive field research and the use of digital technologies. The results obtained confirmed the church&amp;#039;s tendency to be affected by the emergence of a new risk phenomenon - landslides. In order to conserve and rebuild in case of need, the monument was digitized and a three-dimensional model of high accuracy was developed. This approach has the advantage of being low-cost, fast, non-invasive and providing large volumes of valuable information in the process of cultural heritage conservation.</td>
</tr>
<tr id="rev_Ilies2021" class="comment noshow">
	<td colspan="6"><b>Comment</b>: Cultural Heritage use (short mentioning)</td>
</tr>
<tr id="bib_Ilies2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@techreport{Ilies2021,
  author = {Ilies, Dorina Camelia and Caciora, Tudor and Herman, Grigore Vasile and Ilies, Alexandru and Ropa, Madalina and Baias, Stefan},
  title = {Geohazards Affecting Cultural Heritage Monuments. A Complex Case Study From Romania},
  year = {2021},
  note = {Type: article},
  url = {https://www.researchsquare.com/article/rs-31190/v1},
  doi = {https://doi.org/10.21203/rs.3.rs-31190/v1}
}
</pre></td>
</tr>
<tr id="Irschick2021" class="entry">
	<td>Irschick, D.J., Martin, J., Siebert, U., Kristensen, J.H., Madsen, P.T. and Christiansen, F.</td>
	<td>Creation of accurate 3D models of harbor porpoises ( Phocoena phocoena ) using 3D photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('Irschick2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Marine Mammal Science<br/>Vol. 37(2), pp. 482-491&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1111/mms.12759">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1111/mms.12759">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Irschick2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Irschick2021,
  author = {Irschick, Duncan J. and Martin, Johnson and Siebert, Ursula and Kristensen, Jakob H. and Madsen, Peter T and Christiansen, Fredrik},
  title = {Creation of accurate 3D models of harbor porpoises ( Phocoena phocoena ) using 3D photogrammetry},
  journal = {Marine Mammal Science},
  year = {2021},
  volume = {37},
  number = {2},
  pages = {482--491},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/mms.12759},
  doi = {https://doi.org/10.1111/mms.12759}
}
</pre></td>
</tr>
<tr id="Johnson2021" class="entry">
	<td>Johnson, J. and Johnson, A.</td>
	<td>Photogrammetry for a Virtual Reality Nature Scene <p class="infolinks">[<a href="javascript:toggleInfo('Johnson2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of th ACM SIGGRAPH 2021 Educators Forum, pp. 1-2&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3450549.3464416">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3450549.3464416">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Johnson2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Johnson2021,
  author = {Johnson, Justin and Johnson, Amber},
  title = {Photogrammetry for a Virtual Reality Nature Scene},
  booktitle = {Proceedings of th ACM SIGGRAPH 2021 Educators Forum},
  publisher = {ACM},
  year = {2021},
  pages = {1--2},
  url = {https://dl.acm.org/doi/10.1145/3450549.3464416},
  doi = {https://doi.org/10.1145/3450549.3464416}
}
</pre></td>
</tr>
<tr id="Junior2021" class="entry">
	<td>Junior, M.A.T.</td>
	<td>Applied structure from motion photogrammetry: habitat complexity and sponge distribution in natural rocky reefs adjacent to Ria Formosa (Southern Portugal) <p class="infolinks">[<a href="javascript:toggleInfo('Junior2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 109<i>School</i>: UNIVERSITY OF ALGARVE&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://sapientia.ualg.pt/handle/10400.1/15504">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Junior2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Junior2021,
  author = {Junior, Marcos Agiani Tieppo},
  title = {Applied structure from motion photogrammetry: habitat complexity and sponge distribution in natural rocky reefs adjacent to Ria Formosa (Southern Portugal)},
  school = {UNIVERSITY OF ALGARVE},
  year = {2021},
  pages = {109},
  url = {https://sapientia.ualg.pt/handle/10400.1/15504}
}
</pre></td>
</tr>
<tr id="Kaplan2021" class="entry">
	<td>Kaplan, M.</td>
	<td>Image-Based Indoor Positioning System for Audiences in Large Live Entertainment Venues or Theaters <p class="infolinks">[<a href="javascript:toggleInfo('Kaplan2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 71<i>School</i>: California State University Northridge&nbsp;</td>
	<td>phdthesis</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Kaplan2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{Kaplan2021,
  author = {Kaplan, Mark},
  title = {Image-Based Indoor Positioning System for Audiences in Large Live Entertainment Venues or Theaters},
  school = {California State University Northridge},
  year = {2021},
  pages = {71}
}
</pre></td>
</tr>
<tr id="Khan2021" class="entry">
	<td>Khan, M.J., Caleb, J.R., Gadhikar, L. and Mehershahi, S.</td>
	<td>Automated Surveying for Construction Engineering <p class="infolinks">[<a href="javascript:toggleInfo('Khan2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICNTE51185.2021.9487670">DOI</a> <a href="https://ieeexplore.ieee.org/document/9487670/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Khan2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Khan2021,
  author = {Khan, Mohd. Jamaluddin and Caleb, Jim R. and Gadhikar, Lakshmi and Mehershahi, Sharon},
  title = {Automated Surveying for Construction Engineering},
  booktitle = {2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE)},
  publisher = {IEEE},
  year = {2021},
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/document/9487670/},
  doi = {https://doi.org/10.1109/ICNTE51185.2021.9487670}
}
</pre></td>
</tr>
<tr id="Kholil2021" class="entry">
	<td>Kholil, M., Ismanto, I. and Fu'ad, M.N.</td>
	<td>3D reconstruction using Structure From Motion (SFM) algorithm and Multi View Stereo (MVS) based on computer vision <p class="infolinks">[<a href="javascript:toggleInfo('Kholil2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kholil2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td><br/>Vol. 1073(1)Proceedings of the IOP Conference Series: Materials Science and Engineering, pp. 012066&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1088/1757-899X/1073/1/012066">DOI</a> <a href="https://iopscience.iop.org/article/10.1088/1757-899X/1073/1/012066 https://iopscience.iop.org/article/10.1088/1757-899X/1073/1/012066/meta">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Kholil2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The development of the Information and Computer Technology (ICT) sector, three-dimensional (3D) technology is also growing rapidly. Currently, the need to visualize 3D objects is widely used in animation and graphic applications, architecture, education, cultural recognition and Virtual Reality. 3D modeling of historic buildings has become a concern in recent years. 3D reconstruction is an attempt to document reconstruction or restoration if the building is destroyed. By using the 3D model reconstruction using Structure from Motion (SFM) and Multi View Stereo (MVS) algorithm based on Computer Vision, it is hoped that the results of this 3D modeling can be utilized as an effort to preserve 3D objects in the Penataran Temple cultural heritage area. This research was conducted by taking as many as 61 images of objects in the Blitar Penataran Temple area. The photos obtained were reconstructed into a 3D model using the Structure From Motion algorithm in the meshroom. This research a trial of the original image with a compressed image for reconstruction is used to compare the 3D reconstruction process from the two input data. From 61 images processed using the Structure Form Motion algorithm, 33 poses of camera pose and 3D points were improved, both original and compressed images. The number of iterations compresses 1.4% less than the original image and takes 43.53% faster than the original image.</td>
</tr>
<tr id="bib_Kholil2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Kholil2021,
  author = {Kholil, M and Ismanto, I and Fu'ad, M N},
  title = {3D reconstruction using Structure From Motion (SFM) algorithm and Multi View Stereo (MVS) based on computer vision},
  booktitle = {Proceedings of the IOP Conference Series: Materials Science and Engineering},
  publisher = {IOP Publishing},
  year = {2021},
  volume = {1073},
  number = {1},
  pages = {012066},
  url = {https://iopscience.iop.org/article/10.1088/1757-899X/1073/1/012066 https://iopscience.iop.org/article/10.1088/1757-899X/1073/1/012066/meta},
  doi = {https://doi.org/10.1088/1757-899X/1073/1/012066}
}
</pre></td>
</tr>
<tr id="Larsen2021" class="entry">
	<td>Larsen, H., Budka, M. and Bennett, M.R.</td>
	<td>Technological innovation in the recovery and analysis of 3D forensic footwear evidence: Structure from motion (SfM) photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('Larsen2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Science &amp; Justice<br/>Vol. 61(4), pp. 356-368&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.scijus.2021.04.003">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S1355030621000447">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Larsen2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Larsen2021,
  author = {Larsen, Hannah and Budka, Marcin and Bennett, Matthew R.},
  title = {Technological innovation in the recovery and analysis of 3D forensic footwear evidence: Structure from motion (SfM) photogrammetry},
  journal = {Science &amp; Justice},
  year = {2021},
  volume = {61},
  number = {4},
  pages = {356--368},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1355030621000447},
  doi = {https://doi.org/10.1016/j.scijus.2021.04.003}
}
</pre></td>
</tr>
<tr id="Lorenz2021" class="entry">
	<td>Lorenz, W.E., Faller, A. and Wurzer, G.</td>
	<td>DAttE - Detection of Attic Extensions - Workflow to analyze the potentials of roofs in an urban environment <p class="infolinks">[<a href="javascript:toggleInfo('Lorenz2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Lorenz2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Towards a new, configurable architecture - Proceedings of the 39th eCAADe Conference, pp. 375-384&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="http://papers.cumincad.org/cgi-bin/works/paper/ecaade2021_046">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Lorenz2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: European cities like Vienna are characterized by strong growth and, as a result, by high demand for living space. Extending the attic is one way of meeting this demand. However, there is a lack of data to know which roofs are already expanded and to what extent. The city is interested in the data in two ways: firstly, in relation to the distribution of potentials (a possible change in population density, for example, has an impact on infrastructure and parking space) and, secondly, in relation to the material composition (city as a material resource). This paper provides a workflow to fill this gap of knowledge. The new methods of detecting attic extensions are described and a case study is given at the end to show workability.</td>
</tr>
<tr id="bib_Lorenz2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Lorenz2021,
  author = {Lorenz, Wolfgang E. and Faller, Arnold and Wurzer, Gabriel},
  title = {DAttE - Detection of Attic Extensions - Workflow to analyze the potentials of roofs in an urban environment},
  booktitle = {Towards a new, configurable architecture - Proceedings of the 39th eCAADe Conference},
  year = {2021},
  pages = {375--384},
  url = {http://papers.cumincad.org/cgi-bin/works/paper/ecaade2021_046}
}
</pre></td>
</tr>
<tr id="Luigini2021" class="entry">
	<td>Luigini, A. and Basso, A.</td>
	<td>Heritage Education for Primary Age Through an Immersive Serious Game <p class="infolinks">[<a href="javascript:toggleInfo('Luigini2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>rom Building Information Modelling to Mixed Reality. Springer Tracts in Civil Engineering, pp. 157-174&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-49278-6_10">DOI</a> <a href="http://link.springer.com/10.1007/978-3-030-49278-6_10">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Luigini2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Luigini2021,
  author = {Luigini, A. and Basso, A.},
  title = {Heritage Education for Primary Age Through an Immersive Serious Game},
  booktitle = {rom Building Information Modelling to Mixed Reality. Springer Tracts in Civil Engineering},
  publisher = {Springer, Cham},
  year = {2021},
  pages = {157--174},
  url = {http://link.springer.com/10.1007/978-3-030-49278-6_10},
  doi = {https://doi.org/10.1007/978-3-030-49278-6_10}
}
</pre></td>
</tr>
<tr id="Maiwald2021" class="entry">
	<td>Maiwald, F. and Maas, H.</td>
	<td>An automatic workflow for orientation of historical images with large radiometric and geometric differences <p class="infolinks">[<a href="javascript:toggleInfo('Maiwald2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>The Photogrammetric Record<br/>Vol. 36(174)&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1111/phor.12363">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Maiwald2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Maiwald2021,
  author = {Maiwald, Ferdinand and Maas, Hans‐Gerd},
  title = {An automatic workflow for orientation of historical images with large radiometric and geometric differences},
  journal = {The Photogrammetric Record},
  year = {2021},
  volume = {36},
  number = {174},
  doi = {https://doi.org/10.1111/phor.12363}
}
</pre></td>
</tr>
<tr id="Massaro2021" class="entry">
	<td>Massaro, A., Dipierro, G., Selicato, S., Cannella, E., Galiano, A. and Saponaro, A.</td>
	<td>Intelligent Quarry Production Monitoring Risks and Quality by Artificial Intelligence <p class="infolinks">[<a href="javascript:toggleInfo('Massaro2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 2021 IEEE International Workshop on Metrology for Industry 4.0 &amp; IoT (MetroInd4.0&amp;IoT), pp. 242-247&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/MetroInd4.0IoT51437.2021.9488469">DOI</a> <a href="https://ieeexplore.ieee.org/document/9488469/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Massaro2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Massaro2021,
  author = {Massaro, Alessandro and Dipierro, Giovanni and Selicato, Sergio and Cannella, Emanuele and Galiano, Angelo and Saponaro, Annamaria},
  title = {Intelligent Quarry Production Monitoring Risks and Quality by Artificial Intelligence},
  booktitle = {Proceedings of the 2021 IEEE International Workshop on Metrology for Industry 4.0 &amp; IoT (MetroInd4.0&amp;IoT)},
  publisher = {IEEE},
  year = {2021},
  pages = {242--247},
  url = {https://ieeexplore.ieee.org/document/9488469/},
  doi = {https://doi.org/10.1109/MetroInd4.0IoT51437.2021.9488469}
}
</pre></td>
</tr>
<tr id="Merkle2021" class="entry">
	<td>Merkle, D. and Reiterer, A.</td>
	<td>Evaluation of thermography-based automated delamination and cavity detection in concrete bridges <p class="infolinks">[<a href="javascript:toggleInfo('Merkle2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Automated Visual Inspection and Machine Vision IV, pp. 4&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1117/12.2592303">DOI</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11787/2592303/Evaluation-of-thermography-based-automated-delamination-and-cavity-detection-in/10.1117/12.2592303.full">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Merkle2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Merkle2021,
  author = {Merkle, Dominik and Reiterer, Alexander},
  title = {Evaluation of thermography-based automated delamination and cavity detection in concrete bridges},
  booktitle = {Automated Visual Inspection and Machine Vision IV},
  publisher = {SPIE},
  year = {2021},
  pages = {4},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11787/2592303/Evaluation-of-thermography-based-automated-delamination-and-cavity-detection-in/10.1117/12.2592303.full},
  doi = {https://doi.org/10.1117/12.2592303}
}
</pre></td>
</tr>
<tr id="Moseenkov2021" class="entry">
	<td>Moseenkov, S.I., Kuznetsov, V.L., Kolesov, B.A., Zavorin, A.V., Serkova, A.N. and Zolotarev, N.A.</td>
	<td>Design of effective surface contacts on polymer composites modified with multiwalled carbon nanotubes <p class="infolinks">[<a href="javascript:toggleInfo('Moseenkov2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Express Polymer Letters<br/>Vol. 15(9), pp. 826-838&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3144/expresspolymlett.2021.66">DOI</a> <a href="http://www.expresspolymlett.com/letolt.php?file=EPL-0011243&mi=c">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Moseenkov2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Moseenkov2021,
  author = {Moseenkov, S. I. and Kuznetsov, V. L. and Kolesov, B. A. and Zavorin, A. V. and Serkova, A. N. and Zolotarev, N. A.},
  title = {Design of effective surface contacts on polymer composites modified with multiwalled carbon nanotubes},
  journal = {Express Polymer Letters},
  year = {2021},
  volume = {15},
  number = {9},
  pages = {826--838},
  url = {http://www.expresspolymlett.com/letolt.php?file=EPL-0011243&amp;mi=c},
  doi = {https://doi.org/10.3144/expresspolymlett.2021.66}
}
</pre></td>
</tr>
<tr id="Muller2021" class="entry">
	<td>Muller, K., Panfili, D., Matthis, J. and Hayhoe, M.</td>
	<td>Foothold selection during locomotion over rocky terrain <p class="infolinks">[<a href="javascript:toggleInfo('Muller2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Vision<br/>Vol. 21(9), pp. 2837-2837&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1167/JOV.21.9.2837">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Muller2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Muller2021,
  author = {Muller, Karl and Panfili, Dan and Matthis, Jonathan and Hayhoe, Mary},
  title = {Foothold selection during locomotion over rocky terrain},
  journal = {Journal of Vision},
  publisher = {The Association for Research in Vision and Ophthalmology},
  year = {2021},
  volume = {21},
  number = {9},
  pages = {2837--2837},
  doi = {https://doi.org/10.1167/JOV.21.9.2837}
}
</pre></td>
</tr>
<tr id="Niemirepo2021" class="entry">
	<td>Niemirepo, T.T., Viitanen, M. and Vanne, J.</td>
	<td>Open3DGen: open-source software for reconstructing textured 3D models from RGB-D images <p class="infolinks">[<a href="javascript:toggleInfo('Niemirepo2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 12th ACM Multimedia Systems Conference, pp. 12-22&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3458305.3463374">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3458305.3463374">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Niemirepo2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Niemirepo2021,
  author = {Niemirepo, Teo T. and Viitanen, Marko and Vanne, Jarno},
  title = {Open3DGen: open-source software for reconstructing textured 3D models from RGB-D images},
  booktitle = {Proceedings of the 12th ACM Multimedia Systems Conference},
  publisher = {ACM},
  year = {2021},
  pages = {12--22},
  url = {https://dl.acm.org/doi/10.1145/3458305.3463374},
  doi = {https://doi.org/10.1145/3458305.3463374}
}
</pre></td>
</tr>
<tr id="Ortega-Jimenez2021" class="entry">
	<td>Ortega-Jim&eacute;nez, V.M. and Sanford, C.P.</td>
	<td>Beyond the K&aacute;rm&aacute;n gait: Knifefish swimming in periodic and irregular vortex streets <p class="infolinks">[<a href="javascript:toggleInfo('Ortega-Jimenez2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ortega-Jimenez2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Experimental Biology<br/>Vol. 224(10)&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1242/JEB.238808/238109">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Ortega-Jimenez2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Neotropical freshwater fishes such as knifefishes are commonly faced with navigating intense and highly unsteady streams. However, our knowledge on locomotion in apteronotids comes from laminar flows, where the ribbon fin dominates over the pectoral fins or body bending. Here, we studied the 3D kinematics and swimming control of seven black ghost knifefish (Apteronotus albifrons) moving in laminar flows (flow speed U∞≈1–5 BL s−1) and in periodic vortex streets (U∞≈2–4 BL s−1). Two different cylinders (∼2 and ∼3 cm diameter) were used to generate the latter. Additionally, fish were exposed to an irregular wake produced by a free oscillating cylinder (∼2 cm diameter; U∞≈2 BL s−1). In laminar flows, knifefish mainly used their ribbon fin, with wave frequency, speed and acceleration increasing with U∞. In contrast, knifefish swimming behind a fixed cylinder increased the use of pectoral fins, which resulted in changes in body orientation that mimicked steady backward swimming. Meanwhile, individuals behind the oscillating cylinder presented a combination of body bending and ribbon and pectoral fin movements that counteract the out-of-phase yaw oscillations induced by the irregular shedding of vortices. We corroborated passive out-of-phase oscillations by placing a printed knifefish model just downstream of the moving cylinder, but when placed one cylinder diameter downstream, the model oscillated in phase. Thus, the wake left behind an oscillating body is more challenging than a periodic vortex shedding for an animal located downstream, which may have consequences on inter- and intra-specific interactions.</td>
</tr>
<tr id="bib_Ortega-Jimenez2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Ortega-Jimenez2021,
  author = {Ortega-Jim&eacute;nez, Victor M. and Sanford, Christopher P.},
  title = {Beyond the K&aacute;rm&aacute;n gait: Knifefish swimming in periodic and irregular vortex streets},
  journal = {Journal of Experimental Biology},
  publisher = {Company of Biologists Ltd},
  year = {2021},
  volume = {224},
  number = {10},
  doi = {https://doi.org/10.1242/JEB.238808/238109}
}
</pre></td>
</tr>
<tr id="Ozimek2021" class="entry">
	<td>Ozimek, A., Ozimek, P., Skabek, K. and &Lstrok;abed&#378;, P.</td>
	<td>Digital Modelling and Accuracy Verification of a Complex Architectural Object Based on Photogrammetric Reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('Ozimek2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ozimek2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Buildings<br/>Vol. 11(5), pp. 206&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/buildings11050206">DOI</a> <a href="https://www.mdpi.com/2075-5309/11/5/206">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Ozimek2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Data concerning heritage buildings are necessary for all kinds of building surveying and design. This paper presents a method for creating a precise model of a historical architectural and landscape object with complex geometry. Photogrammetric techniques were used, combining terrestrial imaging and photographs taken using UAVs. In large-scale objects, it is necessary to divide the reconstruction into smaller parts and adopt an iterative approach based on the gradual completion of missing fragments, especially those resulting from occlusions. The model developed via the reconstruction was compared with geometrically reliable data (LAS point clouds) available in the public domain. The degree of accuracy it achieved can be used in conservation, for example, in construction cost estimates. Despite extensive research on photogrammetric techniques and their applicability in reconstructing cultural heritage sites, the results obtained have not yet been compared by other researchers with LAS point clouds from the information system for land cover (ISOK).</td>
</tr>
<tr id="bib_Ozimek2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Ozimek2021,
  author = {Ozimek, Agnieszka and Ozimek, Pawe&lstrok; and Skabek, Krzysztof and &Lstrok;abed&#378;, Piotr},
  title = {Digital Modelling and Accuracy Verification of a Complex Architectural Object Based on Photogrammetric Reconstruction},
  journal = {Buildings},
  year = {2021},
  volume = {11},
  number = {5},
  pages = {206},
  url = {https://www.mdpi.com/2075-5309/11/5/206},
  doi = {https://doi.org/10.3390/buildings11050206}
}
</pre></td>
</tr>
<tr id="Page2021" class="entry">
	<td>Page, J., Mukhlish, F. and Bain, M.</td>
	<td>Towards Motion Capture Using a Swarms of Drones <p class="infolinks">[<a href="javascript:toggleInfo('Page2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of 17th International Conference on Intelligent Unmanned Systems, International Society of Intelligent Unmanned Systems&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Page2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Page2021,
  author = {Page, John and Mukhlish, Faqihza and Bain, Michael},
  title = {Towards Motion Capture Using a Swarms of Drones},
  booktitle = {Proceedings of 17th International Conference on Intelligent Unmanned Systems, International Society of Intelligent Unmanned Systems},
  year = {2021}
}
</pre></td>
</tr>
<tr id="Panov2021" class="entry">
	<td>Panov, Z.</td>
	<td>А new approach for introduction of digital granulometric analysis of crushed material <p class="infolinks">[<a href="javascript:toggleInfo('Panov2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Natural Resources and Technology<br/>Vol. 15(1), pp. 13-25&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.46763/NRT211510013p">DOI</a> <a href="https://js.ugd.edu.mk/index.php/NRT/article/view/4234">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Panov2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Panov2021,
  author = {Panov, Zoran},
  title = {А new approach for introduction of digital granulometric analysis of crushed material},
  journal = {Natural Resources and Technology},
  year = {2021},
  volume = {15},
  number = {1},
  pages = {13--25},
  url = {https://js.ugd.edu.mk/index.php/NRT/article/view/4234},
  doi = {https://doi.org/10.46763/NRT211510013p}
}
</pre></td>
</tr>
<tr id="Pearce2021" class="entry">
	<td>Pearce, D.J.M.</td>
	<td>Create, Share, and Save Money Using Open-Source Projects <p class="infolinks">[<a href="javascript:toggleInfo('Pearce2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pearce2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 165&nbsp;</td>
	<td>book</td>
	<td><a href="https://www.accessengineeringlibrary.com/content/book/9781260461763 https://www.accessengineeringlibrary.com/content/book/9781260461763.abstract">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Pearce2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Live a more sustainable and economical life using open-source technology! Designed for beginning hobbyists and makers, this engaging guide is filled with ways to save money by making use of free and open-source technologies on a wide and impressive range of products. Written by a leader in the field of open-source technology, the book reveals the potential of at-home manufacturing and recycling projects—and even how to score free big-ticket items, including housing and electricity. All the projects have big money saving in mind, but also big fun! Create, Share, and Save Money Using Open-Source Projects lays out the many ways in which you can employ these resources on a small scale to live a more economical and sustainable lifestyle. You'll find tons of DIY projects that demonstrate how to use open-source software and hardware to save money on: • Digital photographs and videos • Music, software, and instruments • Scientific equipment • Paper and audio books • Maps and GIS data • Patterns for clothing • Cars • Electronics and renewable energy • Digital at-home manufacturing • Toys</td>
</tr>
<tr id="bib_Pearce2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@book{Pearce2021,
  author = {Pearce, Dr. Joshua M.},
  title = {Create, Share, and Save Money Using Open-Source Projects},
  publisher = {McGraw-Hill Education},
  year = {2021},
  pages = {165},
  url = {https://www.accessengineeringlibrary.com/content/book/9781260461763 https://www.accessengineeringlibrary.com/content/book/9781260461763.abstract}
}
</pre></td>
</tr>
<tr id="Perry2021" class="entry">
	<td>Perry, B., Guo, Y., Atadero, R. and van de Lindt, J.</td>
	<td>Unmanned aerial vehicle (UAV)-enabled bridge inspection framework <p class="infolinks">[<a href="javascript:toggleInfo('Perry2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Bridge Maintenance, Safety, Management, Life-Cycle Sustainability and Innovations, pp. 8&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1201/9780429279119">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Perry2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Perry2021,
  author = {Perry, B.J. and Guo, Y. and Atadero, R. and van de Lindt, J.W.},
  title = {Unmanned aerial vehicle (UAV)-enabled bridge inspection framework},
  booktitle = {Bridge Maintenance, Safety, Management, Life-Cycle Sustainability and Innovations},
  year = {2021},
  pages = {8},
  doi = {https://doi.org/10.1201/9780429279119}
}
</pre></td>
</tr>
<tr id="Pingel2021" class="entry">
	<td>Pingel, T.J., Saavedra, A. and Cobo, L.</td>
	<td>Deriving Land and Water Surface Elevations in the Northeastern Yucat&aacute;n Peninsula Using PPK GPS and UAV-Based Structure from Motion <p class="infolinks">[<a href="javascript:toggleInfo('Pingel2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Papers in Applied Geography<br/>Vol. 7(3), pp. 294-315&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1080/23754931.2021.1871937">DOI</a> <a href="https://www.tandfonline.com/doi/full/10.1080/23754931.2021.1871937">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Pingel2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Pingel2021,
  author = {Pingel, Thomas J. and Saavedra, Andrea and Cobo, Lillian},
  title = {Deriving Land and Water Surface Elevations in the Northeastern Yucat&aacute;n Peninsula Using PPK GPS and UAV-Based Structure from Motion},
  journal = {Papers in Applied Geography},
  year = {2021},
  volume = {7},
  number = {3},
  pages = {294--315},
  url = {https://www.tandfonline.com/doi/full/10.1080/23754931.2021.1871937},
  doi = {https://doi.org/10.1080/23754931.2021.1871937}
}
</pre></td>
</tr>
<tr id="Pirvu2021" class="entry">
	<td>Pirvu, M., Robu, V., Licaret, V., Costea, D., Marcu, A., Slusanschi, E., Sukthankar, R. and Leordeanu, M.</td>
	<td>Depth distillation: unsupervised metric depth estimation for UAVs by finding consensus between kinematics, optical flow and deep learning <p class="infolinks">[<a href="javascript:toggleInfo('Pirvu2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 3209-3217&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/CVPRW53098.2021.00359">DOI</a> <a href="https://ieeexplore.ieee.org/document/9522771/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Pirvu2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Pirvu2021,
  author = {Pirvu, Mihai and Robu, Victor and Licaret, Vlad and Costea, Dragos and Marcu, Alina and Slusanschi, Emil and Sukthankar, Rahul and Leordeanu, Marius},
  title = {Depth distillation: unsupervised metric depth estimation for UAVs by finding consensus between kinematics, optical flow and deep learning},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  publisher = {IEEE},
  year = {2021},
  pages = {3209--3217},
  url = {https://ieeexplore.ieee.org/document/9522771/},
  doi = {https://doi.org/10.1109/CVPRW53098.2021.00359}
}
</pre></td>
</tr>
<tr id="Plum2021" class="entry">
	<td>Plum, F. and Labonte, D.</td>
	<td>scAnt —an open-source platform for the creation of 3D models of arthropods (and other small objects) <p class="infolinks">[<a href="javascript:toggleInfo('Plum2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Plum2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>PeerJ<br/>Vol. 9, pp. e11155&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.7717/peerj.11155">DOI</a> <a href="https://peerj.com/articles/11155">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Plum2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: We present scAnt , an open-source platform for the creation of digital 3D models of arthropods and small objects. scAnt consists of a scanner and a Graphical User Interface, and enables the automated generation of Extended Depth Of Field images from multiple perspectives. These images are then masked with a novel automatic routine which combines random forest-based edge-detection, adaptive thresholding and connected component labelling. The masked images can then be processed further with a photogrammetry software package of choice, including open-source options such as Meshroom , to create high-quality, textured 3D models. We demonstrate how these 3D models can be rigged to enable realistic digital specimen posing, and introduce a novel simple yet effective method to include semi-realistic representations of approximately planar and transparent structures such as wings. As a result of the exclusive reliance on generic hardware components, rapid prototyping and open-source software, scAnt costs only a fraction of available comparable systems. The resulting accessibility of scAnt will (i) drive the development of novel and powerful methods for machine learning-driven behavioural studies, leveraging synthetic data; (ii) increase accuracy in comparative morphometric studies as well as extend the available parameter space with area and volume measurements; (iii) inspire novel forms of outreach; and (iv) aid in the digitisation efforts currently underway in several major natural history collections.</td>
</tr>
<tr id="bib_Plum2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Plum2021,
  author = {Plum, Fabian and Labonte, David},
  title = {scAnt —an open-source platform for the creation of 3D models of arthropods (and other small objects)},
  journal = {PeerJ},
  year = {2021},
  volume = {9},
  pages = {e11155},
  url = {https://peerj.com/articles/11155},
  doi = {https://doi.org/10.7717/peerj.11155}
}
</pre></td>
</tr>
<tr id="Radulescu2021" class="entry">
	<td>Rădulescu, V., Rădulescu, G., Naș, S., Rădulescu, A., Bondrea, M. and Rădulescu, C.M.</td>
	<td>Synthetic Analysis of Geoinformatics Technologies for Preservation of Cultural Heritage, Methodological Approach <p class="infolinks">[<a href="javascript:toggleInfo('Radulescu2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Radulescu2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Applied Engineering Sciences<br/>Vol. 11(1), pp. 33-40&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.2478/jaes-2021-0005">DOI</a> <a href="https://www.sciendo.com/article/10.2478/jaes-2021-0005">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Radulescu2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Currently in Transylvania there are over 600 castles, considered monuments belonging to the world or national heritage. Some of them have disappeared, some are in an advanced degradation, the vast majority being in different stages of degradation, but recoverable, through very expensive investments. The first condition for them to start a program of recovery and put them again in the tourist and cultural circuit is to know exactly the state in which they are, to evaluate the costs. The development of geomatics technologies now allows for the high fidelity assessment of this aspect. These included Global Navigation Satellite System (GNSS) - Total Stations + Levels precision, terrestrial and aerial photogrammetry, laser scanners with fixed stations, for each presenting technical data and products analyzed sequentially and corroborated-complementary. The purpose of the entire action was to establish a Workflow as dedicated as possible to the requests of the specialists involved in such projects, architects, builders, restorers, historians, cultural people, etc. The paper can highlight a model of good practices in this field, the researches continuing, by consulting the beneficiaries of products from the range offered through these activities.</td>
</tr>
<tr id="bib_Radulescu2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Radulescu2021,
  author = {Rădulescu, V.M. and Rădulescu, G.M.T. and Naș, Sanda and Rădulescu, A.T. and Bondrea, M. and Rădulescu, Corina M.},
  title = {Synthetic Analysis of Geoinformatics Technologies for Preservation of Cultural Heritage, Methodological Approach},
  journal = {Journal of Applied Engineering Sciences},
  year = {2021},
  volume = {11},
  number = {1},
  pages = {33--40},
  url = {https://www.sciendo.com/article/10.2478/jaes-2021-0005},
  doi = {https://doi.org/10.2478/jaes-2021-0005}
}
</pre></td>
</tr>
<tr id="Ravi2021" class="entry">
	<td>Ravi, T., Ranganathan, R., Ramesh, S.P. and Dandotiya, D.S.</td>
	<td>3D Printed Personalized Orthotic Inserts Using Photogrammetry and FDM Technology <p class="infolinks">[<a href="javascript:toggleInfo('Ravi2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Ravi2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Fused Deposition Modeling Based 3D Printing, pp. 349-361&nbsp;</td>
	<td>inbook</td>
	<td><a href="https://doi.org/10.1007/978-3-030-68024-4_18">DOI</a> <a href="https://doi.org/10.1007/978-3-030-68024-4_18">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Ravi2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Orthotic shoe inserts are the most prominent fixtures used in shoes/sneakers of the sportspersons to accurate biomechanical foot issues. One size fits all doesn't work in these cases, as foot shape, curvature, and arch height from person to person differs. As of now, personalized inserts are very expensive due to the conventional manufacturing approach. With improved manufacturing technology, additive manufacturing the future is looking bright and promising. Manufacturing of inserts requires the need for soft or flexible material, which can be exploited conveniently using fused deposit modelling (FDM) technology. In this chapter, inserts have been modeled using unique android phone cameras and free computer software's based on photogrammetry technology, which has the capability to converts a series of 2D images into 3D models with STL file format. Then, the scanned model is smoothened in Mesh mixer software. Subsequently, upon making the changes in the model, the final product is printed and tested for its appropriateness for use. While the product developed is a low cost due to the simple, yet customized manufacturing method, the comfort delivered by the inserts are highly satisfactory.</td>
</tr>
<tr id="bib_Ravi2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inbook{Ravi2021,
  author = {Ravi, T and Ranganathan, Rajesh and Ramesh, S P and Dandotiya, Devendra Singh},
  title = {3D Printed Personalized Orthotic Inserts Using Photogrammetry and FDM Technology},
  booktitle = {Fused Deposition Modeling Based 3D Printing},
  publisher = {Springer International Publishing},
  year = {2021},
  pages = {349--361},
  url = {https://doi.org/10.1007/978-3-030-68024-4_18},
  doi = {https://doi.org/10.1007/978-3-030-68024-4_18}
}
</pre></td>
</tr>
<tr id="Rode2021" class="entry">
	<td>Rode, S., Singh, H., Thube, N., Mhaske, M., Ansari, H. and Vadhel, M.</td>
	<td>Design and Fabrication of a 3-D scanning system using Optical Computed Tomography and Photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('Rode2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE)&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICNTE51185.2021.9487696">DOI</a> &nbsp;</td>
</tr>
<tr id="bib_Rode2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Rode2021,
  author = {Rode, Suvarna and Singh, Harshit and Thube, Nimish and Mhaske, Mayur and Ansari, Hassaan and Vadhel, Mayur},
  title = {Design and Fabrication of a 3-D scanning system using Optical Computed Tomography and Photogrammetry},
  booktitle = {Proceedings of the 2021 4th Biennial International Conference on Nascent Technologies in Engineering (ICNTE)},
  publisher = {IEEE},
  year = {2021},
  doi = {https://doi.org/10.1109/ICNTE51185.2021.9487696}
}
</pre></td>
</tr>
<tr id="RONZINO2021" class="entry">
	<td>RONZINO, F.</td>
	<td>Automatic Reconstruction Of Indoor Environments For Sharing AR And VR Spaces <p class="infolinks">[<a href="javascript:toggleInfo('RONZINO2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 141<i>School</i>: Politecnico di Torino&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://webthesis.biblio.polito.it/18182/1/tesi.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_RONZINO2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{RONZINO2021,
  author = {RONZINO, FABRIZIO},
  title = {Automatic Reconstruction Of Indoor Environments For Sharing AR And VR Spaces},
  school = {Politecnico di Torino},
  year = {2021},
  pages = {141},
  url = {https://webthesis.biblio.polito.it/18182/1/tesi.pdf}
}
</pre></td>
</tr>
<tr id="Roscian2021" class="entry">
	<td>Roscian, M., Herrel, A., Cornette, R., Delapr&eacute;, A., Cherel, Y. and Rouget, I.</td>
	<td>Underwater photogrammetry for close‐range 3D imaging of dry‐sensitive objects: The case study of cephalopod beaks <p class="infolinks">[<a href="javascript:toggleInfo('Roscian2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Ecology and Evolution<br/>Vol. 11(12), pp. 7730-7742&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1002/ece3.7607">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/ece3.7607">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Roscian2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Roscian2021,
  author = {Roscian, Marjorie and Herrel, Anthony and Cornette, Rapha&euml;l and Delapr&eacute;, Arnaud and Cherel, Yves and Rouget, Isabelle},
  title = {Underwater photogrammetry for close‐range 3D imaging of dry‐sensitive objects: The case study of cephalopod beaks},
  journal = {Ecology and Evolution},
  year = {2021},
  volume = {11},
  number = {12},
  pages = {7730--7742},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/ece3.7607},
  doi = {https://doi.org/10.1002/ece3.7607}
}
</pre></td>
</tr>
<tr id="Rua2021" class="entry">
	<td>R&uacute;a, E., Cabaleiro, M., Conde, B. and Riveiro, B.</td>
	<td>First results of a methodology to obtain a 1D variable geometry model for the structural analysis of corroded steel beams from the point cloud <p class="infolinks">[<a href="javascript:toggleInfo('Rua2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Structures<br/>Vol. 33, pp. 3257-3268&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.istruc.2021.06.063">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S2352012421005683">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Rua2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Rua2021,
  author = {R&uacute;a, Erik and Cabaleiro, Manuel and Conde, Borja and Riveiro, Bel&eacute;n},
  title = {First results of a methodology to obtain a 1D variable geometry model for the structural analysis of corroded steel beams from the point cloud},
  journal = {Structures},
  year = {2021},
  volume = {33},
  pages = {3257--3268},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352012421005683},
  doi = {https://doi.org/10.1016/j.istruc.2021.06.063}
}
</pre></td>
</tr>
<tr id="Rustler2021" class="entry">
	<td>Rustler, L., Potocna, B., Polic, M., Stepanova, K. and Hoffmann, M.</td>
	<td>Spatial calibration of whole-body artificial skin on a humanoid robot: comparing self-contact, 3D reconstruction, and CAD-based calibration <p class="infolinks">[<a href="javascript:toggleInfo('Rustler2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the IEEE-RAS International Conference on Humanoid Robots (Humanoids), pp. 445-452&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="bib_Rustler2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Rustler2021,
  author = {Rustler, Lukas and Potocna, Bohumila and Polic, Michal and Stepanova, Karla and Hoffmann, Matej},
  title = {Spatial calibration of whole-body artificial skin on a humanoid robot: comparing self-contact, 3D reconstruction, and CAD-based calibration},
  booktitle = {Proceedings of the IEEE-RAS International Conference on Humanoid Robots (Humanoids)},
  publisher = {IEEE},
  year = {2021},
  pages = {445--452}
}
</pre></td>
</tr>
<tr id="Saghiri2021" class="entry">
	<td>Saghiri, M.A., Nath, D., Oguagha, O., Saghiri, A.M. and Morgano, S.M.</td>
	<td>A new reliable alternate method to an intraoral scanner (in-vitro study) <p class="infolinks">[<a href="javascript:toggleInfo('Saghiri2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Physics in Medicine<br/>Vol. 12, pp. 100036&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1016/j.phmed.2021.100036">DOI</a> <a href="https://linkinghub.elsevier.com/retrieve/pii/S2352451021000020">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Saghiri2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Saghiri2021,
  author = {Saghiri, Mohammad Ali and Nath, Devyani and Oguagha, Onyeka and Saghiri, Ali Mohammad and Morgano, Steven M.},
  title = {A new reliable alternate method to an intraoral scanner (in-vitro study)},
  journal = {Physics in Medicine},
  year = {2021},
  volume = {12},
  pages = {100036},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352451021000020},
  doi = {https://doi.org/10.1016/j.phmed.2021.100036}
}
</pre></td>
</tr>
<tr id="Salter2021" class="entry">
	<td>Salter, W.T., Shrestha, A. and Barbour, M.M.</td>
	<td>Open source 3D phenotyping of chickpea plant architecture across plant development <p class="infolinks">[<a href="javascript:toggleInfo('Salter2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Plant Methods<br/>Vol. 17(1), pp. 95&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1186/s13007-021-00795-6">DOI</a> <a href="https://plantmethods.biomedcentral.com/articles/10.1186/s13007-021-00795-6">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Salter2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Salter2021,
  author = {Salter, William T. and Shrestha, Arjina and Barbour, Margaret M.},
  title = {Open source 3D phenotyping of chickpea plant architecture across plant development},
  journal = {Plant Methods},
  year = {2021},
  volume = {17},
  number = {1},
  pages = {95},
  url = {https://plantmethods.biomedcentral.com/articles/10.1186/s13007-021-00795-6},
  doi = {https://doi.org/10.1186/s13007-021-00795-6}
}
</pre></td>
</tr>
<tr id="Saponaro2021" class="entry">
	<td>Saponaro, A., Dipierro, G., Cannella, E., Panarese, A., Galiano, A.M. and Massaro, A.</td>
	<td>A UAV-GPR Fusion Approach for the Characterization of a Quarry Excavation Area in Falconara Albanese, Southern Italy <p class="infolinks">[<a href="javascript:toggleInfo('Saponaro2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Saponaro2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Drones<br/>Vol. 5(2), pp. 40&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.3390/drones5020040">DOI</a> <a href="https://www.mdpi.com/2504-446X/5/2/40">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Saponaro2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The characterization of a quarry site which is suitable for railway ballast aggregate production represents a big challenge for the mining industry. The knowledge of structural discontinuities within local geological materials is fundamental to guide mining operations, optimize investments, and guarantee quarry security. This research work presents an innovative methodology for the subsurface investigation of a quarry excavation area down to a depth of about 50 m in Falconara Albanese, Calabria, Italy. The proposed methodological approach incorporates photogrammetry, drone technology, and GPR data acquisition and processing. Photogrammetry represents the first step for obtaining a 3D topographical model reconstruction of the whole quarry, helping to detail the acquisition approach and properly plan the subsequent drone survey. In particular, two 120 MHz antennas have been mounted on the drone and two profiles have been acquired above and across the quarry. Results show the presence of fractured material and demonstrate the applicability of the method for identification of areas that are more suitable for railway ballast production. The presented method is therefore capable of detecting subsurficial fractures at a quarry site by means of a relatively fast and cost-effective procedure. Results are achieved within the framework of an industry project.</td>
</tr>
<tr id="bib_Saponaro2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Saponaro2021,
  author = {Saponaro, Annamaria and Dipierro, Giovanni and Cannella, Emanuele and Panarese, Antonio and Galiano, Angelo Maurizio and Massaro, Alessandro},
  title = {A UAV-GPR Fusion Approach for the Characterization of a Quarry Excavation Area in Falconara Albanese, Southern Italy},
  journal = {Drones},
  year = {2021},
  volume = {5},
  number = {2},
  pages = {40},
  url = {https://www.mdpi.com/2504-446X/5/2/40},
  doi = {https://doi.org/10.3390/drones5020040}
}
</pre></td>
</tr>
<tr id="Saptaji_2021" class="entry">
	<td>Saptaji, K., Faizul, M. and Fakhri, A.</td>
	<td>Construction of low-cost 3D scanner using triangulation and Screened Poisson Surface Reconstruction techniques <p class="infolinks">[<a href="javascript:toggleInfo('Saptaji_2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Saptaji_2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>IOP Conference Series: Materials Science and Engineering<br/>Vol. 1098(6), pp. 62091&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1088/1757-899x/1098/6/062091">DOI</a> <a href="https://doi.org/10.1088/1757-899x/1098/6/062091">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Saptaji_2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: The application of 3D scanner technology among industrial practitioner in Indonesia and Malaysia is still at the beginning stage. Compared to others, this technology has already been adapted mostly by growing country such as China, Korea, US, Germany and Italy. This technology can be seen implemented in manufacturing, aerospace, medical and dentistry industries. The concept of 3D scanner technology is mainly to improve the reverse engineering process. Due to the high cost of 3D scanner machine available in the market, therefore a reasonable cost-effective 3D scanner is needed to be developed especially for education purposes. The objective of this project is to develop low-cost 3D scanning setup to create a mesh of a small-scale object with the help of open-sources software for 3D scanning and 3D mesh processing. Triangulation technique was used for the scanning process to capture the object surface. Screened Poisson Surface Reconstruction techniques was applied to improve the uncomplete and uneven surface mesh. In order to test the setup, 3D scanning was conducted on 4 different objects with different colours and surface finish. The scanning results show that the proposed method produced a good 3D mesh with less noise and less uncomplete surface.</td>
</tr>
<tr id="bib_Saptaji_2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Saptaji_2021,
  author = {Saptaji, K and Faizul, M and Fakhri, A},
  title = {Construction of low-cost 3D scanner using triangulation and Screened Poisson Surface Reconstruction techniques},
  journal = {IOP Conference Series: Materials Science and Engineering},
  publisher = {IOP Publishing},
  year = {2021},
  volume = {1098},
  number = {6},
  pages = {62091},
  url = {https://doi.org/10.1088/1757-899x/1098/6/062091},
  doi = {https://doi.org/10.1088/1757-899x/1098/6/062091}
}
</pre></td>
</tr>
<tr id="Scharnagl2021" class="entry">
	<td>Scharnagl, T. and Meiller, D.</td>
	<td>Physically Based Material Synthesis <p class="infolinks">[<a href="javascript:toggleInfo('Scharnagl2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Scharnagl2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 15th International Conference on Computer Graphics, Visualization, Computer Vision and Image Processing, pp. 129-132&nbsp;</td>
	<td>inproceedings</td>
	<td>&nbsp;</td>
</tr>
<tr id="abs_Scharnagl2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: This paper demonstrates an experimental approach of synthesizing features from real-world materials for use as a virtual physically based rendering material for computer generated imagery via photo scanning and photogrammetry.</td>
</tr>
<tr id="bib_Scharnagl2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Scharnagl2021,
  author = {Scharnagl, Tassilo and Meiller, Dieter},
  title = {Physically Based Material Synthesis},
  booktitle = {Proceedings of the 15th International Conference on Computer Graphics, Visualization, Computer Vision and Image Processing},
  year = {2021},
  pages = {129--132}
}
</pre></td>
</tr>
<tr id="Sebar2021" class="entry">
	<td>Sebar, L.E., Grassini, S., Parvis, M. and Lombardo, L.</td>
	<td>A low-cost automatic acquisition system for photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('Sebar2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Sebar2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 2021 IEEE International Instrumentation and Measurement Technology Conference (I2MTC), pp. 1-6&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/I2MTC50364.2021.9459991">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Sebar2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Photogrammetry is a non-destructive technique commonly employed in the cultural heritage field for reconstructing a 3D virtual replica of an artifact by simply taking several photos of the artifact itself from different points of view. The 3D model can be used either for documenting the artifact or for preserving its geometrical information and appearance. Moreover, by using a digital 3D model is extremely easy sharing information with the public and researchers without physically moving the artifact, and this represents a unique opportunity which cannot be achieved with traditional methods. Unfortunately most systems already present on the market are complex and costly both due to their hardware and software. This paper presents a novel acquisition system which is extremely cheap and can be easily arranged in any conservation laboratory. The solution is based on a simple acquisition system designed with the aim of providing researchers with a user-friendly and low-cost platform for the reconstruction of an artifact 3D model. The proposed system can be virtually interfaced to every commercial camera and can be integrated with several 3D reconstruction software. As an example, the authors employed a free open-source software referred to as Meshroom.</td>
</tr>
<tr id="bib_Sebar2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Sebar2021,
  author = {Sebar, Leila Es and Grassini, Sabrina and Parvis, Marco and Lombardo, Luca},
  title = {A low-cost automatic acquisition system for photogrammetry},
  booktitle = {Proceedings of the 2021 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  year = {2021},
  pages = {1--6},
  doi = {https://doi.org/10.1109/I2MTC50364.2021.9459991}
}
</pre></td>
</tr>
<tr id="Shah2021" class="entry">
	<td>Shah, F.M., Gaggero, T., Gaiotti, M. and Rizzo, C.M.</td>
	<td>Condition assessment of ship structure using robot assisted 3D-reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('Shah2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Shah2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Ship Technology Research&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1080/09377255.2021.1872219">DOI</a> <a href="https://www.tandfonline.com/doi/abs/10.1080/09377255.2021.1872219">URL</a>&nbsp;</td>
</tr>
<tr id="abs_Shah2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Ships condition is assessed regularly to maintain safety. Traditionally, structural integrity assessment is performed by surveyors, requiring complex and time-consuming operations to accessany ship...</td>
</tr>
<tr id="bib_Shah2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Shah2021,
  author = {Shah, Faisal Mehmood and Gaggero, Tomaso and Gaiotti, Marco and Rizzo, Cesare Mario},
  title = {Condition assessment of ship structure using robot assisted 3D-reconstruction},
  journal = {Ship Technology Research},
  publisher = {Taylor &amp; Francis},
  year = {2021},
  url = {https://www.tandfonline.com/doi/abs/10.1080/09377255.2021.1872219},
  doi = {https://doi.org/10.1080/09377255.2021.1872219}
}
</pre></td>
</tr>
<tr id="Silva2021" class="entry">
	<td>Silva, M.Z., Brito, T., Lima, J.L. and Silva, M.F.</td>
	<td>Industrial Robotic Arm in Machining Process Aimed to 3D Objects Reconstruction <p class="infolinks">[<a href="javascript:toggleInfo('Silva2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 22nd IEEE International Conference on Industrial Technology (ICIT), pp. 1100-1105&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1109/ICIT46573.2021.9453596">DOI</a> <a href="https://ieeexplore.ieee.org/document/9453596/">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Silva2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Silva2021,
  author = {Silva, Matheus Zorawski and Brito, Thadeu and Lima, Jose L. and Silva, Manuel F.},
  title = {Industrial Robotic Arm in Machining Process Aimed to 3D Objects Reconstruction},
  booktitle = {Proceedings of the 22nd IEEE International Conference on Industrial Technology (ICIT)},
  publisher = {IEEE},
  year = {2021},
  pages = {1100--1105},
  url = {https://ieeexplore.ieee.org/document/9453596/},
  doi = {https://doi.org/10.1109/ICIT46573.2021.9453596}
}
</pre></td>
</tr>
<tr id="Sinthanayothin2021" class="entry">
	<td>Sinthanayothin, C., Bholsithi, W. and Wongwaen, N.</td>
	<td>Morph targets for 3D facial animation with webcam using Facemesh, Jeeliz-transfer APIs, and Three.js <p class="infolinks">[<a href="javascript:toggleInfo('Sinthanayothin2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Proceedings of the 13th International Conference on Digital Image Processing (ICDIP 2021), pp. 45&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1117/12.2600859">DOI</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/2600859/Morph-targets-for-3D-facial-animation-with-webcam-using-Facemesh/10.1117/12.2600859.full">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Sinthanayothin2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Sinthanayothin2021,
  author = {Sinthanayothin, Chanjira and Bholsithi, Wisarut and Wongwaen, Nonlapas},
  title = {Morph targets for 3D facial animation with webcam using Facemesh, Jeeliz-transfer APIs, and Three.js},
  booktitle = {Proceedings of the 13th International Conference on Digital Image Processing (ICDIP 2021)},
  publisher = {SPIE},
  year = {2021},
  pages = {45},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/2600859/Morph-targets-for-3D-facial-animation-with-webcam-using-Facemesh/10.1117/12.2600859.full},
  doi = {https://doi.org/10.1117/12.2600859}
}
</pre></td>
</tr>
<tr id="Su2021" class="entry">
	<td>Su, B., Zheng, K. and Wang, W.</td>
	<td>A GitHub Project Recommendation Model Based on Self-Attention Sequence <p class="infolinks">[<a href="javascript:toggleInfo('Su2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>The 2021 3rd International Conference on Big Data Engineering, pp. 110-116&nbsp;</td>
	<td>inproceedings</td>
	<td><a href="https://doi.org/10.1145/3468920.3468936">DOI</a> <a href="https://dl.acm.org/doi/10.1145/3468920.3468936">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Su2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@inproceedings{Su2021,
  author = {Su, Bin and Zheng, Kai and Wang, Wei},
  title = {A GitHub Project Recommendation Model Based on Self-Attention Sequence},
  booktitle = {The 2021 3rd International Conference on Big Data Engineering},
  publisher = {ACM},
  year = {2021},
  pages = {110--116},
  url = {https://dl.acm.org/doi/10.1145/3468920.3468936},
  doi = {https://doi.org/10.1145/3468920.3468936}
}
</pre></td>
</tr>
<tr id="TAMBURELLO2021" class="entry">
	<td>TAMBURELLO, F.</td>
	<td>3D Reconstruction Of Indoor Environments <p class="infolinks">[<a href="javascript:toggleInfo('TAMBURELLO2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>, pp. 139<i>School</i>: Politecnico di Torino&nbsp;</td>
	<td>phdthesis</td>
	<td><a href="https://webthesis.biblio.polito.it/17957/1/tesi.pdf">URL</a>&nbsp;</td>
</tr>
<tr id="bib_TAMBURELLO2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@phdthesis{TAMBURELLO2021,
  author = {TAMBURELLO, FRANCESCO},
  title = {3D Reconstruction Of Indoor Environments},
  school = {Politecnico di Torino},
  year = {2021},
  pages = {139},
  url = {https://webthesis.biblio.polito.it/17957/1/tesi.pdf}
}
</pre></td>
</tr>
<tr id="Tomes2021" class="entry">
	<td>Tome&scaron;, J., Tylov&aacute;, N., Kohout, J. and Mare&scaron;, J.</td>
	<td>Virtual Reality Model Assessment Platform: Transfer Models to a Standalone Virtual Reality Headset <p class="infolinks">[<a href="javascript:toggleInfo('Tomes2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Software Engineering and Algorithms. CSOC 2021. Lecture Notes in Networks and Systems, pp. 469-479&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-77442-4_40">DOI</a> <a href="https://link.springer.com/10.1007/978-3-030-77442-4_40">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Tomes2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Tomes2021,
  author = {Tome&scaron;, Jakub and Tylov&aacute;, Naďa and Kohout, Jan and Mare&scaron;, Jan},
  title = {Virtual Reality Model Assessment Platform: Transfer Models to a Standalone Virtual Reality Headset},
  booktitle = {Software Engineering and Algorithms. CSOC 2021. Lecture Notes in Networks and Systems},
  publisher = {Springer, Cham},
  year = {2021},
  pages = {469--479},
  url = {https://link.springer.com/10.1007/978-3-030-77442-4_40},
  doi = {https://doi.org/10.1007/978-3-030-77442-4_40}
}
</pre></td>
</tr>
<tr id="Toth2021" class="entry">
	<td>T&oacute;th, D., Petrus, K., Heckmann, V., Simon, G. and Po&oacute;r, V.S.</td>
	<td>Application of photogrammetry in forensic pathology education of medical students in response to COVID‐19 <p class="infolinks">[<a href="javascript:toggleInfo('Toth2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Journal of Forensic Sciences<br/>Vol. 66(4), pp. 1533-1537&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1111/1556-4029.14709">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1111/1556-4029.14709">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Toth2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Toth2021,
  author = {T&oacute;th, D&eacute;nes and Petrus, Karola and Heckmann, Veronika and Simon, G&aacute;bor and Po&oacute;r, Viktor Soma},
  title = {Application of photogrammetry in forensic pathology education of medical students in response to COVID‐19},
  journal = {Journal of Forensic Sciences},
  year = {2021},
  volume = {66},
  number = {4},
  pages = {1533--1537},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/1556-4029.14709},
  doi = {https://doi.org/10.1111/1556-4029.14709}
}
</pre></td>
</tr>
<tr id="UGWITZ2021" class="entry">
	<td>UGWITZ, P., HERMAN, L., ACHOŇ, Z. and STACHOŇ, Z.</td>
	<td>3D Visualization of historical buildings: methods, their utility in the tourism industry and beyond <p class="infolinks">[<a href="javascript:toggleInfo('UGWITZ2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Region&aacute;ln&iacute; rozvoj mezi teori&iacute; a prax&iacute;. Hradec Kr&aacute;lov&eacute;: Civitas per Populi<br/>Vol. 1, pp. 43-62&nbsp;</td>
	<td>article</td>
	<td><a href="https://www.muni.cz/vyzkum/publikace/1757857">URL</a>&nbsp;</td>
</tr>
<tr id="bib_UGWITZ2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{UGWITZ2021,
  author = {UGWITZ, Pavel and HERMAN, Luk&aacute;&scaron; and ACHOŇ, Zden&#283;s and STACHOŇ, Zden&#283;k},
  title = {3D Visualization of historical buildings: methods, their utility in the tourism industry and beyond},
  journal = {Region&aacute;ln&iacute; rozvoj mezi teori&iacute; a prax&iacute;. Hradec Kr&aacute;lov&eacute;: Civitas per Populi},
  year = {2021},
  volume = {1},
  pages = {43--62},
  url = {https://www.muni.cz/vyzkum/publikace/1757857}
}
</pre></td>
</tr>
<tr id="Varotto2021" class="entry">
	<td>Varotto, E., Zurla, L., Galassi, F.M. and Ingoglia, C.</td>
	<td>The earliest known Italian case of bilateral non-osseous calcaneonavicular coalition from the mediaeval cemetery of Troina (Enna, Sicily) <p class="infolinks">[<a href="javascript:toggleInfo('Varotto2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Archaeological and Anthropological Sciences<br/>Vol. 13(9), pp. 154&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1007/s12520-021-01427-9">DOI</a> <a href="https://link.springer.com/10.1007/s12520-021-01427-9">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Varotto2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Varotto2021,
  author = {Varotto, Elena and Zurla, Lorenzo and Galassi, Francesco M. and Ingoglia, Caterina},
  title = {The earliest known Italian case of bilateral non-osseous calcaneonavicular coalition from the mediaeval cemetery of Troina (Enna, Sicily)},
  journal = {Archaeological and Anthropological Sciences},
  year = {2021},
  volume = {13},
  number = {9},
  pages = {154},
  url = {https://link.springer.com/10.1007/s12520-021-01427-9},
  doi = {https://doi.org/10.1007/s12520-021-01427-9}
}
</pre></td>
</tr>
<tr id="Wallner2021" class="entry">
	<td>Wallner, M., Steininger, D., Widhalm, V., Sch&ouml;rghuber, M. and Beleznai, C.</td>
	<td>RGB-D Railway Platform Monitoring and Scene Understanding for Enhanced Passenger Safety <p class="infolinks">[<a href="javascript:toggleInfo('Wallner2021','comment')">Comment</a>] [<a href="javascript:toggleInfo('Wallner2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021. Lecture Notes in Computer Science&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-3-030-68787-8_47">DOI</a> &nbsp;</td>
</tr>
<tr id="rev_Wallner2021" class="comment noshow">
	<td colspan="6"><b>Comment</b>: We exploit the modular concepts of Meshroom and demonstrate its use as a generic vision processing pipeline and scalable evaluation framework</td>
</tr>
<tr id="bib_Wallner2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Wallner2021,
  author = {Wallner, Marco and Steininger, Daniel and Widhalm, Verena and Sch&ouml;rghuber, Matthias and Beleznai, Csaba},
  title = {RGB-D Railway Platform Monitoring and Scene Understanding for Enhanced Passenger Safety},
  booktitle = {Pattern Recognition. ICPR International Workshops and Challenges. ICPR 2021. Lecture Notes in Computer Science},
  year = {2021},
  doi = {https://doi.org/10.1007/978-3-030-68787-8_47}
}
</pre></td>
</tr>
<tr id="Willman2021" class="entry">
	<td>Willman, J.C., Valera, A.C. and Silva, A.M.</td>
	<td>The embodiment of craft production in Bronze Age Portugal: Exceptional dental wear grooves in an individual from Monte do Vale do Ouro 2 (Ferreira do Alentejo, Portugal) <p class="infolinks">[<a href="javascript:toggleInfo('Willman2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>International Journal of Osteoarchaeology<br/>Vol. 31(2), pp. 252-262&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1002/oa.2944">DOI</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/oa.2944">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Willman2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Willman2021,
  author = {Willman, John Charles and Valera, Ant&oacute;nio Carlos and Silva, Ana Maria},
  title = {The embodiment of craft production in Bronze Age Portugal: Exceptional dental wear grooves in an individual from Monte do Vale do Ouro 2 (Ferreira do Alentejo, Portugal)},
  journal = {International Journal of Osteoarchaeology},
  year = {2021},
  volume = {31},
  number = {2},
  pages = {252--262},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/oa.2944},
  doi = {https://doi.org/10.1002/oa.2944}
}
</pre></td>
</tr>
<tr id="Zahari2021" class="entry">
	<td>Zahari, N.M., Karim, M.A.A., Nurhikmah, F., Aziz, N.A., Zawawi, M.H. and Mohamad, D.</td>
	<td>Review of Unmanned Aerial Vehicle Photogrammetry for Aerial Mapping Applications <p class="infolinks">[<a href="javascript:toggleInfo('Zahari2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>ICCOEE2020. ICCOEE 2021. Lecture Notes in Civil Engineering, pp. 669-676&nbsp;</td>
	<td>incollection</td>
	<td><a href="https://doi.org/10.1007/978-981-33-6311-3_76">DOI</a> <a href="http://link.springer.com/10.1007/978-981-33-6311-3_76">URL</a>&nbsp;</td>
</tr>
<tr id="bib_Zahari2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@incollection{Zahari2021,
  author = {Zahari, N. M. and Karim, Mohammad Arif Abdul and Nurhikmah, F. and Aziz, Nurhanani A. and Zawawi, M. H. and Mohamad, Daud},
  title = {Review of Unmanned Aerial Vehicle Photogrammetry for Aerial Mapping Applications},
  booktitle = {ICCOEE2020. ICCOEE 2021. Lecture Notes in Civil Engineering},
  year = {2021},
  pages = {669--676},
  url = {http://link.springer.com/10.1007/978-981-33-6311-3_76},
  doi = {https://doi.org/10.1007/978-981-33-6311-3_76}
}
</pre></td>
</tr>
<tr id="zaslavskiy_mark_2021_4514963" class="entry">
	<td>Zaslavskiy, M. and Kovynev, M.</td>
	<td>Review of Photogrammetry Techniques for 3D Scanning Tasks of Buildings <p class="infolinks">[<a href="javascript:toggleInfo('zaslavskiy_mark_2021_4514963','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>&nbsp;</td>
	<td>proceedings</td>
	<td><a href="https://doi.org/10.5281/zenodo.4514963">DOI</a> <a href="https://doi.org/10.5281/zenodo.4514963">URL</a>&nbsp;</td>
</tr>
<tr id="bib_zaslavskiy_mark_2021_4514963" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@proceedings{zaslavskiy_mark_2021_4514963,
  author = {Zaslavskiy, Mark and Kovynev, Maxim},
  title = {Review of Photogrammetry Techniques for 3D Scanning Tasks of Buildings},
  publisher = {FRUCT Oy},
  year = {2021},
  url = {https://doi.org/10.5281/zenodo.4514963},
  doi = {https://doi.org/10.5281/zenodo.4514963}
}
</pre></td>
</tr>
<tr id="Zhong2021" class="entry">
	<td>Zhong, F., Jindal, A., Y&ouml;ntem, &Ouml;., Hanji, P., Watt, S. and Mantiuk, R.</td>
	<td>Reproducing Reality with a High-Dynamic-Range Multi-Focal Stereo Display <p class="infolinks">[<a href="javascript:toggleInfo('Zhong2021','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Zhong2021','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>ACM Transactions on Graphics<br/>Vol. 40(6), pp. 14&nbsp;</td>
	<td>article</td>
	<td><a href="https://doi.org/10.1145/3478513.3480513">DOI</a> &nbsp;</td>
</tr>
<tr id="abs_Zhong2021" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Which one is real? (a) High-Dynamic-Range Mul�-Focal Stereo display (b) view of the real-scene (c) virtual and real objects shown side-by-side Fig. 1. We built a High-Dynamic-Range Multi-Focal Stereo display (a) which allows for a direct comparison with a physical scene located in front of the observer (b). The display can reproduce real-world 3D objects with accurate color, contrast, disparity, and a range of focal depth, making it hard to distinguish between real and virtual scenes (c). With well-established methods for producing photo-realistic results, the next big challenge of graphics and display technologies is to achieve perceptual realism-producing imagery indistinguishable from real-world 3D scenes. To deliver all necessary visual cues for perceptual realism, we built a High-Dynamic-Range Multi-Focal Stereo Display that achieves high resolution, accurate color, a wide dynamic range, and most depth cues, including binocular presentation and a range of focal depth. The display and associated imaging system have been designed to capture and reproduce a small near-eye three-dimensional object and to allow for a direct comparison between virtual and real scenes. To assess our reproduction of realism and demonstrate the capability of the display and imaging system, we conducted an experiment in which the participants were asked to discriminate between a virtual object and its physical counterpart. Our results indicate that the participants can only detect the discrepancy with a probability of 0.44. With such a level of perceptual realism, our display apparatus can facilitate a range of visual experiments that require the highest fidelity of reproduction while allowing for the full control of the displayed stimuli.</td>
</tr>
<tr id="bib_Zhong2021" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@article{Zhong2021,
  author = {Zhong, F ; and Jindal, A ; and Y&ouml;ntem, &Ouml; ; and Hanji, P ; and Watt, S ; and Mantiuk, R},
  title = {Reproducing Reality with a High-Dynamic-Range Multi-Focal Stereo Display},
  journal = {ACM Transactions on Graphics},
  publisher = {Accepted/In press},
  year = {2021},
  volume = {40},
  number = {6},
  pages = {14},
  doi = {https://doi.org/10.1145/3478513.3480513}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Times, T.N.Y.</td>
	<td>Capturing Images for Photogrammetry <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>&nbsp;</td>
	<td>misc</td>
	<td><a href="https://rd.nytimes.com/projects/capturing-images-for-photogrammetry">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Discover tips and best practices for capturing large-scale photogrammetry scenes with a mobile phone.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {The New York Times},
  title = {Capturing Images for Photogrammetry},
  year = {2021},
  url = {https://rd.nytimes.com/projects/capturing-images-for-photogrammetry}
}
</pre></td>
</tr>
<tr id="" class="entry">
	<td>Martin, J.</td>
	<td>RealityCapture, Epic Games, and Building the Ultimate Simulation <p class="infolinks">[<a href="javascript:toggleInfo('','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('','bibtex')">BibTeX</a>]</p></td>
	<td>2021</td>
	<td>blog&nbsp;</td>
	<td>misc</td>
	<td><a href="https://www.mosaic51.com/featured/reality-capture-epic-games-ultimate-simulation/?fbclid=IwAR1KJMwEhLp0ZMUpuOGSpsNwttRNm8w-1oi4Re1W1AMhr6ASj2098M4MBV8">URL</a>&nbsp;</td>
</tr>
<tr id="abs_" class="abstract noshow">
	<td colspan="6"><b>Abstract</b>: Meshroom is an open source, free project that is fully functional and very powerful. This was the first 3d software that I used, and without knowing what I was doing, I dropped 120 photos into it, clicked “start” and out came a nicely textured 3d mesh of a sandstone sculpture.</td>
</tr>
<tr id="bib_" class="bibtex noshow">
<td colspan="6"><b>BibTeX</b>:
<pre>
@misc{,
  author = {Jeffrey Martin},
  title = {RealityCapture, Epic Games, and Building the Ultimate Simulation},
  year = {2021},
  url = {https://www.mosaic51.com/featured/reality-capture-epic-games-ultimate-simulation/?fbclid=IwAR1KJMwEhLp0ZMUpuOGSpsNwttRNm8w-1oi4Re1W1AMhr6ASj2098M4MBV8}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> 2021.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>
